{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2669d422",
   "metadata": {},
   "source": [
    "# Input text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bf4a398e",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = ''''One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
    "\n",
    "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
    "\n",
    "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
    "\n",
    "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
    "\n",
    "It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
    "\n",
    "The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. Which means the difference in outcome between someone who's adept at it and someone who's not is very great.\n",
    "\n",
    "Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
    "\n",
    "Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially.\n",
    "\n",
    "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to pt.\n",
    "\n",
    "Even after decades of thinking about this, I find that sentence startling.'''"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "394c5f74",
   "metadata": {},
   "source": [
    "# Chunker settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d624b76d",
   "metadata": {},
   "outputs": [],
   "source": [
    "CHUNK_SIZE = 128\n",
    "CHUNK_OVERLAP = 32"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3701e85",
   "metadata": {},
   "source": [
    "# Token Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "89413d8a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fc/experiments/rag-project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n",
      "/Users/fc/experiments/rag-project/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk text: 'One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "\n",
      "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
      "\n",
      "It's obviously true that the returns for performance are superlinear in business. Some think this is\n",
      "Token count: 128\n",
      "Start index: 0\n",
      "End index: 573\n",
      "Chunk text:  get no customers, and you go out of business.\n",
      "\n",
      "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
      "\n",
      "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious\n",
      "Token count: 128\n",
      "Start index: 425\n",
      "End index: 1020\n",
      "Chunk text:  these, the rich get richer. [1]\n",
      "\n",
      "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
      "\n",
      "It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
      "\n",
      "The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow\n",
      "Token count: 128\n",
      "Start index: 874\n",
      "End index: 1494\n",
      "Chunk text:  you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. Which means the difference in outcome between someone who's adept at it and someone who's not is very great.\n",
      "\n",
      "Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
      "\n",
      "Y Combinator encourages founders to\n",
      "Token count: 128\n",
      "Start index: 1324\n",
      "End index: 1960\n",
      "Chunk text:  companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
      "\n",
      "Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially.\n",
      "\n",
      "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it\n",
      "Token count: 128\n",
      "Start index: 1794\n",
      "End index: 2429\n",
      "Chunk text:  you tend to get something that grows exponentially.\n",
      "\n",
      "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to pt.\n",
      "\n",
      "Even after decades of thinking about this, I find that sentence startling.\n",
      "Token count: 79\n",
      "Start index: 2280\n",
      "End index: 2659\n"
     ]
    }
   ],
   "source": [
    "from chonkie import TokenChunker\n",
    "\n",
    "# Basic initialization with default parameters\n",
    "chunker = TokenChunker(\n",
    "    tokenizer=\"gpt2\",                   # Supports string identifiers\n",
    "    chunk_size=CHUNK_SIZE,              # Maximum tokens per chunk\n",
    "    chunk_overlap=CHUNK_OVERLAP         # Overlap between chunks\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk(text)\n",
    "for chunk in chunks:\n",
    "    print(f\"Chunk text: {chunk.text}\")\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Start index: {chunk.start_index}\")\n",
    "    print(f\"End index: {chunk.end_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c63398d",
   "metadata": {},
   "source": [
    "# Sentence Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fa69897f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk text: 'One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "\n",
      "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
      "\n",
      "Token count: 108\n",
      "Start index: 0\n",
      "End index: 472\n",
      "Chunk text: You get no customers, and you go out of business.\n",
      "\n",
      "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. \n",
      "Token count: 105\n",
      "Start index: 422\n",
      "End index: 903\n",
      "Chunk text: In all of these, the rich get richer. [1]\n",
      "\n",
      "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
      "\n",
      "It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
      "\n",
      "The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. \n",
      "Token count: 116\n",
      "Start index: 865\n",
      "End index: 1420\n",
      "Chunk text: \n",
      "The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. Which means the difference in outcome between someone who's adept at it and someone who's not is very great.\n",
      "\n",
      "Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. \n",
      "Token count: 96\n",
      "Start index: 1271\n",
      "End index: 1733\n",
      "Chunk text: Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
      "\n",
      "Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. \n",
      "Token count: 110\n",
      "Start index: 1679\n",
      "End index: 2223\n",
      "Chunk text: It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially.\n",
      "\n",
      "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to pt.\n",
      "\n",
      "Even after decades of thinking about this, I find that sentence startling.\n",
      "Token count: 117\n",
      "Start index: 2103\n",
      "End index: 2659\n"
     ]
    }
   ],
   "source": [
    "from chonkie import SentenceChunker\n",
    "\n",
    "# Basic initialization with default parameters\n",
    "chunker = SentenceChunker(\n",
    "    tokenizer_or_token_counter=\"gpt2\",      # Supports string identifiers\n",
    "    chunk_size=CHUNK_SIZE,                  # Maximum tokens per chunk\n",
    "    chunk_overlap=CHUNK_OVERLAP,            # Overlap between chunks\n",
    "    min_sentences_per_chunk=1               # Minimum sentences in each chunk\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk(text)\n",
    "for chunk in chunks:\n",
    "    print(f\"Chunk text: {chunk.text}\")\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Start index: {chunk.start_index}\")\n",
    "    print(f\"End index: {chunk.end_index}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44034749",
   "metadata": {},
   "source": [
    "# Recursive Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6356510f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk text: 'One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "\n",
      "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
      "Token count: 107\n",
      "Start index: 0\n",
      "End index: 471\n",
      "Chunk text: \n",
      "\n",
      "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
      "Token count: 95\n",
      "Start index: 471\n",
      "End index: 906\n",
      "Chunk text: \n",
      "\n",
      "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
      "\n",
      "It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
      "Token count: 74\n",
      "Start index: 906\n",
      "End index: 1270\n",
      "Chunk text: \n",
      "\n",
      "The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. Which means the difference in outcome between someone who's adept at it and someone who's not is very great.\n",
      "Token count: 67\n",
      "Start index: 1270\n",
      "End index: 1604\n",
      "Chunk text: \n",
      "\n",
      "Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
      "Token count: 64\n",
      "Start index: 1604\n",
      "End index: 1923\n",
      "Chunk text: \n",
      "\n",
      "Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially.\n",
      "Token count: 82\n",
      "Start index: 1923\n",
      "End index: 2332\n",
      "Chunk text: \n",
      "\n",
      "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to pt.\n",
      "\n",
      "Even after decades of thinking about this, I find that sentence startling.\n",
      "Token count: 70\n",
      "Start index: 2332\n",
      "End index: 2659\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from chonkie import RecursiveChunker\n",
    "\n",
    "chunker = RecursiveChunker.from_recipe(\n",
    "    name=\"default\",\n",
    "    lang=\"en\",\n",
    "    chunk_size=CHUNK_SIZE,  # Maximum tokens per chunk\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk(text)\n",
    "for chunk in chunks:\n",
    "    print(f\"Chunk text: {chunk.text}\")\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Start index: {chunk.start_index}\")\n",
    "    print(f\"End index: {chunk.end_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c707fce6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chonkie.types.recursive.RecursiveChunk,\n",
       " dict_keys(['text', 'start_index', 'end_index', 'token_count', 'context', 'level']))"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[0]), chunks[0].to_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c635ca98",
   "metadata": {},
   "source": [
    "# Semantic Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "23266a8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk text: 'One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "\n",
      "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
      "\n",
      "Token count: 111\n",
      "Start index: 0\n",
      "End index: 472\n",
      "Chunk text: \n",
      "It's obviously true that the returns for performance are superlinear in business. Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
      "\n",
      "You can't understand the world without understanding the concept of superlinear returns. \n",
      "Token count: 114\n",
      "Start index: 472\n",
      "End index: 997\n",
      "Chunk text: And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
      "\n",
      "It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
      "\n",
      "The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. \n",
      "Token count: 106\n",
      "Start index: 997\n",
      "End index: 1496\n",
      "Chunk text: Which means the difference in outcome between someone who's adept at it and someone who's not is very great.\n",
      "\n",
      "Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
      "\n",
      "Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. \n",
      "Token count: 122\n",
      "Start index: 1496\n",
      "End index: 2103\n",
      "Chunk text: It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially.\n",
      "\n",
      "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to pt.\n",
      "\n",
      "Even after decades of thinking about this, I find that sentence startling.\n",
      "Token count: 118\n",
      "Start index: 2103\n",
      "End index: 2659\n"
     ]
    }
   ],
   "source": [
    "from chonkie import SemanticChunker\n",
    "\n",
    "# Basic initialization with default parameters\n",
    "chunker = SemanticChunker(\n",
    "    embedding_model=\"minishlab/potion-base-8M\",  # Default model\n",
    "    threshold=0.5,                               # Similarity threshold (0-1) or (1-100) or \"auto\"\n",
    "    chunk_size=CHUNK_SIZE,                       # Maximum tokens per chunk\n",
    "    min_sentences=1                              # Initial sentences per chunk\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk(text)\n",
    "for chunk in chunks:\n",
    "    print(f\"Chunk text: {chunk.text}\")\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Start index: {chunk.start_index}\")\n",
    "    print(f\"End index: {chunk.end_index}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "79a4e053",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chonkie.types.semantic.SemanticChunk,\n",
       " dict_keys(['text', 'start_index', 'end_index', 'token_count', 'context', 'sentences']))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(chunks[0]), chunks[0].to_dict().keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "336d2979",
   "metadata": {},
   "source": [
    "Inspecting sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "55635d10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(chonkie.types.semantic.SemanticSentence, 5)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunk_sentences = chunks[0].sentences\n",
    "type(chunk_sentences[0]), len(chunk_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "70b03755",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence text: 'One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "\n",
      "Sentence embedding: [-0.08002032  0.08384115 -0.15242851 -0.01662905  0.1546974   0.1862143\n",
      " -0.14668271 -0.1180561  -0.09991404 -0.06428061]...\n",
      "\n",
      "Sentence text: \n",
      "Teachers and coaches implicitly told us the returns were linear. \n",
      "Sentence embedding: [-0.29372326  0.0668354  -0.17556645  0.06406913  0.19441003  0.2577094\n",
      " -0.15412916 -0.13282807 -0.07830012  0.02185827]...\n",
      "\n",
      "Sentence text: \"You get out,\" I heard a thousand times, \"what you put in.\" They meant well, but this is rarely true. \n",
      "Sentence embedding: [-0.3769128   0.11292984 -0.10909131 -0.00038342  0.20120978  0.2154198\n",
      " -0.1785941  -0.14814211  0.05318506  0.0355464 ]...\n",
      "\n",
      "Sentence text: If your product is only half as good as your competitor's, you don't get half as many customers. \n",
      "Sentence embedding: [-0.3903855   0.11076837 -0.04779201 -0.03220946  0.17338549  0.18829888\n",
      " -0.12727416 -0.11798425  0.14425997  0.09575932]...\n",
      "\n",
      "Sentence text: You get no customers, and you go out of business.\n",
      "\n",
      "Sentence embedding: [-0.17845249  0.13945955 -0.04182392 -0.17385544  0.22706324  0.18350954\n",
      " -0.14852972 -0.1274623   0.17388192 -0.01243831]...\n",
      "\n"
     ]
    }
   ],
   "source": [
    "for cs in chunk_sentences:\n",
    "    print(f\"Sentence text: {cs.text}\")\n",
    "    print(f\"Sentence embedding: {cs.embedding[:10]}...\")  # Print first 5 elements of the embedding\n",
    "    print(\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b419b5b",
   "metadata": {},
   "source": [
    "# Neural Chunker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0c036ee2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "Device set to use mps\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chunk text: 'One of the most important things I didn't understand about the world when I was a child is the degree to which the returns for performance are superlinear.\n",
      "\n",
      "Teachers and coaches implicitly told us the returns were linear. \"You get out,\" I heard a thousand times, \"what you put in.\"\n",
      "Token count: 63\n",
      "Start index: 0\n",
      "End index: 282\n",
      "Chunk text:  They meant well, but this is rarely true.\n",
      "Token count: 10\n",
      "Start index: 282\n",
      "End index: 324\n",
      "Chunk text:  If your product is only half as good as your competitor's, you don't get half as many customers. You get no customers, and you go out of business.\n",
      "\n",
      "It's obviously true that the returns for performance are superlinear in business.\n",
      "Token count: 51\n",
      "Start index: 324\n",
      "End index: 554\n",
      "Chunk text:  Some think this is a flaw of capitalism, and that if we changed the rules it would stop being true. But superlinear returns for performance are a feature of the world, not an artifact of rules we've invented. We see the same pattern in fame, power, military victories, knowledge, and even benefit to humanity. In all of these, the rich get richer. [1]\n",
      "Token count: 78\n",
      "Start index: 554\n",
      "End index: 906\n",
      "Chunk text: \n",
      "\n",
      "You can't understand the world without understanding the concept of superlinear returns. And if you're ambitious you definitely should, because this will be the wave you surf on.\n",
      "\n",
      "\n",
      "Token count: 37\n",
      "Start index: 906\n",
      "End index: 1088\n",
      "Chunk text: It may seem as if there are a lot of different situations with superlinear returns, but as far as I can tell they reduce to two fundamental causes: exponential growth and thresholds.\n",
      "\n",
      "\n",
      "Token count: 37\n",
      "Start index: 1088\n",
      "End index: 1272\n",
      "Chunk text: The most obvious case of superlinear returns is when you're working on something that grows exponentially. For example, growing bacterial cultures. When they grow at all, they grow exponentially. But they're tricky to grow. Which means the difference in outcome between someone who's adept at it and someone who's not is very great.\n",
      "\n",
      "Token count: 67\n",
      "Start index: 1272\n",
      "End index: 1605\n",
      "Chunk text: \n",
      "Startups can also grow exponentially, and we see the same pattern there. Some manage to achieve high growth rates. Most don't. And as a result you get qualitatively different outcomes: the companies with high growth rates tend to become immensely valuable, while the ones with lower growth rates may not even survive.\n",
      "\n",
      "Token count: 63\n",
      "Start index: 1605\n",
      "End index: 1924\n",
      "Chunk text: \n",
      "Y Combinator encourages founders to focus on growth rate rather than absolute numbers. It prevents them from being discouraged early on, when the absolute numbers are still low. It also helps them decide what to focus on: you can use growth rate as a compass to tell you how to evolve the company. But the main advantage is that by focusing on growth rate you tend to get something that grows exponentially.\n",
      "\n",
      "Token count: 82\n",
      "Start index: 1924\n",
      "End index: 2333\n",
      "Chunk text: \n",
      "YC doesn't explicitly tell founders that with growth rate \"you get out what you put in,\" but it's not far from the truth. And if growth rate were proportional to performance, then the reward for performance p over time t would be proportional to pt.\n",
      "\n",
      "Even after decades of thinking about this, I find that sentence startling.\n",
      "Token count: 70\n",
      "Start index: 2333\n",
      "End index: 2659\n"
     ]
    }
   ],
   "source": [
    "from chonkie import NeuralChunker\n",
    "\n",
    "# Basic initialization with default parameters\n",
    "chunker = NeuralChunker(\n",
    "    model=\"mirth/chonky_modernbert_base_1\",  # Default model\n",
    "    device_map=\"auto\",                       # Device to run the model on ('cpu', 'cuda', etc.)\n",
    "    min_characters_per_chunk=10,             # Minimum characters for a chunk\n",
    "    return_type=\"chunks\"                     # Output type\n",
    ")\n",
    "\n",
    "chunks = chunker.chunk(text)\n",
    "for chunk in chunks:\n",
    "    print(f\"Chunk text: {chunk.text}\")\n",
    "    print(f\"Token count: {chunk.token_count}\")\n",
    "    print(f\"Start index: {chunk.start_index}\")\n",
    "    print(f\"End index: {chunk.end_index}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
