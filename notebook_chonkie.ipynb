{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d497e57e",
   "metadata": {},
   "source": [
    "# 1. Setup Asyncio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0b7c49a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nest_asyncio\n",
    "\n",
    "nest_asyncio.apply()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d74b235",
   "metadata": {},
   "source": [
    "# 2. Setup the Qdrant vector database"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc42de2b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fc/experiments/rag-project/.venv/lib/python3.9/site-packages/urllib3/__init__.py:35: NotOpenSSLWarning: urllib3 v2 only supports OpenSSL 1.1.1+, currently the 'ssl' module is compiled with 'LibreSSL 2.8.3'. See: https://github.com/urllib3/urllib3/issues/3020\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "import qdrant_client\n",
    "\n",
    "collection_name = \"chat_with_docs_chonkie\"\n",
    "\n",
    "client = qdrant_client.QdrantClient(\n",
    "    host=\"localhost\",\n",
    "    port=6333,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08dcc9f8",
   "metadata": {},
   "source": [
    "# 3. Read the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "82745a5d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import SimpleDirectoryReader\n",
    "\n",
    "input_dir_path = \"./docs\"\n",
    "\n",
    "loader = SimpleDirectoryReader(\n",
    "    input_dir=input_dir_path,\n",
    "    required_exts=[\".pdf\"],\n",
    "    recursive=True\n",
    ")\n",
    "\n",
    "docs = loader.load_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "aacc0201",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='01595f54-f73e-4e17-a1a5-ad637c75da7e', embedding=None, metadata={'page_label': '1', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nDSP Y: C OMPILING DECLARATIVE LANGUAGE\\nMODEL CALLS INTO SELF -IMPROVING PIPELINES\\nOmar Khattab,1 Arnav Singhvi,2\\nParidhi Maheshwari,4 Zhiyuan Zhang,1\\nKeshav Santhanam,1 Sri Vardhamanan,6 Saiful Haq,6\\nAshutosh Sharma,6 Thomas T. Joshi,7 Hanna Moazam,8\\nHeather Miller,3,9 Matei Zaharia,2 Christopher Potts1\\n1Stanford University, 2UC Berkeley, 3Carnegie Mellon University,\\n4Amazon Alexa AI, 5Dashworks Technologies, Inc.,\\n6IIT Bombay, 7Calera Capital, 8Microsoft, 9Two Sigma Investments\\nokhattab@cs.stanford.edu\\nABSTRACT\\nThe ML community is rapidly exploring techniques for prompting language mod-\\nels (LMs) and for stacking them into pipelines that solve complex tasks. Un-\\nfortunately, existing LM pipelines are typically implemented using hard-coded\\n“prompt templates”, i.e. lengthy strings discovered via trial and error. Toward a\\nmore systematic approach for developing and optimizing LM pipelines, we intro-\\nduce DSPy, a programming model that abstracts LM pipelines astext transforma-\\ntion graphs, i.e. imperative computation graphs where LMs are invoked through\\ndeclarative modules. DSPy modules are parameterized, meaning they can learn\\n(by creating and collecting demonstrations) how to apply compositions of prompt-\\ning, finetuning, augmentation, and reasoning techniques. We design a compiler\\nthat will optimize any DSPy pipeline to maximize a given metric. We conduct\\ntwo case studies, showing that succinct DSPy programs can express and optimize\\nsophisticated LM pipelines that reason about math word problems, tackle multi-\\nhop retrieval, answer complex questions, and control agent loops. Within minutes\\nof compiling, a few lines of DSPy allow GPT-3.5 and llama2-13b-chat to self-\\nbootstrap pipelines that outperform standard few-shot prompting (generally by\\nover 25% and 65%, respectively) and pipelines with expert-created demonstra-\\ntions (by up to 5–46% and 16–40%, respectively). On top of that, DSPy pro-\\ngrams compiled to open and relatively small LMs like 770M-parameter T5 and\\nllama2-13b-chat are competitive with approaches that rely on expert-written\\nprompt chains for proprietary GPT-3.5.\\nDSPy is available at https://github.com/stanfordnlp/dspy.\\n1 I NTRODUCTION\\nLanguage models (LMs) are enabling researchers to build NLP systems at higher levels of abstrac-\\ntion and with lower data requirements than ever before (Bommasani et al., 2021). This is fueling an\\nexploding space of “prompting” techniques—and lightweight finetuning techniques—for adapting\\nLMs to new tasks (Kojima et al., 2022), eliciting systematic reasoning from them (Wei et al., 2022;\\nWang et al., 2022b), andaugmenting them with retrieved sources (Guu et al., 2020; Lazaridou et al.,\\n2022; Khattab et al., 2022) or with tools (Yao et al., 2022; Schick et al., 2023). Most of these tech-\\nniques are explored in isolation, but interest has been growing in building multi-stage pipelines and\\nagents that decompose complex tasks into more manageable calls to LMs in an effort to improve\\nperformance (Qi et al., 2019; Khattab et al., 2021a; Karpas et al., 2022; Dohan et al., 2022; Khot\\net al., 2022; Khattab et al., 2022; Chen et al., 2022; Pourreza & Rafiei, 2023; Shinn et al., 2023).\\nUnfortunately, LMs are known to be sensitive to how they are prompted for each task, and this is\\nexacerbated in pipelines where multiple LM calls have to interact effectively. As a result, the LM\\n1\\narXiv:2310.03714v1  [cs.CL]  5 Oct 2023', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8084eedf-d1f1-4f0b-bf47-c3612d196444', embedding=None, metadata={'page_label': '2', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\ncalls in existing LM pipelines and in popular developer frameworks are generally implemented using\\nhard-coded ‘prompt templates’, that is, long strings of instructions and demonstrations that are hand\\ncrafted through manual trial and error. We argue that this approach, while pervasive, can be brittle\\nand unscalable—conceptually akin to hand-tuning the weights for a classifier. A given string prompt\\nmight not generalize to different pipelines or across different LMs, data domains, or even inputs.\\nToward a more systematic approach to designing AI pipelines, we introduce theDSPy programming\\nmodel.1 DSPy pushes building new LM pipelines away from manipulating free-form strings and\\ncloser to programming (composing modular operators to build text transformation graphs) where a\\ncompiler automatically generates optimized LM invocation strategies and prompts from a program.\\nWe draw inspiration from the consensus that emerged around neural network abstractions (Bergstra\\net al., 2013), where (1) many general-purpose layers can be modularly composed in any complex\\narchitecture and (2) the model weights can be trained using optimizers instead of being hand-tuned.\\nTo this end, we propose the DSPy programming model(Sec 3). We first translate string-based\\nprompting techniques, including complex and task-dependent ones like Chain of Thought (Wei et al.,\\n2022) and ReAct (Yao et al., 2022), into declarative modules that carrynatural-language typed sig-\\nnatures. DSPy modules are task-adaptive components—akin to neural network layers—that abstract\\nany particular text transformation, like answering a question or summarizing a paper. We then pa-\\nrameterize each module so that it can learn its desired behavior by iteratively bootstrapping useful\\ndemonstrations within the pipeline. Inspired directly by PyTorch abstractions (Paszke et al., 2019),\\nDSPy modules are used via expressive define-by-run computational graphs. Pipelines are expressed\\nby (1) declaring the modules needed and (2) using these modules in any logical control flow (e.g.,\\nifstatements, for loops, exceptions, etc.) to logically connect the modules.\\nWe then develop theDSPy compiler(Sec 4), which optimizes any DSPy program to improve quality\\nor cost. The compiler inputs are the program, a few training inputs with optional labels, and a valida-\\ntion metric. The compiler simulates versions of the program on the inputs and bootstraps example\\ntraces of each module for self-improvement, using them to construct effective few-shot prompts\\nor finetuning small LMs for steps of the pipeline. Optimization in DSPy is highly modular: it is\\nconducted by teleprompters,2 which are general-purpose optimization strategies that determine how\\nthe modules should learn from data. In this way, the compiler automatically maps the declarative\\nmodules to high-quality compositions of prompting, finetuning, reasoning, and augmentation.\\nProgramming models like DSPy could be assessed along many dimensions, but we focus on the role\\nof expert-crafted prompts in shaping system performance. We are seeking to reduce or even remove\\ntheir role through DSPy modules (e.g., versions of popular techniques like Chain of Thought) and\\nteleprompters. We report on two expansive case studies: math word problems (GMS8K; Cobbe et al.\\n2021) and multi-hop question answering (HotPotQA; Yang et al. 2018) with explorations of chain\\nof thought, multi-chain reflection, multi-hop retrieval, retrieval-augmented question answering, and\\nagent loops. Our evaluations use a number of different compiling strategies effectively and show\\nthat straightforward DSPy programs outperform systems using hand-crafted prompts, while also\\nallowing our programs to use much smaller and hence more efficient LMs effectively.\\nOverall, this work proposes the first programming model that translates prompting techniques into\\nparameterized declarative modules and introduces an effective compiler with general optimiza-\\ntion strategies (teleprompters) to optimize arbitrary pipelines of these modules. Our main contri-\\nbutions are empirical and algorithmic: with DSPy, we have found that we can implement very\\nshort programs that can bootstrap self-improving multi-stage NLP systems using LMs as small as\\nllama2-13b-chat and T5-Large (770M parameters). Without hand-crafted prompts and within\\nminutes to tens of minutes of compiling, compositions of DSPy modules can raise the quality of\\nsimple programs from 33% to 82% (Sec 6) and from 32% to 46% (Sec 7) for GPT-3.5 and, simi-\\nlarly, from 9% to 47% (Sec 6) and from 22% to 41% (Sec 7) for llama2-13b-chat.\\n1DSPy is pronounced dee-ess-pie. It’s the second iteration of our earlier Demonstrate–Search–Predict\\nframework (DSP; Khattab et al. 2022). This paper introduces the key concepts in DSPy. For more extensive and\\nup-to-date documentation of the framework, we refer readers to https://github.com/stanfordnlp/dspy.\\n2We derive the name tele-prompters from the notion of abstracting and automating the task of prompting,\\nin particular, such that it happens at a distance, without manual intervention.\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9bb304c0-299e-483a-8a4c-248a70bb00bc', embedding=None, metadata={'page_label': '3', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n2 R ELATED WORK\\nThis work is inspired by the role that Torch (Collobert et al., 2002), Theano (Bergstra et al., 2010;\\n2011; Al-Rfou et al., 2016), Chainer (Tokui et al., 2015), and others played in the development in\\ndeep learning by providing powerful abstractions. A similar transformation is emerging with higher-\\nlevel pipelines of LMs, and we are seeking to offer a solid conceptual framework and programming\\nabstractions for what we call foundation model programming. We draw on differentiable program-\\nming (Wang et al., 2018) but applied to LM calls rather than neural networks, and borrow syntactic\\nelements from PyTorch (Paszke et al., 2019).\\nIn-context learning (McCann et al. 2018; Radford et al. 2018; Brown et al. 2020) is a key mechanism\\nfor foundation model programming. A growing body of work has revealed that, especially with\\ninstruction tuning (Ouyang et al., 2022), we can elicit sophisticated behavior via prompting (Wei\\net al., 2022; Wang et al., 2022b; Press et al., 2022; Yao et al., 2022; Khot et al., 2022; Madaan et al.,\\n2023). Similarly, forms of weak supervision that would normally require task-specific (Khattab\\net al., 2021a;b) or hand-built (Ratner et al., 2016; Hancock et al., 2018) heuristics are now done by\\nLMs (Wang et al., 2022b; Zelikman et al., 2022; Zhang et al., 2022; Shao et al., 2023).\\nIn-context learning methods now routinely invoke tools, leading to LM pipelines that use retrieval\\nmodels (Chen et al., 2017; Lewis et al., 2020; Guu et al., 2020; Lazaridou et al., 2022; Izacard et al.,\\n2022), multimodal foundation models, and more traditional tools like APIs (Nakano et al., 2021)\\nand calculators. A number of toolkits have been developed to facilitate this, including LangChain\\n(Chase, 2022), Semantic Kernel (Microsoft, 2023), LlamaIndex (Liu, 2022), and many other re-\\ntrieval and agent libraries. These toolkits provide pre-packaged chains and agents that connect\\nLMs with numerous accessible tools. However, they suffer from the pervasive prompt engineering\\nchallenges we address in DSPy: they express task-specific behavior through hand-written prompt\\ntemplates (for detailed discussion, see Appendix B).\\nResearchers are starting to apply discrete optimization and RL to find effective prompts, generally\\nfor a single logical LM call (Guo et al., 2023; Pryzant et al., 2023; Huang et al., 2022; Yang et al.,\\n2023). DSPy seeks to generalize this space: it offers a rich framework for optimizing arbitrary\\npipelines from high-level declarative signatures, by bootstrapping high-quality multi-stage demon-\\nstrations with constraints. In this framework, DSPy teleprompters may apply optimization using\\nmodel selection techniques like cross-validation or, in principle, with sophisticated techniques in-\\nvolving RL and LM feedback (Hu et al., 2023; Zhao et al., 2023a; Shinn et al., 2023) or learned or\\nBayesian hyperparameter optimization methods (Bergstra et al., 2013; Akiba et al., 2019).\\nThe present paper seeks to motivate DSPy as a programming model and to report new empirical\\nfindings from applying the DSPy compiler. This is inspired by formative work by Bergstra et al.\\n(2010; 2013), Paszke et al. (2019), and Wolf et al. (2020), who support their respective programming\\nmodels with a mix of benchmark numbers and some qualitative measures. For the current paper, we\\nfocus on showing that DSPy and its compiler allow us to build outstanding LM systems without\\nhand-crafted prompt strings, but instead from truly modular units, and that this opens up doors for\\nsystematically exploring a rich design space at a very high programmatic level of abstraction.\\n3 T HE DSP Y PROGRAMMING MODEL\\nWe present DSPy, which treats LMs as abstract devices for text generation,3 and optimizes their us-\\nage in arbitrary computational graphs. DSPy programs are expressed in Python: each program takes\\nthe task input (e.g., a question to answer or a paper to summarize) and returns the output (e.g., an\\nanswer or a summary) after a series of steps. DSPy contributes three abstractions toward automatic\\noptimization: signatures, modules, and teleprompters. Signatures abstract the input/output behavior\\nof a module; modules replace existing hand-prompting techniques and can be composed in arbitrary\\npipelines; and teleprompters optimize all modules in the pipeline to maximize a metric.\\n3We assume access to one or more LMs, which consume a prompt string and return text completions. This\\nmay be a promptable LM capable of in-context learning (e.g., GPT-3.5 or Llama2-7b) or a smaller finetuneable\\nLM (e.g., T5-base). An LM may be selected as the default; operations will use it unless configured otherwise.\\n3', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7c493630-f470-4cee-9a4b-4efd87c6abb7', embedding=None, metadata={'page_label': '4', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n3.1 N ATURAL LANGUAGE SIGNATURES CAN ABSTRACT PROMPTING & FINETUNING\\nInstead of free-form string prompts, DSPy programs use natural language signatures to assign work\\nto the LM. A DSPy signature isnatural-language typed declaration of a function: a short declarative\\nspec that tells DSPy what a text transformation needs to do (e.g., “consume questions and return\\nanswers”), rather than how a specific LM should be prompted to implement that behavior. More\\nformally, a DSPy signature is a tuple of input fields and output fields (and an optional instruction).\\nA field consists offield name and optional metadata.4 In typical usage, the roles of fields are inferred\\nby DSPy as a function of field names. For instance, the DSPy compiler will use in-context learning\\nto interpret questiondifferently from answer and will iteratively refine its usage of these fields.\\nSignatures offer two benefits over prompts: they can be compiled into self-improving and pipeline-\\nadaptive prompts or finetunes. This is primarily done by bootstrapping (Sec 4) useful demonstrating\\nexamples for each signature. Additionally, they handle structured formatting and parsing logic to\\nreduce (or, ideally, avoid) brittle string manipulation in user programs.\\nIn practice, DSPy signatures can be expressed with a shorthand notation likequestion -> answer,\\nso that line 1 in the following is a complete DSPy program for a basic question-answering system\\n(with line 2 illustrating usage and line 3 the response when GPT-3.5 is the LM):\\n1 qa = dspy.Predict(\"question -> answer\")\\n2 qa(question=\"Where is Guaran ´ı spoken?\")\\n3 # Out: Prediction(answer=’Guaran ´ı is spoken mainly in South America.’)\\nIn the shorthand notation, each field’s name indicates the semantic role that the input (or output)\\nfield plays in the transformation. DSPy will parse this notation and expand the field names into\\nmeaningful instructions for the LM, so that english document -> french translation would\\nprompt for English to French translation. When needed, DSPy offers more advanced programming\\ninterfaces for expressing more explicit constraints on signatures (Appendix A).\\n3.2 P ARAMETERIZED & TEMPLATED MODULES CAN ABSTRACT PROMPTING TECHNIQUES\\nAkin to type signatures in programming languages, DSPy signatures simply define an interface and\\nprovide type-like hints on the expected behavior. To use a signature, we must declare amodule with\\nthat signature, like we instantiated a Predict module above. A module declaration like this returns\\na function having that signature.\\nThe Predict Module The core module for working with signatures in DSPy isPredict(simplified\\npseudocode in Appendix D.1). Internally, Predict stores the supplied signature, an optional LM to\\nuse (initially None, but otherwise overrides the default LM for this module), and a list of demon-\\nstrations for prompting (initially empty). Like layers in PyTorch, the instantiated module behaves as\\na callable function: it takes in keyword arguments corresponding to the signature input fields (e.g.,\\nquestion), formats a prompt to implement the signature and includes the appropriate demonstra-\\ntions, calls the LM, and parses the output fields. When Predict detects it’s being used in compile\\nmode, it will also internally track input/output traces to assist the teleprompter at bootstrapping the\\ndemonstrations.\\nOther Built-in ModulesDSPy modules translate prompting techniques into modular functions that\\nsupport any signature, contrasting with the standard approach of prompting LMs with task-specific\\ndetails (e.g., hand-written few-shot examples). To this end, DSPy includes a number of more sophis-\\nticated modules like ChainOfThought, ProgramOfThought, MultiChainComparison, and ReAct.5\\nThese can all be used interchangeably to implement a DSPy signature. For instance, simply chang-\\n4String descriptions of the task and the fields are also optional and usually omitted. Fields can carry optional\\nfield prefix and description. By default, fields are assumed to hold free-form strings; we are actively exploring\\noptional data type as a way to specify constraints on valid values (e.g.,boolor int) and more gracefully handle\\nformatting and parsing logic, though this feature is not core to DSPy at the time of writing.\\n5These modules generalize prompting techniques from the literature, respectively, by Wei et al. (2022),\\nChen et al. (2022), Yoran et al. (2023), and Yao et al. (2022) and, in doing so, generalize the ideas on zero-shot\\nprompting and rationale self-generation from Kojima et al. (2022), Zelikman et al. (2022), Zhang et al. (2022),\\nand Huang et al. (2022) to parameterized modules that can bootstrap arbitrary multi-stage pipelines.\\n4', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a9ec16d3-b32b-44cb-a65d-31221e0b6822', embedding=None, metadata={'page_label': '5', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\ning Predict to ChainOfThought in the above program leads to a system that thinks step by step\\nbefore committing to its output field.\\nImportantly, all of these modules are implemented in a few lines of code by expanding the user-\\ndefined signature and calling Predict one or more times on new signatures as appropriate. For\\ninstance, we show a simplified implementation of the built-in ChainOfThought below.\\n1 class ChainOfThought(dspy.Module):\\n2 def __init__(self, signature):\\n3 # Modify signature from ‘*inputs -> *outputs‘ to ‘*inputs -> rationale, *outputs‘.\\n4 rationale_field = dspy.OutputField(prefix=\"Reasoning: Let’s think step by step.\")\\n5 signature = dspy.Signature(signature).prepend_output_field(rationale_field)\\n6\\n7 # Declare a sub-module with the modified signature.\\n8 self.predict = dspy.Predict(signature)\\n9\\n10 def forward(self, **kwargs):\\n11 # Just forward the inputs to the sub-module.\\n12 return self.predict(**kwargs)\\nThis is a fully-fledged module capable of learning effective few-shot prompting for any LM or task.\\nWe contrast that with Appendix C, which copies long reasoning prompts hand-written by sources\\nranging from recent research to popular prompting libraries.\\nParameterization Uniquely, DSPy parameterizes these prompting techniques. To understand this\\nparameterization, observe that any LM call seeking to implement a particular signature needs to\\nspecify parameters that include: (1) the specific LM to call (Chen et al., 2023), (2) the prompt in-\\nstructions (Yang et al., 2023) and the string prefix of each signature field and, most importantly, (3)\\nthe demonstrations used as few-shot prompts (for frozen LMs) or as training data (for finetuning).\\nWe focus primarily on automatically generating and selecting useful demonstrations. In our case\\nstudies, we find that bootstrapping good demonstrations gives us a powerful way to teach sophisti-\\ncated pipelines of LMs new behaviors systematically.\\nTools DSPy programs may use tools, which are modules that execute computation. We support re-\\ntrieval models through a dspy.Retrievemodule. At the time of writing, DSPy has built-in support\\nfor ColBERTv2, Pyserini, and Pinecone retrievers, and we have explored experimental dspy.SQL\\nfor executing SQL queries and dspy.PythonInterpreterfor executing Python code in a sandbox.\\nPrograms DSPy modules can be composed in arbitrary pipelines in a define-by-run interface. In-\\nspired directly by PyTorch and Chainer, one first declares the modules needed at initialization, allow-\\ning DSPy to keep track of them for optimization, and then one expresses the pipeline with arbitrary\\ncode that calls the modules in a forward method. As a simple illustration, we offer the following\\nsimple but complete retrieval-augmented generation (RAG) system.\\n1 class RAG(dspy.Module):\\n2 def __init__(self, num_passages=3):\\n3 # ‘Retrieve‘ will use the user’s default retrieval settings unless overriden.\\n4 self.retrieve = dspy.Retrieve(k=num_passages)\\n5 # ‘ChainOfThought‘ with signature that generates answers given retrieval & question.\\n6 self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\\n7\\n8 def forward(self, question):\\n9 context = self.retrieve(question).passages\\n10 return self.generate_answer(context=context, question=question)\\nTo highlight modularity, we use ChainOfThought as a drop-in replacement of the basic Predict.\\nOne can now simply write RAG()(\"Where is Guaran ´ı spoken?\") to use it. Notice that, if we\\nuse a signature \"context, question -> search query\", we get a system that generates search\\nqueries rather than answers.\\n3.3 T ELEPROMPTERS CAN AUTOMATE PROMPTING FOR ARBITRARY PIPELINES\\nWhen compiling a DSPy program, we generally invoke a teleprompter, which is an optimizer that\\ntakes the program, a training set, and a metric—and returns a new optimized program. Different\\nteleprompters (Sec 4) apply different strategies for optimization.\\n5', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='aa61be79-04bd-4732-ab71-a9de57bceaa6', embedding=None, metadata={'page_label': '6', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nIn DSPy, training sets may be small, potentially a handful of examples, though larger data enables\\nmore powerful optimization. Training examples may be incomplete, i.e., only input values are nec-\\nessary. Labels for the pipeline steps are not required, unless they need to be used in the metric. In\\npractice, we typically assume labels only for (at most) the program’s final output, not the intermedi-\\nate steps. This label-efficiency is critical for modularity: building a new pipeline in DSPy requires\\nsimply recompiling the new pipeline’s code, not annotating data specific to the new pipeline.\\nMetrics can be simple notions like exact match (EM) or F1, but they can be entire DSPy programs\\nthat balance multiple concerns. For example, we may compile the RAG module above against a\\ndataset of question–answer pairs qa trainset and the metric EM. The goal of optimization here is\\nto effectively bootstrap few-shot demonstrations. The following code achieves this:\\n1 # Small training set with only questions and final answers.\\n2 qa_trainset = [dspy.Example(question=\"What is the capital of France?\", answer=\"Paris\")]\\n3\\n4 # The teleprompter will bootstrap missing labels: reasoning chains and retrieval contexts.\\n5 teleprompter = dspy.BootstrapFewShot(metric=dspy.evaluate.answer_exact_match)\\n6 compiled_rag = teleprompter.compile(RAG(), trainset=qa_trainset)\\nIn this example, the BootstrapFewShot teleprompter (Sec 4, Appendix E.1) simulates RAG on the\\ntraining example(s). It will collect demonstrations of each module (i.e., examples of its input–output\\nbehavior) that collectively lead to valid output (i.e., respecting the signatures and the metric).\\nIf one wanted to push the compiled program to be extractive given its retrieved contexts, one could\\ndefine a custom metric to use in place of dspy.evaluate.answer exact match:\\n1 def answer_and_context_match(example, pred, trace=None):\\n2 answer_match = dspy.evaluate.answer_exact_match(example, pred)\\n3\\n4 # Is the prediction a substring of some passage?\\n5 context_match = any((pred.answer.lower() in c) for c in pred.context)\\n6\\n7 return answer_match and context_match\\nNotice that behavior like this might be more accurately checked by another DSPy program that\\nchecks for faithful grounding of answers. Such metrics are fully supported and encouraged in DSPy.\\nTeleprompters can be composed by specifying a teacher program. DSPy will sample demonstra-\\ntions from this program for prompt optimization. This composition can enable very rich pipelines,\\nwhere expensive programs (e.g., complex expensive ensembles using large LMs) supervise cheap\\nprograms (e.g., simple pipelines using smaller LMs). One may start withcompiled ragfrom above\\n(say, compiled to use a large Llama2-13b-chat LM) but now fine-tune Flan-T5-large to create an\\nefficient program:\\n1 # Larger set of questions with *no labels*. Labels for all steps will be bootstrapped.\\n2 unlabeled_questions = [dspy.Example(question=\"What is the capital of Germany?\"), ...]\\n3\\n4 # As we assumes no answer, we use ‘answer_passage_match‘ to filter ungrounded answers.\\n5 finetuning_teleprompter = BootstrapFinetune(metric=dspy.evaluate.answer_passage_match)\\n6\\n7 # We set ‘teacher=compiled_rag‘ to compose. Bootstrapping will now use ‘compiled_rag ‘.\\n8 compiled_rag_via_finetune = finetuning_teleprompter.compile(RAG(), teacher=compiled_rag,\\ntrainset=unlabeled_questions, target=’google/flan-t5-large’)\\n4 T HE DSP Y COMPILER\\nA key source of DSPy’s expressive power is its ability to compile—or automatically optimize—any\\nprogram in this programming model. Compiling relies on a teleprompter, which is an optimizer for\\nDSPy programs that improves the quality (or cost) of modules via prompting or finetuning, which\\nare unified in DSPy. While DSPy does not enforce this when creating new teleprompters, typical\\nteleprompters go through three stages.\\nStage 1: Candidate GenerationThe compiler first (recursively) finds all uniquePredictmodules\\n(predictors) in a program, including those nested under other modules. For each unique predictor\\np, the teleprompter may generate candidate values for the parameters of p: the instructions, field\\ndescriptions, or—most importantly—demonstrations (i.e., example input–output pairs). In this iter-\\n6', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='39189720-9ce2-4a61-8f50-42ff26cc0c33', embedding=None, metadata={'page_label': '7', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nation of DSPy, we focus on demonstrations and find that simple rejection-sampling-like approaches\\ncan help bootstrap highly effective multi-stage systems.\\nConsider the simplest non-trivial teleprompter in DSPy,BootstrapFewShot(simplified pseudocode\\nin Appendix E.1). This teleprompter will simulate a teacher program (or, if unset, the zero-shot\\nversion of the program being compiled) on some training inputs, possibly one or more times with\\na high temperature. When running in compile mode, multi-stage traces are tracked transparently\\nand in a thread-safe fashion throughout execution. The program’s metric is used to filter for multi-\\nstage traces that together help the pipeline pass the metric. We thus obtain potential labels for all\\nsignatures in the program by throwing away the bad examples and using the good examples as\\npotential demonstrations, though these design decisions are under user control.\\nWhile LMs can be highly unreliable, we find they can be rather efficient at searching the space\\nof solutions for multi-stage designs. A well-decomposed program can typically find at least a few\\ntraining examples where the LM can pass the constraints enforced by the signatures and metrics,\\nallowing us to bootstrap iteratively if needed.\\nStage 2: Parameter OptimizationNow each parameter has a discrete set of candidates: demon-\\nstrations, instructions, etc. Many hyperparameter tuning algorithms (e.g., random search or Tree-\\nstructured Parzen Estimators as in HyperOpt (Bergstra et al., 2013) and Optuna (Akiba et al., 2019))\\ncan be applied for selection among candidates. We report simplified implementations of DSPy’s\\nBootstrapFewShotWithRandomSearch and BootstrapFewShotWithOptuna in Appendix E.2 and\\nAppendix E.3.\\nAnother type of optimization is finetuning with BootstrapFinetune, where the demonstrations are\\nused to update the LM’s weights for each predictor. When this is applied, the LM parameter of each\\nmodule is updated to the new LM weights. Typically, we are optimizing average quality using the\\nmetric with cross-validation over the training set or a validation set. This is applicable even with no\\nlabels for any stages, depending on the nature of metric.\\nStage 3: Higher-Order Program OptimizationA different type of optimization that the DSPy\\ncompiler supports is modifying the control flow of the program. One of the simplest forms of\\nthese is ensembles, which we use in the case studies in this work. An ensemble will bootstrap\\nmultiple copies of the same program, and then replace the program with a new one that runs them\\nall in parallel and reduces their predictions into one with a custom function (e.g., majority voting).\\nIn future work, this stage can easily accommodate techniques for more dynamic (i.e., test-time)\\nbootstrapping as well as automatic backtracking-like logic.\\n5 G OALS OF EVALUATION\\nProgramming frameworks can be evaluated along many dimensions: computational efficiency, de-\\nveloper efficiency, intuitiveness of the code and concepts, and so forth. In this paper, we focus on\\nperhaps the most pressing issue for current LM pipelines: the role of hand-written, task-specific\\nprompts in achieving performant systems. Our evaluations seek to test the following hypotheses:\\nH1 With DSPy, we can replace hand-crafted prompt strings with concise and well-defined\\nmodules, without reducing quality or expressive power.\\nH2 Parameterizing the modules and treating prompting as an optimization problem makes\\nDSPy better at adapting to different LMs, and it may outperform expert-written prompts.\\nH3 The resulting modularity makes it possible to more thoroughly explore complex pipelines\\nthat have useful performance characteristics or that fit nuanced metrics.\\nOur evaluation will explore these hypotheses using diverse task–program pairs. We hope this begins\\na shift from underspecified questions like “how do different LMs compare on GSM8K” toward “how\\nthey compare on GSM8K with program P when compiled with strategy S”, which is a well-defined\\nand reproducible run. Ultimately, our goal is to reduce the role of artful prompt construction in\\nmodern AI in favor of the development of new modular, composable programs and optimizers.\\n7', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='3eb834cd-9430-41b2-86d1-656d22d6f391', embedding=None, metadata={'page_label': '8', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nTable 1: Results with in-context learning on GSM8K math word problems. Each row represents\\na separate pipeline: the module in the Program column is compiled against the examples in the\\nTraining set. The programs, compilers, and (small) training sets are defined in Section 6. Rows with\\nensemblebuild on the immediately preceding row. Notably, all programs in this table are expressed\\nby composing two to four DSPy modules and teleprompters. Compiling the correctmodules, instead\\nof string prompts, improves different LMs from 4–20% accuracy to 49–88% accuracy.\\nGPT-3.5 Llama2-13b-chat\\nProgram Compilation Training Dev Test Dev Test\\nvanilla\\nnone n/a 24.0 25.2 7.0 9.4\\nfewshot trainset 33.1 – 4.3 –\\nbootstrap trainset 44.0 – 28.0 –\\nbootstrap×2 trainset 64.7 61.7 37.3 36.5\\n+ensemble trainset 62.7 61.9 39.0 34.6\\nCoT\\nnone n/a 50.0 – 26.7 –\\nfewshot trainset 63.0 – 27.3 –\\nfewshot +humanCoT 78.6 72.4 34.3 33.7\\nbootstrap trainset 80.3 72.9 43.3 –\\n+ensemble trainset 88.3 81.6 43.7 –\\nreflection\\nnone n/a 65.0 – 36.7 –\\nfewshot trainset 71.7 – 36.3 –\\nbootstrap trainset 83.0 76.0 44.3 40.2\\n+ensemble trainset 86.7 – 49.0 46.9\\n6 C ASE STUDY: M ATH WORD PROBLEMS\\nWe evaluate on the popular GSM8K dataset with grade school math questions (Cobbe et al., 2021).\\nWe sample 200 and 300 question–answer pairs from the official training set for training and develop-\\nment, respectively. Our final evaluations use the 1.3k official test set examples. We report extensive\\ncomparisons on the development set to avoid overfitting on test. Following prior work on GSM8K,\\nwe evaluate the accuracy of the final numerical value that appears in the LM output.\\nPrograms Considered For this task, we consider three simple DSPy programs: a one-step Pre-\\ndict module (vanilla), a two-step ChainOfThought module ( CoT), and finally a multi-stage Com-\\nparerOfThoughts module (ThoughtReflection). These are fully defined by the following code:\\n1 vanilla = dspy.Predict(\"question -> answer\") # GSM8K Program ‘vanilla‘\\n2\\n3 CoT = dspy.ChainOfThought(\"question -> answer\") # GSM8K Program ‘CoT‘\\n1 class ThoughtReflection(dspy.Module):\\n2 def __init__(self, num_attempts):\\n3 self.predict = dspy.ChainOfThought(\"question -> answer\", n=num_attempts)\\n4 self.compare = dspy.MultiChainComparison(’question -> answer’, M=num_attempts)\\n5\\n6 def forward(self, question):\\n7 completions = self.predict(question=question).completions\\n8 return self.compare(question=question, completions=completions)\\n9\\n10 reflection = ThoughtReflection(num_attempts=5) # GSM8K Program ‘reflection‘\\nIn reflection, five reasoning chains are sampled from the LM (alongside their answers) and they\\nare compared in parallel by a built-in MultiChainComparison module, which generalizes Yoran\\net al. (2023). This generates a new answer taking into account the patterns from the five attempts.\\nCritically, the modules used are all generic, none is specific math problems or particular LM.\\nCompiling As we discussed in Section 4, DSPy programs can be compiled into new, optimized\\nprograms. In our experiments, we evaluate the programs zero-shot (no compiling) as well as a\\nnumber of strategies for compiling. Our simplest compiler is LabeledFewShot:\\n1 fewshot = dspy.LabeledFewShot(k=8).compile(program, trainset=trainset)\\nHere, programcan be any DSPy module. This simply samplesk=8random demonstrations from the\\ntrainsetfor the fields common to the training examples and the signature(s), in this case,question\\nand answer, but not the reasoning for instance. We report the average of 3–5 runs (depending on the\\nsetting) when applying such random sampling.\\n8', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d54e3fb0-737d-4d37-8f86-844a9006f7da', embedding=None, metadata={'page_label': '9', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nNext, we also consider bootstrapping few-shot examples with random search:\\n1 tp = BootstrapFewShotWithRandomSearch(metric=gsm8k_accuracy)\\n2 bootstrap = tp.compile(program, trainset=trainset, valset=devset)\\nThis will generate demonstration chains for examples in the training set and optimize the selection\\nof demonstrations (from this set) to self-improve the program’s modules. As the name indicates, this\\nis done with random search, treating the selection of demonstrations as a parameter to optimize.\\nNext, if desired, this bootstrapping process can be nested in DSPy. In particular, we can use the\\noptimized bootstrap program itself to further bootstrap another program. This is relevant, for\\nexample, whenever the original zero-shot program performs relatively poorly.\\n1 bootstrap2 = tp.compile(program, teacher=bootstrap, trainset=trainset, valset=devset)\\nAnd lastly, we consider ensembling these bootstraps:\\n1 # A program that ensembles the top-7 candidate programs from a bootstrapping compiler run\\n(in particular ‘bootstrap‘ or, when applicable, ‘bootstrap2‘) with majority voting.\\n2 ensemble = Ensemble(reduce_fn=dspy.majority).compile(bootstrap.programs[:7])\\nGSM8K includes human reasoning chains. Above, trainset does not include these reasoning\\nchains. We also evaluate with trainset human CoT, which extends the examples in trainsetwith\\nthe human reasoning string. These two datasets can be used interchangeably as the value for the\\ntrainset parameter above. We note here that compiling generally runs on the order of minutes\\n(or tens of minutes) as even the more expensive settings only require running the program a few\\nthousand times (e.g., 10–20 trials over 150–300 validation examples) and they can occur in parallel.\\nResults Our results are summarized in Table 1, which includes dev results as well as our evaluation\\nof promising representatives of each approach on the test set. First, the vanilla program results\\nshow that GPT-3.5 and llama2-13b-chat struggle with math word problems when they have to\\npredict the answers directly, that is, without using a reasoning chain first. This is most pronounced\\nin the absence of good demonstrations, which can be seen in the none compilation setting (i.e.,\\nzero-shot instruction) and the fewshot setting (i.e., sampling random question–answer pairs). In-\\nterestingly, however,vanillais helped substantially by compiling withbootstrapand by iterating\\nthis process into bootstrap×2. On inspecting the prompts bootstrapped (Appendix F), we see that\\nthe prompt allows the LM to leverage the answer field for reasoning first, which is permitted as the\\nmetric extracts the final numerical value for evaluation.\\nNext, we consider theCoTprogram. While the expert human reasoning chains (+human CoT) provide\\na large boost when available, we can match or surpass this using bootstrap, substantiating our\\nhypothesis that DSPy can cut the need for hand-crafted prompts. Beyond this, we see that the\\nreflectionprogram, while only a few lines longer than the others, is a clear winner, thoughCoTis\\nquite effective with ensemble. Overall, the bootstrap compilation procedure leads to large gains\\nfor every program, across both LMs. Indeed, all programs in this table are expressed by composing\\ntwo to four DSPy modules and teleprompters, and they reveal overall that—in the new paradigm\\nprescribed by DSPy—it’s composing the right generic modules, rather than manipulating string\\nprompts, that improves different LMs from 4–20% accuracy to 49–88% accuracy.\\nWe can informally compare with the following. Zhang et al. (2022) reports 48% for\\ntext-davinci-002, which aligns closely with our llama2-13b-chat results, and reports 59.4%\\nwith codex when employing a manual CoT approach and 62.8% with an automatic CoT method.\\nWang et al. (2022b) report 57% for CoT prompting with PaLM 540-B, which becomes 74% upon\\nadding self-consistency. The Llama2 authors (Touvron et al., 2023) presents 28.7% forllama2-13b,\\n42.2% for llama2-34b, and 56.8% for llama2-70b. Intriguingly, our program with the 13b variant\\nof the model is competitive with their 34b-based results even though we don’t use human reasoning\\nchains in our program. Zhao et al. (2023b) reports 80.8% for CoT with gpt-3.5-turbo from April\\n2023. The GPT-4 authors (OpenAI, 2023) reports that GPT-3.5 scores 57.1% and GPT-4 elevates\\nthis to 92% but they note that GPT-4 was in fact pre-trained on a subset of GSM8K’s training set.\\n9', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c940e797-b73f-430e-94a7-089429757735', embedding=None, metadata={'page_label': '10', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n7 C ASE STUDY: C OMPLEX QUESTION ANSWERING\\nIn this case study, we explore the multi-hop question answering task with the HotPotQA (Yang et al.,\\n2018) dataset in the open-domain “fullwiki” setting. For retrieval, we use a search index of the of-\\nficial Wikipedia 2017 “abstracts” dump of HotPotQA. Search is conducted by a ColBERTv2 (San-\\nthanam et al., 2021) retriever. The HotPotQA test set is hidden, so we reserve the official validation\\nset for our testing, and sample 1000 examples for that. We sub-divide the training set into 70%/30%\\ntrain/validation splits. In the training (and thus validation) split, we keep only examples marked as\\n“hard” in the original dataset, which matches the designation of the official validation and test sets.\\nFor training and for reporting development results, we sample 200 and 300 examples respectively.\\nPrograms Considered Our simplest baseline is the vanilla program used in the previous case\\nstudy on GSM8K (Sec 6); the \"question -> answer\" signature is universal enough that it will\\nwork for this task (and many others) when compiled appropriately.\\nOur baseline RAG program is the one given in Section 3.2 as a simple example of RAG with a\\ndspy.ChainOfThought layer. We will see that this program does not excel at HotPotQA, and this\\nmotivates us to evaluate two multi-hop programs.\\nTo that end, we first test ReAct (Yao et al., 2022), a multi-step agent for tool use, which is imple-\\nmented as a built-in module in DSPy. In the simplest case, a ReAct module for a particular signature\\ncan be declared as follows in DSPy:\\n1 react = dspy.ReAct(\"question -> answer\", tools=[dspy.Retrieve(k=1)], max_iters=5)\\nWe also test the following custom program, which simulates the information flow in Baleen (Khattab\\net al., 2021a) and IRRR (Qi et al., 2020) and has similarities to IRCoT (Trivedi et al., 2022).\\n1 class BasicMultiHop(dspy.Module):\\n2 def __init__(self, passages_per_hop):\\n3 self.retrieve = dspy.Retrieve(k=passages_per_hop)\\n4 self.generate_query = dspy.ChainOfThought(\"context, question -> search_query\")\\n5 self.generate_answer = dspy.ChainOfThought(\"context, question -> answer\")\\n6\\n7 def forward(self, question):\\n8 context = []\\n9\\n10 for hop in range(2):\\n11 query = self.generate_query(context=context, question=question).search_query\\n12 context += self.retrieve(query).passages\\n13\\n14 return self.generate_answer(context=context, question=question)\\n15\\n16 multihop = BasicMultiHop(passages_per_hop=3)\\nCompiling For compilers, we continue to use the ones that we used for GSM8K (see Sec 6). We\\nalso consider two compositions of our teleprompters. For ReAct, we consider bootstrapping with\\nBootstrapFewShotWithRandomSearch starting from an earlier bootstrap of the ReAct program.\\nFor the simple multihop program, we also consider fine-tuning with T5-Large starting from the\\nearlier bootstrap of that program.\\n1 multihop_t5 = dspy.BootstrapFinetune(metric=answer_exact_match).compile(program,\\nteacher=bootstrap, trainset=trainset, target=’t5-large’)\\nResults Table 2 summarizes our results. Compared with the vanillafew-shot prompting, a chain-\\nof-thought and retrieval-augmented generation ( CoT RAG) program can self-bootstrap in DSPy to\\nincrease answer EM substantially. However, this relies entirely on the ColBERTv2 retriever to find\\nrelevant passages directly from the original questions, limiting its passage recall. This is tackled in\\nthe reactand multihopprograms, which will generate queries for the retriever in multiple iterative\\n“hops”. Indeed, overall, a simple multihop program performs the best, and in general bootstrap\\nagain proves to be very effective at raising its quality relative to itsfewshot variant for both LMs.\\nIn particular, we can see that bootstrap (and/or bootstrap×2) can outperform both fewshot\\nprompting (for multihop) and expert human reasoning (for react; adapted slightly from Yao et al.\\n(2022) to our retrieval setting). Perhaps most importantly, we can makellama2-13b-chatcompet-\\nitive with GPT-3.5 by simply compiling our programs.\\nTo assess the finetuning capacity of DSPy, we also evaluated the compiler multihop t5 defined\\nabove which produces a T5-Large (770M parameter) model. This program scores 39.3% answer\\nEM and 46.0% passage accuracy on the dev set, using only 200 labeled inputs and 800 unlabeled\\n10', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='59c1c39f-921a-4aea-b95b-b40a336a80f1', embedding=None, metadata={'page_label': '11', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nTable 2: Results with in-context learning on HotPotQA multi-hop retrieval question answering. We\\nreport answer exact match (Ans) and pair-retrieval accuracy (Psg). Each row represents a separate\\npipeline: the module in the Program column is compiled against the examples in the Training set.\\nThe programs, compilers, and (small) training sets are defined in the main text. For HotPotQA, we\\nuse the training set (and not dev) directly for cross-validation. ∗The marked result is evaluated on\\n50% of our test set due to cost.\\nGPT-3.5 Llama2-13b-chat\\nProgram Compiler Dev Test Dev Test\\nAns Psg Ans Psg Ans Psg Ans Psg\\nvanilla fewshot 34.3 n/a 31.5 n/a 27.5 n/a 21.8 n/a\\nCoTRAG fewshot 36.4 36.0 29.8 34.4 34.5 36.0 28.0 34.4\\nbootstrap 42.3 36.0 – – 38.3 36.0 32.9 34.4\\nreact\\nnone 20.3 – – – 20.0 – – –\\n+humanr 33.0 – – – 28.3 – – –\\nbootstrap 31.0 – – – 24.7 – – –\\nbootstrap×2 39.0 – – – 40.0 – – –\\nmultihop\\nfewshot 36.9 38.3 31.2 40.8 34.7 32.0 31.3 30.8\\nbootstrap 48.7 47.0 39.6 43.8 42.0 48.3 36.4 43.5\\nensemble 54.7 – 45.6∗ – 50.0 – 41.0 –\\nquestions. For compiling, we use a teacher program consisting of an ensemble (union) of two\\nmultihop with llama2-13b-chat. Considering its extremely small size and local availability, this\\ncompiled program with T5-Largewould impose orders of magnitude lower costs for inference than\\na proprietary LM like GPT-3.5.\\nOur results may be pegged against the evaluation on HotPotQA in a number of recent papers, though\\nthere is significant variation in evaluation methodology and test set samples across studies in this\\nspace. Using CoT prompting, Si et al. (2022) achieve 25.2% EM. With a “recite-and-answer” tech-\\nnique that uses PaLM-62B (Chowdhery et al., 2022) to recite evidence passages, Sun et al. (2022)\\nachieve 26.5% EM. Wang et al. (2022a) achieve 33.8% EM and 44.6% F1 when applying self-\\nconsistency for PaLM-540B. Yao et al. (2022) achieve 27.4% EM using ReAct with PaLM-540B\\nand 30.8 with text-davinci-002, with a tool giving it the ability for search using a Wikipedia\\nAPI. They push their PaLM results to 35.1% EM by applying an additional CoT step with self-\\nconsistency, which may resemble our ensemble approach in the sense of aggregating multiple an-\\nswers. Trivedi et al. (2022) reports 49% using a pipeline with code-davinci-002 LM on a sample\\nof 500 HotPotQA questions.\\n8 C ONCLUSION\\nThis paper introduced DSPy, a new programming model for designing AI systems using pipelines\\nof pretrained LMs and other tools. We presented three new concepts introduced in this abstraction\\n(DSPy signatures, modules, and teleprompters), and showed in two very different case studies that\\nit supports rapid development of highly effective systems that use relatively small LMs. We have\\nmaintained open-source versions of this framework for close to a year. In this period, we have seen\\nand created a large number of programs that were compiled to high-quality systems by DSPy, span-\\nning tasks from information extraction to low-resource synthetic data generation. In the interest of\\nspace and to maintain reasonable scope in this paper, we leave reporting on such tasks under con-\\ntrolled experimental conditions to future work. While in-context learning has proved transformative\\nover the past 2–3 years of LM research, we argue that the true expressive power in this emerging\\nparadigm is in building sophisticated text transformation graphs in which composable modules and\\noptimizers (teleprompters) come together to leverage LMs in more systematic and reliable ways.\\nACKNOWLEDGMENTS\\nWe thank Josh Purtell for suggesting the apt name “text transformation graph” for the computational\\ngraph abstraction of DSPy. We thank Rick Battle, Igor Kotenkov, Lisa Li, David Hall, Ashwin\\nParanjape, Chris Manning, Percy Liang, and many researchers, developers, and users for valuable\\n11', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='679cd65b-6134-46ae-a4d9-7e298dce217e', embedding=None, metadata={'page_label': '12', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\ndiscussions and feedback. We thank Giuseppe Attanasio for his public LATEX GitHub-style Python\\ncode formatting gist.6\\nThis work was partially supported by IBM as a founding member of the Stanford Institute for\\nHuman-Centered Artificial Intelligence (HAI), Oracle, Virtusa, and Cigna Healthcare. It was also\\npartially supported by an HAI Azure compute grant. This research was supported in part by affiliate\\nmembers and other supporters of the Stanford DAWN project–Facebook, Google, and VMware—as\\nwell as the NSF under CAREER grant CNS-1651570. Any opinions, findings, and conclusions or\\nrecommendations expressed in this material are those of the authors and do not necessarily reflect\\nthe views of the National Science Foundation. Omar Khattab is supported by the Apple Scholars in\\nAI/ML fellowship.\\n\\\\usepackage[pdftex]{graphicx} ...\\n\\\\includegraphics[width=0.8\\\\linewidth]{myfile.pdf}\\nREFERENCES\\nTakuya Akiba, Shotaro Sano, Toshihiko Yanase, Takeru Ohta, and Masanori Koyama. Optuna:\\nA next-generation hyperparameter optimization framework. In Proceedings of the 25th ACM\\nSIGKDD international conference on knowledge discovery & data mining, pp. 2623–2631, 2019.\\nRami Al-Rfou, Guillaume Alain, Amjad Almahairi, Christof Angermueller, Dzmitry Bahdanau,\\nNicolas Ballas, Fr ´ed´eric Bastien, Justin Bayer, Anatoly Belikov, Alexander Belopolsky, et al.\\nTheano: A Python framework for fast computation of mathematical expressions. arXiv e-prints,\\npp. arXiv–1605, 2016.\\nJames Bergstra, Olivier Breuleux, Fr ´ed´eric Bastien, Pascal Lamblin, Razvan Pascanu, Guillaume\\nDesjardins, Joseph Turian, David Warde-Farley, and Yoshua Bengio. Theano: A CPU and GPU\\nmath compiler in Python. In Proc. 9th python in science conf, volume 1, pp. 3–10, 2010.\\nJames Bergstra, Fr ´ed´eric Bastien, Olivier Breuleux, Pascal Lamblin, Razvan Pascanu, Olivier De-\\nlalleau, Guillaume Desjardins, David Warde-Farley, Ian Goodfellow, Arnaud Bergeron, et al.\\nTheano: Deep learning on gpus with Python. In NIPS 2011, BigLearning Workshop, Granada,\\nSpain, volume 3. Citeseer, 2011.\\nJames Bergstra, Daniel Yamins, and David Cox. Making a science of model search: Hyperparameter\\noptimization in hundreds of dimensions for vision architectures. In International conference on\\nmachine learning, pp. 115–123. PMLR, 2013.\\nRishi Bommasani, Drew A Hudson, Ehsan Adeli, Russ Altman, Simran Arora, Sydney von Arx,\\nMichael S Bernstein, Jeannette Bohg, Antoine Bosselut, Emma Brunskill, et al. On the opportu-\\nnities and risks of foundation models. arXiv preprint arXiv:2108.07258, 2021.\\nTom Brown, Benjamin Mann, Nick Ryder, Melanie Subbiah, Jared D Kaplan, Prafulla Dhariwal,\\nArvind Neelakantan, Pranav Shyam, Girish Sastry, Amanda Askell, et al. Language models are\\nfew-shot learners. Advances in neural information processing systems, 33:1877–1901, 2020.\\nHarrison Chase. Hwchase17/langchain. 2022. URL https://github.com/hwchase17/\\nlangchain.\\nDanqi Chen, Adam Fisch, Jason Weston, and Antoine Bordes. Reading Wikipedia to answer\\nopen-domain questions. In Proceedings of the 55th Annual Meeting of the Association for\\nComputational Linguistics (Volume 1: Long Papers) , pp. 1870–1879, Vancouver, Canada, July\\n2017. Association for Computational Linguistics. doi: 10.18653/v1/P17-1171. URL https:\\n//aclanthology.org/P17-1171.\\nLingjiao Chen, Matei Zaharia, and James Zou. Frugalgpt: How to use large language models while\\nreducing cost and improving performance. arXiv preprint arXiv:2305.05176, 2023.\\n6https://gist.github.com/g8a9/07c2be12ae02cfad4aa430d77dc940cb\\n12', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='4e1e24ce-0d68-4132-bf41-f1d4bac152ad', embedding=None, metadata={'page_label': '13', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nWenhu Chen, Xueguang Ma, Xinyi Wang, and William W Cohen. Program of thoughts prompt-\\ning: Disentangling computation from reasoning for numerical reasoning tasks. arXiv preprint\\narXiv:2211.12588, 2022.\\nAakanksha Chowdhery, Sharan Narang, Jacob Devlin, Maarten Bosma, Gaurav Mishra, Adam\\nRoberts, Paul Barham, Hyung Won Chung, Charles Sutton, Sebastian Gehrmann, et al. Palm:\\nScaling language modeling with pathways. arXiv preprint arXiv:2204.02311, 2022.\\nKarl Cobbe, Vineet Kosaraju, Mohammad Bavarian, Mark Chen, Heewoo Jun, Lukasz Kaiser,\\nMatthias Plappert, Jerry Tworek, Jacob Hilton, Reiichiro Nakano, et al. Training verifiers to\\nsolve math word problems. arXiv preprint arXiv:2110.14168, 2021.\\nRonan Collobert, Samy Bengio, and Johnny Mari´ethoz. Torch: a modular machine learning software\\nlibrary. Technical report, Idiap, 2002.\\nDavid Dohan, Winnie Xu, Aitor Lewkowycz, Jacob Austin, David Bieber, Raphael Gontijo Lopes,\\nYuhuai Wu, Henryk Michalewski, Rif A Saurous, Jascha Sohl-Dickstein, et al. Language model\\ncascades. arXiv preprint arXiv:2207.10342, 2022.\\nLuyu Gao, Zhuyun Dai, Panupong Pasupat, Anthony Chen, Arun Tejasvi Chaganty, Yicheng Fan,\\nVincent Zhao, Ni Lao, Hongrae Lee, Da-Cheng Juan, et al. Rarr: Researching and revising what\\nlanguage models say, using language models. In Proceedings of the 61st Annual Meeting of the\\nAssociation for Computational Linguistics (Volume 1: Long Papers), pp. 16477–16508, 2023a.\\nLuyu Gao, Aman Madaan, Shuyan Zhou, Uri Alon, Pengfei Liu, Yiming Yang, Jamie Callan, and\\nGraham Neubig. Pal: Program-aided language models. In International Conference on Machine\\nLearning, pp. 10764–10799. PMLR, 2023b.\\nQingyan Guo, Rui Wang, Junliang Guo, Bei Li, Kaitao Song, Xu Tan, Guoqing Liu, Jiang Bian,\\nand Yujiu Yang. Connecting large language models with evolutionary algorithms yields powerful\\nprompt optimizers. arXiv preprint arXiv:2309.08532, 2023.\\nKelvin Guu, Kenton Lee, Zora Tung, Panupong Pasupat, and Ming-Wei Chang. Realm: Retrieval-\\naugmented language model pre-training. arXiv preprint arXiv:2002.08909, 2020. URL https:\\n//arxiv.org/abs/2002.08909.\\nBraden Hancock, Paroma Varma, Stephanie Wang, Martin Bringmann, Percy Liang, and Christopher\\nR´e. Training classifiers with natural language explanations. In Proceedings of the 56th Annual\\nMeeting of the Association for Computational Linguistics (Volume 1: Long Papers) , pp. 1884–\\n1895. Association for Computational Linguistics, 2018. URL http://aclweb.org/anthology/\\nP18-1175.\\nBin Hu, Chenyang Zhao, Pu Zhang, Zihao Zhou, Yuanhang Yang, Zenglin Xu, and Bin Liu. En-\\nabling intelligent interactions between an agent and an LLM: A reinforcement learning approach.\\narXiv preprint arXiv:2306.03604, 2023. URL https://arxiv.org/abs/2306.03604.\\nJiaxin Huang, Shixiang Shane Gu, Le Hou, Yuexin Wu, Xuezhi Wang, Hongkun Yu, and Jiawei\\nHan. Large language models can self-improve. arXiv preprint arXiv:2210.11610, 2022.\\nGautier Izacard, Patrick Lewis, Maria Lomeli, Lucas Hosseini, Fabio Petroni, Timo Schick, Jane\\nDwivedi-Yu, Armand Joulin, Sebastian Riedel, and Edouard Grave. Few-shot learning with re-\\ntrieval augmented language models. arXiv preprint arXiv:2208.03299, 2022.\\nEhud Karpas, Omri Abend, Yonatan Belinkov, Barak Lenz, Opher Lieber, Nir Ratner, Yoav Shoham,\\nHofit Bata, Yoav Levine, Kevin Leyton-Brown, et al. Mrkl systems: A modular, neuro-symbolic\\narchitecture that combines large language models, external knowledge sources and discrete rea-\\nsoning. arXiv preprint arXiv:2205.00445, 2022.\\nOmar Khattab, Christopher Potts, and Matei Zaharia. Baleen: Robust Multi-Hop Reasoning at Scale\\nvia Condensed Retrieval. In Thirty-Fifth Conference on Neural Information Processing Systems,\\n2021a.\\nOmar Khattab, Christopher Potts, and Matei Zaharia. Relevance-guided supervision for openqa with\\nColBERT. Transactions of the Association for Computational Linguistics, 9:929–944, 2021b.\\n13', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9f16210f-a902-4028-af84-6951ee50b0f0', embedding=None, metadata={'page_label': '14', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text=\"Preprint\\nOmar Khattab, Keshav Santhanam, Xiang Lisa Li, David Hall, Percy Liang, Christopher Potts,\\nand Matei Zaharia. Demonstrate-search-predict: Composing retrieval and language models for\\nknowledge-intensive nlp. arXiv preprint arXiv:2212.14024, 2022.\\nTushar Khot, Harsh Trivedi, Matthew Finlayson, Yao Fu, Kyle Richardson, Peter Clark, and Ashish\\nSabharwal. Decomposed prompting: A modular approach for solving complex tasks. arXiv\\npreprint arXiv:2210.02406, 2022.\\nTakeshi Kojima, Shixiang Shane Gu, Machel Reid, Yutaka Matsuo, and Yusuke Iwasawa. Large\\nlanguage models are zero-shot reasoners. arXiv preprint arXiv:2205.11916, 2022.\\nAngeliki Lazaridou, Elena Gribovskaya, Wojciech Stokowiec, and Nikolai Grigorev. Internet-\\naugmented language models through few-shot prompting for open-domain question answering.\\narXiv preprint arXiv:2203.05115, 2022.\\nPatrick Lewis, Ethan Perez, Aleksandra Piktus, Fabio Petroni, Vladimir Karpukhin, Na-\\nman Goyal, Heinrich K ¨uttler, Mike Lewis, Wen-tau Yih, Tim Rockt ¨aschel, Sebastian\\nRiedel, and Douwe Kiela. Retrieval-augmented generation for knowledge-intensive nlp\\ntasks. In H. Larochelle, M. Ranzato, R. Hadsell, M.F. Balcan, and H. Lin (eds.), Ad-\\nvances in Neural Information Processing Systems , volume 33, pp. 9459–9474. Curran Asso-\\nciates, Inc., 2020. URLhttps://proceedings.neurips.cc/paper files/paper/2020/file/\\n6b493230205f780e1bc26945df7481e5-Paper.pdf.\\nJerry Liu. LlamaIndex, 11 2022. URL https://github.com/jerryjliu/llama index.\\nAman Madaan, Niket Tandon, Prakhar Gupta, Skyler Hallinan, Luyu Gao, Sarah Wiegreffe, Uri\\nAlon, Nouha Dziri, Shrimai Prabhumoye, Yiming Yang, et al. Self-refine: Iterative refinement\\nwith self-feedback. arXiv preprint arXiv:2303.17651, 2023.\\nBryan McCann, Nitish Shirish Keskar, Caiming Xiong, and Richard Socher. The natural language\\ndecathlon: Multitask learning as question answering. arXiv:1806.08730, 2018. URL https:\\n//arxiv.org/abs/1806.08730.\\nMicrosoft. Semantic kernel. 2023. URL https://learn.microsoft.com/semantic-kernel/.\\nReiichiro Nakano, Jacob Hilton, Suchir Balaji, Jeff Wu, Long Ouyang, Christina Kim, Christo-\\npher Hesse, Shantanu Jain, Vineet Kosaraju, William Saunders, Xu Jiang, Karl Cobbe, Tyna\\nEloundou, Gretchen Krueger, Kevin Button, Matthew Knight, Benjamin Chess, and John Schul-\\nman. WebGPT: Browser-assisted question-answering with human feedback, 2021. URL https:\\n//arxiv.org/abs/2112.09332.\\nOpenAI. Gpt-4 technical report, 2023.\\nLong Ouyang, Jeff Wu, Xu Jiang, Diogo Almeida, Carroll L Wainwright, Pamela Mishkin, Chong\\nZhang, Sandhini Agarwal, Katarina Slama, Alex Ray, et al. Training language models to follow\\ninstructions with human feedback. arXiv preprint arXiv:2203.02155, 2022.\\nAdam Paszke, Sam Gross, Francisco Massa, Adam Lerer, James Bradbury, Gregory Chanan, Trevor\\nKilleen, Zeming Lin, Natalia Gimelshein, Luca Antiga, Alban Desmaison, Andreas Kopf, Edward\\nYang, Zachary DeVito, Martin Raison, Alykhan Tejani, Sasank Chilamkurthy, Benoit Steiner,\\nLu Fang, Junjie Bai, and Soumith Chintala. PyTorch: An imperative style, high-performance\\ndeep learning library. In H. Wallach, H. Larochelle, A. Beygelzimer, F. d'Alch ´e-Buc, E. Fox,\\nand R. Garnett (eds.), Advances in Neural Information Processing Systems , volume 32. Curran\\nAssociates, Inc., 2019. URL https://proceedings.neurips.cc/paper files/paper/2019/\\nfile/bdbca288fee7f92f2bfa9f7012727740-Paper.pdf.\\nMohammadreza Pourreza and Davood Rafiei. Din-sql: Decomposed in-context learning of text-to-\\nsql with self-correction. arXiv preprint arXiv:2304.11015, 2023.\\nOfir Press, Muru Zhang, Sewon Min, Ludwig Schmidt, Noah A Smith, and Mike Lewis. Measuring\\nand narrowing the compositionality gap in language models. arXiv preprint arXiv:2210.03350,\\n2022.\\n14\", path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='f60bd093-c646-4642-aa11-b7f1cd86c865', embedding=None, metadata={'page_label': '15', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nReid Pryzant, Dan Iter, Jerry Li, Yin Tat Lee, Chenguang Zhu, and Michael Zeng. Automatic prompt\\noptimization with” gradient descent” and beam search. arXiv preprint arXiv:2305.03495, 2023.\\nPeng Qi, Xiaowen Lin, Leo Mehr, Zijian Wang, and Christopher D. Manning. Answering complex\\nopen-domain questions through iterative query generation. In Proceedings of the 2019 Con-\\nference on Empirical Methods in Natural Language Processing and the 9th International Joint\\nConference on Natural Language Processing (EMNLP-IJCNLP) , pp. 2590–2602, Hong Kong,\\nChina, 2019. Association for Computational Linguistics. doi: 10.18653/v1/D19-1261. URL\\nhttps://aclanthology.org/D19-1261.\\nPeng Qi, Haejun Lee, Oghenetegiri Sido, Christopher D Manning, et al. Retrieve, rerank, read,\\nthen iterate: Answering open-domain questions of arbitrary complexity from text. arXiv preprint\\narXiv:2010.12527, 2020. URL https://arxiv.org/abs/2010.12527.\\nAlec Radford, Karthik Narasimhan, Tim Salimans, and Ilya Sutskever. Improving language un-\\nderstanding by generative pre-training. Ms, OpenAI, 2018. URL https://openai.com/blog/\\nlanguage-unsupervised/.\\nAlexander J Ratner, Christopher M De Sa, Sen Wu, Daniel Selsam, and Christopher R ´e. Data\\nprogramming: Creating large training sets, quickly. In D. D. Lee, M. Sugiyama, U. V .\\nLuxburg, I. Guyon, and R. Garnett (eds.), Advances in Neural Information Processing Systems\\n29, pp. 3567–3575. Curran Associates, Inc., 2016. URL https://papers.nips.cc/paper/\\n6523-data-programming-creating-large-training-sets-quickly .\\nKeshav Santhanam, Omar Khattab, Jon Saad-Falcon, Christopher Potts, and Matei Zaharia. Col-\\nBERTv2: Effective and Efficient Retrieval via Lightweight Late Interaction. arXiv preprint\\narXiv:2112.01488, 2021.\\nTimo Schick, Jane Dwivedi-Yu, Roberto Dess`ı, Roberta Raileanu, Maria Lomeli, Luke Zettlemoyer,\\nNicola Cancedda, and Thomas Scialom. Toolformer: Language models can teach themselves to\\nuse tools. arXiv preprint arXiv:2302.04761, 2023.\\nZhihong Shao, Yeyun Gong, Yelong Shen, Minlie Huang, Nan Duan, and Weizhu Chen. Syn-\\nthetic prompting: Generating chain-of-thought demonstrations for large language models. arXiv\\npreprint arXiv:2302.00618, 2023.\\nNoah Shinn, Beck Labash, and Ashwin Gopinath. Reflexion: an autonomous agent with dynamic\\nmemory and self-reflection. arXiv preprint arXiv:2303.11366, 2023.\\nChenglei Si, Zhe Gan, Zhengyuan Yang, Shuohang Wang, Jianfeng Wang, Jordan Boyd-Graber, and\\nLijuan Wang. Prompting gpt-3 to be reliable. arXiv preprint arXiv:2210.09150, 2022.\\nZhiqing Sun, Xuezhi Wang, Yi Tay, Yiming Yang, and Denny Zhou. Recitation-augmented language\\nmodels. arXiv preprint arXiv:2210.01296, 2022.\\nSeiya Tokui, Kenta Oono, Shohei Hido, and Justin Clayton. Chainer: a next-generation open source\\nframework for deep learning. In Proceedings of workshop on machine learning systems (Learn-\\ningSys) in the twenty-ninth annual conference on neural information processing systems (NIPS) ,\\nvolume 5, pp. 1–6, 2015.\\nHugo Touvron, Louis Martin, Kevin Stone, Peter Albert, Amjad Almahairi, Yasmine Babaei, Niko-\\nlay Bashlykov, Soumya Batra, Prajjwal Bhargava, Shruti Bhosale, et al. Llama 2: Open founda-\\ntion and fine-tuned chat models. arXiv preprint arXiv:2307.09288, 2023.\\nHarsh Trivedi, Niranjan Balasubramanian, Tushar Khot, and Ashish Sabharwal. Interleaving re-\\ntrieval with chain-of-thought reasoning for knowledge-intensive multi-step questions. arXiv\\npreprint arXiv:2212.10509, 2022.\\nFei Wang, James Decker, Xilun Wu, Gregory Essertel, and Tiark Rompf. Backpropaga-\\ntion with callbacks: Foundations for efficient and expressive differentiable programming.\\nIn S. Bengio, H. Wallach, H. Larochelle, K. Grauman, N. Cesa-Bianchi, and R. Gar-\\nnett (eds.), Advances in Neural Information Processing Systems , volume 31. Curran Asso-\\nciates, Inc., 2018. URLhttps://proceedings.neurips.cc/paper files/paper/2018/file/\\n34e157766f31db3d2099831d348a7933-Paper.pdf.\\n15', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='09e70d78-65f6-4377-acc6-cf79c3c358eb', embedding=None, metadata={'page_label': '16', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Rationale-\\naugmented ensembles in language models. arXiv preprint arXiv:2207.00747, 2022a.\\nXuezhi Wang, Jason Wei, Dale Schuurmans, Quoc Le, Ed Chi, and Denny Zhou. Self-consistency\\nimproves chain of thought reasoning in language models. arXiv preprint arXiv:2203.11171 ,\\n2022b.\\nJason Wei, Xuezhi Wang, Dale Schuurmans, Maarten Bosma, Ed Chi, Quoc Le, and Denny\\nZhou. Chain of thought prompting elicits reasoning in large language models. arXiv preprint\\narXiv:2201.11903, 2022.\\nThomas Wolf, Lysandre Debut, Victor Sanh, Julien Chaumond, Clement Delangue, Anthony Moi,\\nPierric Cistac, Tim Rault, Remi Louf, Morgan Funtowicz, Joe Davison, Sam Shleifer, Patrick\\nvon Platen, Clara Ma, Yacine Jernite, Julien Plu, Canwen Xu, Teven Le Scao, Sylvain Gug-\\nger, Mariama Drame, Quentin Lhoest, and Alexander Rush. Transformers: State-of-the-art\\nnatural language processing. In Proceedings of the 2020 Conference on Empirical Methods\\nin Natural Language Processing: System Demonstrations , pp. 38–45, Online, 2020. Associ-\\nation for Computational Linguistics. doi: 10.18653/v1/2020.emnlp-demos.6. URL https:\\n//aclanthology.org/2020.emnlp-demos.6.\\nChengrun Yang, Xuezhi Wang, Yifeng Lu, Hanxiao Liu, Quoc V Le, Denny Zhou, and Xinyun\\nChen. Large language models as optimizers. arXiv preprint arXiv:2309.03409, 2023.\\nZhilin Yang, Peng Qi, Saizheng Zhang, Yoshua Bengio, William W Cohen, Ruslan Salakhutdinov,\\nand Christopher D Manning. Hotpotqa: A dataset for diverse, explainable multi-hop question\\nanswering. arXiv preprint arXiv:1809.09600, 2018.\\nShunyu Yao, Jeffrey Zhao, Dian Yu, Nan Du, Izhak Shafran, Karthik Narasimhan, and Yuan Cao.\\nReact: Synergizing reasoning and acting in language models. arXiv preprint arXiv:2210.03629,\\n2022.\\nOri Yoran, Tomer Wolfson, Ben Bogin, Uri Katz, Daniel Deutch, and Jonathan Berant. Answering\\nquestions by meta-reasoning over multiple chains of thought. arXiv preprint arXiv:2304.13007,\\n2023.\\nEric Zelikman, Yuhuai Wu, and Noah D Goodman. Star: Bootstrapping reasoning with reasoning.\\narXiv preprint arXiv:2203.14465, 2022.\\nZhuosheng Zhang, Aston Zhang, Mu Li, and Alex Smola. Automatic chain of thought prompting in\\nlarge language models. arXiv preprint arXiv:2210.03493, 2022.\\nAndrew Zhao, Daniel Huang, Quentin Xu, Matthieu Lin, Yong-Jin Liu, and Gao Huang. ExpeL:\\nLLM agents are experiential learners. arXiv preprint arXiv:2308.10144 , 2023a. URL https:\\n//arxiv.org/pdf/2308.10144.\\nXu Zhao, Yuxi Xie, Kenji Kawaguchi, Junxian He, and Qizhe Xie. Automatic model selection with\\nlarge language models for reasoning. arXiv preprint arXiv:2305.14333, 2023b.\\n16', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='18e61b98-4b92-4c52-b952-cc7b2aaaa1f1', embedding=None, metadata={'page_label': '17', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nA A DVANCED SIGNATURES\\nWhen more control is desired, one can express signatures as Python classes to provide explicit\\ninstructions of the transformation and describe the format or role of each field more directly. For\\ninstance, the following signature generates search queries using context and an optional question:\\n1 class GenerateSearchQuery(dspy.Signature):\\n2 \"\"\"Write a simple search query that will help answer a complex question.\"\"\"\\n3\\n4 context = dspy.InputField(desc=\"may contain relevant facts\")\\n5 question = dspy.InputField()\\n6 query = dspy.OutputField(dtype=dspy.SearchQuery)\\nUsing the above, we can specify a complete system for the generation of a synthetic IR dataset where\\nthe queries are mediated by a question generated by the LM:\\n1 query_gen = dspy.Predict(GenerateSearchQuery)\\n2 query_gen(context=\"Language typology\")\\n3 # Out: Prediction(question=’What are the main types of language classification?’,\\nquery=’\"language classification\" OR \"language typology\" -wikipedia’)\\nIf questions are available, they can be supplied as shown: query gen(context=\"Language\\ntypology\", question=\"What are the primary language families of South America?\").\\nAs a work in progress feature, users can optionally specify the type of output fields as bool, int,\\nfloat, list, or dict instead of the default free-form string type, as in contexts, question ->\\nanswer found: bool.\\nB C OMPARISON WITH EXISTING LIBRARIES LIKE LANG CHAIN AND\\nLLAMA INDEX\\nLangChain and LlamaIndex are perhaps the most popular library in the general space of prompting\\nLMs. These libraries have a different focus compared to DSPy and they suffer internally from the\\nprompt engineering challenges that DSPy aims to resolve. In particular, whereas the goal of DSPy\\nis to tackle the fundamental challenges of prompt engineering for building new LM computational\\ngraphs, LangChain and LlamaIndex generally help application developers who need pre-packaged\\ncomponents and chains, e.g., implementations of popular and reusable pipelines (e.g., particular\\nagents and specific retrieval pipelines) and tools (e.g., connections to various databases and imple-\\nmentations of long- and short-term memory for agents).\\nThese off-the-shelf higher-level abstractions contrast with DSPy’s focus on introducing core com-\\nposable operators. In particular, DSPy introduces signatures (to abstract prompts), modules (to\\nabstract prompting techniques), and teleprompters to act as optimizers for arbitrary imperative code\\n(DSPy programs) that chain modules together. Its goal is to help researchers and practitioners\\nbuild new LM pipelines quickly and achieve very high quality through automatic compilation (self-\\nimprovement) instead of manual prompt engineering.\\nIn contrast, typical existing research implementations and existing libraries like LangChain and\\nLlamaIndex are implemented using manual prompt engineering, which is the key problem that DSPy\\ntackles. We conducted an informal study to highlight this. In late September 2023, we found\\nthat the LangChain codebase contains 50 strings exceeding 1000 characters, which are generally\\nprompts, compared to none at all in DSPy. Indeed, a substantial number of LangChain’s Python\\nfiles are singularly dedicated to task-related templating and prompt engineering with 12prompts.py\\nfiles and and 42 prompt.py files. DSPy, on the other hand, provides a structured framework that\\nautomatically bootstraps prompts. The library itself does not contain a single hand-written prompt\\ndemonstration for any tasks at the time of writing, despite the very high quality with various LMs.\\nTo review the typical forms of prompt engineering in existing libraries, we consider the follow-\\ning in LangChain. The LangChain Program-Aided Language Model Gao et al. (2023a) chain pro-\\ngram uses few-shot learning, leveraging a template that is 3982 characters long with 8 math word\\nproblems (Prompt 2) and corresponding outputted programs as learning examples for the language\\nmodel. LangChain also contains a prompt for SQL query tasks for each of the databases like Or-\\nacle, GoogleSQL, DuckDB, Crate, and MySQL, with the average length of these prompts at 1058\\ncharacters. Other task areas such as QA with sources (Prompt B) and Graph QA also have signif-\\n17', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8c4cb196-d4fe-4804-a25c-a70d026729fa', embedding=None, metadata={'page_label': '18', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nicantly lengthy prompt templates, with averages of 1337 and 722 characters, respectively. While\\nexpert-written prompts can be useful, we believe that LM- and task-adaptive prompts bootstrapped\\nautomatically can offer far more power (and are far more modular) than hard-coding a prompt per\\ndatabase provider inside the code base. The next appendix section contains a number of prompts\\ncopied from related research papers and existing libraries.\\nC S AMPLE LARGE PROMPTS\\nThis section highlights a few popular existing frameworks that structure prompts with extensive\\nprompt engineering templates. The primary objective is to capture how many words and characters\\nare used for such large multi-line prompts defined for tasks or tools and present these example\\nprompts retrieved from open-sourced papers and repositories. The formatting of these example\\nprompts is adapted from Gao et al. (2023a).\\nTask/Tool Prompt Source Words Characters\\nPrompt 1: Text-evidence checker Gao et al. (2023a) 818 4964\\nPrompt 2: Math word problems (PAL) LangChain & Gao et al. (2023b) 566 3957\\nPrompt 3: ReAct Yao et al. (2022) 593 3889\\nPrompt 4: Zero-shot ReAct LangChain 101 600\\nPrompt 5: QA with sources LangChain 992 6197\\nPrompt 6: SQL MyScale querying LangChain 343 2239\\nPrompt 7: Relevant docs retrieval LlamaIndex 129 719\\nPrompt 8: IRS chatbot LlamaIndex 389 2258\\n18', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='e027d526-8f4d-4296-9b65-3256006d5cdd', embedding=None, metadata={'page_label': '19', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 [web] I will check some things you said.\\n2\\n3 (1) You said: Your nose switches back and forth between nostrils. When you sleep, you switch about every 45 minutes. This\\nis to prevent a buildup of mucus. It’s called the nasal cycle.\\n4 I checked: How often do your nostrils switch?\\n5 I found this article: Although we don’t usually notice it, during the nasal cycle one nostril becomes congested and thus\\ncontributes less to airflow, while the other becomes decongested. On average, the congestion pattern switches about every\\n2 hours, according to a small 2016 study published in the journal PLOS One.\\n6 Your nose’s switching time is about every 2 hours, not 45 minutes.\\n7 This disagrees with what you said.\\n8\\n9 (2) You said: The Little House books were written by Laura Ingalls Wilder. The books were published by HarperCollins.\\n10 I checked: Who published the Little House books?\\n11 I found this article: These are the books that started it all -- the stories that captured the hearts and imaginations of\\nchildren and young adults worldwide. Written by Laura Ingalls Wilder and published by HarperCollins, these beloved books\\nremain a favorite to this day.\\n12 The Little House books were published by HarperCollins.\\n13 This agrees with what you said.\\n14\\n15 (3) You said: The Stanford Prison Experiment was conducted in the basement of Jordan Hall, Stanford’s psychology building.\\n16 I checked: Where was Stanford Prison Experiment conducted?\\n17 I found this article: Carried out August 15-21, 1971 in the basement of Jordan Hall, the Stanford Prison Experiment set\\nout to examine the psychological effects of authority and powerlessness in a prison environment.\\n18 The Stanford Prison Experiment was conducted in Jordan Hall.\\n19 This agrees with what you said.\\n20\\n21 (4) You said: Social work is a profession that is based in the philosophical tradition of humanism. It is an intellectual\\ndiscipline that has its roots in the 1800s.\\n22 I checked: When did social work have its roots?\\n23 I found this article: The Emergence and Growth of the Social work Profession<br><br> Social work’s roots were planted in\\nthe 1880s, when charity organization societies (COS) were created to organize municipal voluntary relief associations and\\nsettlement houses were established.\\n24 Social work has its roots in the 1880s, not 1800s.\\n25 This disagrees with what you said.\\n26\\n27 (5) You said: The Havel-Hakimi algorithm is an algorithm for converting the adjacency matrix of a graph into its adjacency\\nlist. It is named after Vaclav Havel and Samih Hakimi.\\n28 I checked: What is the Havel-Hakimi algorithm?\\n29 I found this article: The Havel-Hakimi algorithm constructs a special solution if a simple graph for the given degree\\nsequence exists, or proves that one cannot find a positive answer. This construction is based on a recursive algorithm.\\nThe algorithm was published by Havel (1955), and later by Hakimi (1962).\\n30 Havel-Hakimi algorithm is for constructing a special solution if a simple graph for the given degree sequence exists, or\\nproving that one cannot find a positive answer, not converting the adjacency matrix of a graph into its adjacency list.\\n31 This disagrees with what you said.\\n32\\n33 (6) You said: \"Time of My Life\" is a song by American singer-songwriter Bill Medley from the soundtrack of the 1987 film\\nDirty Dancing. The song was produced by Michael Lloyd.\\n34 I checked: Who was the producer of \"(I’ve Had) The Time of My Life\"?\\n35 I found this article: On September 8, 2010, the original demo of this song, along with a remix by producer Michael Lloyd,\\nwas released as digital files in an effort to raise money for the Patrick Swayze Pancreas Cancer Resarch Foundation at\\nStanford University.\\n36 \"Time of My Life\" was produced by Michael Lloyd.\\n37 This agrees with what you said.\\n38\\n39 (7) You said: Kelvin Hopins was suspended from the Labor Party because he had allegedly sexually harassed and behaved\\ninappropriately towards a Labour Party activist, Ava Etemadzadeh.\\n40 I checked: Why was Kelvin Hopins suspeneded from the Labor Party?\\n41 I found this article: A former Labour MP has left the party before an inquiry into sexual harassment allegations against\\nhim was able to be concluded, the party has confirmed. Kelvin Hopkins was accused in 2017 of inappropriate physical contact\\nand was suspended by the Labour party pending an investigation.This agrees with what you said.\\n42 Kelvin Hopins was suspended because he had allegedly sexually harassed and behaved inappropriately towards a Labour Party\\nactivist, Ava Etemadzadeh.\\n43 This agrees with what you said.\\n44\\n45 (8) You said: In the battles of Lexington and Concord, the British side was led by General Thomas Smith.\\n46 I checked: Who led the British side in the battle of Lexington and Concord?\\n47 I found this article: Interesting Facts about the Battles of Lexington and Concord. The British were led by Lieutenant\\nColonel Francis Smith. There were 700 British regulars.\\n48 The British side was led by Lieutenant Colonel Francis Smith, not General Thomas Hall.\\n49 This disagrees with what you said.\\n50\\n51 (9) You said: {text}\\n52 I checked: {query}\\n53 I found this article: {evidence}\\n54\\nFigure 1: Example few-shot prompt using a reasoning chain for agreement model that identifies\\ninconsistencies between text and evidence (Gao et al., 2023a).\\n19', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='7406dd68-b9f0-4d6c-9d09-4c60329df6f7', embedding=None, metadata={'page_label': '20', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 Q: Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\\n2\\n3 # solution in Python:\\n4\\n5\\n6 def solution():\\n7 \"\"\"Olivia has $23. She bought five bagels for $3 each. How much money does she have left?\"\"\"\\n8 money initial = 23\\n9 bagels = 5\\n10 bagel cost = 3\\n11 money spent = bagels * bagel cost\\n12 money left = money initial - money spent\\n13 result = money left\\n14 return result\\n15\\n16\\n17\\n18\\n19\\n20 Q: Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls did he\\nhave at the end of wednesday?\\n21\\n22 # solution in Python:\\n23\\n24\\n25 def solution():\\n26 \"\"\"Michael had 58 golf balls. On tuesday, he lost 23 golf balls. On wednesday, he lost 2 more. How many golf balls\\ndid he have at the end of wednesday?\"\"\"\\n27 golf balls initial = 58\\n28 golf balls lost tuesday = 23\\n29 golf balls lost wednesday = 2\\n30 golf balls left = golf balls initial - golf balls lost tuesday - golf balls lost wednesday\\n31 result = golf balls left\\n32 return result\\n33\\n34\\n35\\n36\\n37\\n38 Q: There were nine computers in the server room. Five more computers were installed each day, from monday to thursday.\\nHow many computers are now in the server room?\\n39\\n40 # solution in Python:\\n41\\n42\\n43 def solution():\\n44 \"\"\"There were nine computers in the server room. Five more computers were installed each day, from monday to thursday.\\nHow many computers are now in the server room?\"\"\"\\n45 computers initial = 9\\n46 computers per day = 5\\n47 num days = 4\\n48 computers added = computers per day * num days\\n49 computers total = computers initial + computers added\\n50 result = computers total\\n51 return result\\n52\\n53\\n54\\n55\\n56\\n57 Q: Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\\n58\\n59 # solution in Python:\\n60\\n61\\n62 def solution():\\n63 \"\"\"Shawn has five toys. For Christmas, he got two toys each from his mom and dad. How many toys does he have now?\"\"\"\\n64 toys initial = 5\\n65 mom toys = 2\\n66 dad toys = 2\\n67 total received = mom toys + dad toys\\n68 total toys = toys initial + total received\\n69 result = total toys\\n70 return result\\n71\\n72\\n73\\n74\\n75\\n76 Q: Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give to\\nDenny?\\n77\\n78 # solution in Python:\\n79\\n80\\n81\\n20', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='9c2fc0b3-8e10-4c06-8bbd-e88269f4120c', embedding=None, metadata={'page_label': '21', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1\\n2\\n3\\n4 def solution():\\n5 \"\"\"Jason had 20 lollipops. He gave Denny some lollipops. Now Jason has 12 lollipops. How many lollipops did Jason give\\nto Denny?\"\"\"\\n6 jason lollipops initial = 20\\n7 jason lollipops after = 12\\n8 denny lollipops = jason lollipops initial - jason lollipops after\\n9 result = denny lollipops\\n10 return result\\n11\\n12\\n13\\n14\\n15\\n16 Q: Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\\n17\\n18 # solution in Python:\\n19\\n20 def solution():\\n21 \"\"\"Leah had 32 chocolates and her sister had 42. If they ate 35, how many pieces do they have left in total?\"\"\"\\n22 leah chocolates = 32\\n23 sister chocolates = 42\\n24 total chocolates = leah chocolates + sister chocolates\\n25 chocolates eaten = 35\\n26 chocolates left = total chocolates - chocolates eaten\\n27 result = chocolates left\\n28 return result\\n29\\n30\\n31\\n32\\n33\\n34 Q: If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\\n35\\n36 # solution in Python:\\n37\\n38\\n39 def solution():\\n40 \"\"\"If there are 3 cars in the parking lot and 2 more cars arrive, how many cars are in the parking lot?\"\"\"\\n41 cars initial = 3\\n42 cars arrived = 2\\n43 total cars = cars initial + cars arrived\\n44 result = total cars\\n45 return result\\n46\\n47\\n48\\n49\\n50\\n51 Q: There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will be\\n21 trees. How many trees did the grove workers plant today?\\n52\\n53 # solution in Python:\\n54\\n55\\n56 def solution():\\n57 \"\"\"There are 15 trees in the grove. Grove workers will plant trees in the grove today. After they are done, there will\\nbe 21 trees. How many trees did the grove workers plant today?\"\"\"\\n58 trees initial = 15\\n59 trees after = 21\\n60 trees added = trees after - trees initial\\n61 result = trees added\\n62 return result\\n63\\n64\\n65\\n66\\n67\\n68 Q: {question}\\n69\\n70 # solution in Python:\\nFigure 2: PAL example few-shot prompt for solving math questions by generating code.\\n21', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='92536b39-1aa2-429e-8e47-48ac1717d734', embedding=None, metadata={'page_label': '22', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 Solve a question answering task with interleaving Thought, Action, Observation steps. Thought can reason about the current\\nsituation, and Action can be three types:\\n2 (1) Search[entity], which searches the exact entity on Wikipedia and returns the first paragraph if it exists. If not, it\\nwill return some similar entities to search.\\n3 (2) Lookup[keyword], which returns the next sentence containing keyword in the current passage.\\n4 (3) Finish[answer], which returns the answer and finishes the task.\\n5 Here are some examples.\\n6 Question: What is the elevation range for the area that the eastern sector of the Colorado orogeny extends into?\\n7 Action 1: Search[Colorado orogeny]\\n8 Observation 1: The Colorado orogeny was an episode of mountain building (an orogeny) in Colorado and surrounding areas.\\n9 Action 2: Lookup[eastern sector]\\n10 Observation 2: (Result 1 / 1) The eastern sector extends into the High Plains and is called the Central Plains orogeny.\\n11 Action 3: Search[High Plains]\\n12 Observation 3: High Plains refers to one of two distinct land regions:\\n13 Action 4: Search[High Plains (United States)]\\n14 Observation 4: The High Plains are a subregion of the Great Plains. From east to west, the High Plains rise in elevation\\nfrom around 1,800 to 7,000 ft (550 to 2,130 m).[3]\\n15 Action 5: Finish[1,800 to 7,000 ft]\\n16 Question: Musician and satirist Allie Goertz wrote a song about the \"The Simpsons\" character Milhouse, who Matt Groening\\nnamed after who?\\n17 Action 1: Search[Milhouse]\\n18 Observation 1: Milhouse Mussolini Van Houten is a recurring character in the Fox animated television series The Simpsons\\nvoiced by Pamela Hayden and created by Matt Groening.\\n19 Action 2: Lookup[named after]\\n20 Observation 2: (Result 1 / 1) Milhouse was named after U.S. president Richard Nixon, whose middle name was Milhous.\\n21 Action 3: Finish[Richard Nixon]\\n22 Question: Which documentary is about Finnish rock groups, Adam Clayton Powell or The Saimaa Gesture?\\n23 Action 1: Search[Adam Clayton Powell]\\n24 Observation 1: Could not find [Adam Clayton Powell]. Similar: [’Adam Clayton Powell III’, ’Seventh Avenue (Manhattan)’,\\n’Adam Clayton Powell Jr. State Office Building’, ’Isabel Washington Powell’, ’Adam Powell’, ’Adam Clayton Powell (film)’,\\n’Giancarlo Esposito’].\\n25 Action 2: Search[Adam Clayton Powell (film)]\\n26 Observation 2: Adam Clayton Powell is a 1989 American documentary film directed by Richard Kilberg. The film is about the\\nrise and fall of influential African-American politician Adam Clayton Powell Jr.[3][4] It was later aired as part of the\\nPBS series The American Experience.\\n27 Action 3: Finish[The Saimaa Gesture]\\n28 Question: What profession does Nicholas Ray and Elia Kazan have in common?\\n29 Action 1: Search[Nicholas Ray]\\n30 Observation 1: Nicholas Ray (born Raymond Nicholas Kienzle Jr., August 7, 1911 { June 16, 1979) was an American film\\ndirector, screenwriter, and actor best known for the 1955 film Rebel Without a Cause.\\n31 Action 2: Search[Elia Kazan]\\n32 Observation 2: Elia Kazan was an American film and theatre director, producer, screenwriter and actor.\\n33 Action 3: Finish[director, screenwriter, actor]\\n34 Question: Which magazine was started first Arthur’s Magazine or First for Women?\\n35 Action 1: Search[Arthur’s Magazine]\\n36 Observation 1: Arthur’s Magazine (1844-1846) was an American literary periodical published in Philadelphia in the 19th\\ncentury.\\n37 Action 2: Search[First for Women]\\n38 Observation 2: First for Women is a woman’s magazine published by Bauer Media Group in the USA.[1] The magazine was started\\nin 1989.\\n39 Action 3: Finish[Arthur’s Magazine]\\n40 Question: Were Pavel Urysohn and Leonid Levin known for the same type of work?\\n41 Action 1: Search[Pavel Urysohn]\\n42 Observation 1: Pavel Samuilovich Urysohn (February 3, 1898 ˆa August 17, 1924) was a Soviet mathematician who is best known\\nfor his contributions in dimension theory.\\n43 Action 2: Search[Leonid Levin]\\n44 Observation 2: Leonid Anatolievich Levin is a Soviet-American mathematician and computer scientist.\\n45 Action 3: Finish[yes]\\nFigure 3: ReAct example prompt for interleaving Thought, Action, Observation steps.\\n22', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='8dc4d3ec-9eaf-46b5-b6b3-c4aee00fc705', embedding=None, metadata={'page_label': '23', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 Answer the following questions as best you can. You have access to the following tools:\\n2 Search: useful for when you need to answer questions about the world\\n3 Use the following format:\\n4 Question: the input question you must answer\\n5 Thought: you should always think about what to do\\n6 Action: the action to take, should be one of [Search]\\n7 Action Input: the input to the action\\n8 Observation: the result of the action\\n9 ... (this Thought/Action/Action Input/Observation can repeat N times)\\n10 Thought: I now know the final answer\\n11 Final Answer: the final answer to the original input question\\n12 Begin!\\n13 Question: {question}\\n14 Thought:\\nFigure 4: Langchain ReAct example prompt for interleaving Thought, Action, Observation steps.\\n23', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2390d2a3-0854-40ed-a79e-bcda50716dc4', embedding=None, metadata={'page_label': '24', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 Given the following extracted parts of a long document and a question, create a final answer with references (\"SOURCES\").\\n2 If you don’t know the answer, just say that you don’t know. Don’t try to make up an answer.\\n3 ALWAYS return a \"SOURCES\" part in your answer.\\n4\\n5 QUESTION: Which state/country’s law governs the interpretation of the contract?\\n6 =========\\n7 Content: This Agreement is governed by English law and the parties submit to the exclusive jurisdiction of the English\\ncourts in relation to any dispute (contractual or non-contractual) concerning this Agreement save that either party may\\napply to any court for an injunction or other relief to protect its Intellectual Property Rights.\\n8 Source: 28-pl\\n9 Content: No Waiver. Failure or delay in exercising any right or remedy under this Agreement shall not constitute a waiver\\nof such (or any other) right or remedy.\\n10 11.7 Severability. The invalidity, illegality or unenforceability of any term (or part of a term) of this Agreement shall\\nnot affect the continuation in force of the remainder of the term (if any) and this Agreement.\\n11 11.8 No Agency. Except as expressly stated otherwise, nothing in this Agreement shall create an agency, partnership or\\njoint venture of any kind between the parties.\\n12 11.9 No Third-Party Beneficiaries.\\n13 Source: 30-pl\\n14 Content: (b) if Google believes, in good faith, that the Distributor has violated or caused Google to violate any\\nAnti-Bribery Laws (as defined in Clause 8.5) or that such a violation is reasonably likely to occur,\\n15 Source: 4-pl\\n16 =========\\n17 FINAL ANSWER: This Agreement is governed by English law.\\n18 SOURCES: 28-pl\\n19\\n20 QUESTION: What did the president say about Michael Jackson?\\n21 =========\\n22 Content: Madam Speaker, Madam Vice President, our First Lady and Second Gentleman. Members of Congress and the Cabinet.\\nJustices of the Supreme Court. My fellow Americans.\\n23 Last year COVID-19 kept us apart. This year we are finally together again.\\n24 Tonight, we meet as Democrats Republicans and Independents. But most importantly as Americans.\\n25 With a duty to one another to the American people to the Constitution.\\n26 And with an unwavering resolve that freedom will always triumph over tyranny.\\n27 Six days ago, Russia’s Vladimir Putin sought to shake the foundations of the free world thinking he could make it bend to\\nhis menacing ways. But he badly miscalculated.\\n28 He thought he could roll into Ukraine and the world would roll over. Instead he met a wall of strength he never imagined.\\n29 He met the Ukrainian people.\\n30 From President Zelenskyy to every Ukrainian, their fearlessness, their courage, their determination, inspires the world.\\n31 Groups of citizens blocking tanks with their bodies. Everyone from students to retirees teachers turned soldiers defending\\ntheir homeland.\\n32 Source: 0-pl\\n33 Content: And we won’t stop.\\n34 We have lost so much to COVID-19. Time with one another. And worst of all, so much loss of life.\\n35 Let’s use this moment to reset. Let’s stop looking at COVID-19 as a partisan dividing line and see it for what it is: A\\nGod-awful disease.\\n36 Let’s stop seeing each other as enemies, and start seeing each other for who we really are: Fellow Americans.\\n37 We can’t change how divided we’ve been. But we can change how we move forward|on COVID-19 and other issues we must face\\ntogether.\\n38 I recently visited the New York City Police Department days after the funerals of Officer Wilbert Mora and his partner,\\nOfficer Jason Rivera.\\n39 They were responding to a 9-1-1 call when a man shot and killed them with a stolen gun.\\n40 Officer Mora was 27 years old.\\n41 Officer Rivera was 22.\\n42 Both Dominican Americans who’d grown up on the same streets they later chose to patrol as police officers.\\n43 I spoke with their families and told them that we are forever in debt for their sacrifice, and we will carry on their\\nmission to restore the trust and safety every community deserves.\\n44 Source: 24-pl\\n45 Content: And a proud Ukrainian people, who have known 30 years of independence, have repeatedly shown that they will not\\ntolerate anyone who tries to take their country backwards.\\n46 To all Americans, I will be honest with you, as I’ve always promised. A Russian dictator, invading a foreign country, has\\ncosts around the world.\\n47 And I’m taking robust action to make sure the pain of our sanctions is targeted at Russia’s economy. And I will use every\\ntool at our disposal to protect American businesses and consumers.\\n48 Tonight, I can announce that the United States has worked with 30 other countries to release 60 Million barrels of oil\\nfrom reserves around the world.\\n49 America will lead that effort, releasing 30 Million barrels from our own Strategic Petroleum Reserve. And we stand ready\\nto do more if necessary, unified with our allies.\\n50 These steps will help blunt gas prices here at home. And I know the news about what’s happening can seem alarming.\\n51 But I want you to know that we are going to be okay.\\n52 Source: 5-pl\\n53 Content: More support for patients and families.\\n54 To get there, I call on Congress to fund ARPA-H, the Advanced Research Projects Agency for Health.\\n55 It’s based on DARPA|the Defense Department project that led to the Internet, GPS, and so much more.\\n56 ARPA-H will have a singular purpose|to drive breakthroughs in cancer, Alzheimer’s, diabetes, and more.\\n24', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ea111861-33e3-4ec5-b592-b230dfa44b35', embedding=None, metadata={'page_label': '25', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 A unity agenda for the nation.\\n2 We can do this.\\n3 My fellow Americans|tonight , we have gathered in a sacred space|the citadel of our democracy.\\n4 In this Capitol, generation after generation, Americans have debated great questions amid great strife, and have done\\ngreat things.\\n5 We have fought for freedom, expanded liberty, defeated totalitarianism and terror.\\n6 And built the strongest, freest, and most prosperous nation the world has ever known.\\n7 Now is the hour.\\n8 Our moment of responsibility.\\n9 Our test of resolve and conscience, of history itself.\\n10 It is in this moment that our character is formed. Our purpose is found. Our future is forged.\\n11 Well I know this nation.\\n12 Source: 34-pl\\n13 =========\\n14 FINAL ANSWER: The president did not mention Michael Jackson.\\n15 SOURCES:\\n16\\n17 QUESTION: {question}\\n18 =========\\n19 {summaries}\\n20 =========\\n21 FINAL ANSWER:\\nFigure 5: Langchain example prompt for QA with sources.\\n1 You are a MyScale expert. Given an input question, first create a syntactically correct MyScale query to run, then look\\nat the results of the query and return the answer to the input question.\\n2 MyScale queries has a vector distance function called DISTANCE(column, array) to compute relevance to the user’s question\\nand sort the feature array column by the relevance.\\n3 When the query is asking for {top k} closest row, you have to use this distance function to calculate distance to entity’s\\narray on vector column and order by the distance to retrieve relevant rows.\\n4 *NOTICE*: DISTANCE(column, array) only accept an array column as its first argument and a NeuralArray(entity) as its second\\nargument. You also need a user defined function called NeuralArray(entity) to retrieve the entity’s array.\\n5 Unless the user specifies in the question a specific number of examples to obtain, query for at most {top k} results using\\nthe LIMIT clause as per MyScale. You should only order according to the distance function.\\n6 Never query for all columns from a table. You must query only the columns that are needed to answer the question. Wrap\\neach column name in double quotes (\") to denote them as delimited identifiers.\\n7 Pay attention to use only the column names you can see in the tables below. Be careful to not query for columns that do\\nnot exist. Also, pay attention to which column is in which table.\\n8 Pay attention to use today() function to get the current date, if the question involves \"today\". ORDER BY clause should\\nalways be after WHERE clause. DO NOT add semicolon to the end of SQL. Pay attention to the comment in table schema.\\n9\\n10 Use the following format:\\n11 ======== table info ========\\n12 {table info}\\n13 Question: {input}\\n14 SQLQuery:\\n15\\n16 Here are some examples:\\n17 ======== table info ========\\n18 CREATE TABLE \"ChatPaper\" (\\n19 abstract String,\\n20 id String,\\n21 vector Array(Float32),\\n22 ) ENGINE = ReplicatedReplacingMergeTree()\\n23 ORDER BY id\\n24 PRIMARY KEY id\\n25 Question: What is Feature Pyramid Network?\\n26 SQLQuery: SELECT ChatPaper.title, ChatPaper.id, ChatPaper.authors FROM ChatPaper ORDER BY DISTANCE(vector,\\nNeuralArray(PaperRank contribution)) LIMIT {top k}\\n27\\n28 Let’s begin:\\n29 ======== table info ========\\n30 {table info}\\n31 Question: {input}\\n32 SQLQuery:\\nFigure 6: Langchain example prompt for SQL querying using MyScale.\\n25', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='00531e84-3dcd-433d-badf-2eed6160de9a', embedding=None, metadata={'page_label': '26', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 A list of documents is shown below. Each document has a number next to it along with a summary of the document. A question\\nis also provided.\\n2 Respond with the numbers of the documents you should consult to answer the question, in order of relevance, as well as the\\nrelevance score.\\n3 The relevance score is a number from 1-10 based on how relevant you think the document is to the question.\\n4 Do not include any documents that are not relevant to the question.\\n5\\n6 Example format:\\n7 Document 1:\\n8 <summary of document 1>\\n9\\n10 Document 2:\\n11 <summary of document 2>\\n12\\n13 ...\\n14\\n15 Document 10:\\n16 <summary of document 10>\\n17\\n18 Question: <question>\\n19 Answer:\\n20 Doc: 9, Relevance: 7\\n21 Doc: 3, Relevance: 4\\n22 Doc: 7, Relevance: 3\\n23\\n24 Let’s try this now:\\n25 {context str}\\n26 Question: {query str}\\n27 Answer:\\nFigure 7: LlamaIndex example prompt for returning relevant documents and corresponding sum-\\nmaries.\\n1 You are an IRS chatbot whose primary goal is to help users with filing their tax returns for the 2022 year.\\n2 Provide concise replies that are polite and professional.\\n3 Answer questions truthfully based on official government information, with consideration to context provided below on\\nchanges for 2022 that can affect tax refund.\\n4 Do not answer questions that are not related to United States tax procedures and respond with \"I can only help with any\\ntax-related questions you may have.\".\\n5 If you do not know the answer to a question, respond by saying \\\\I do not know the answer to your question. You may be able\\nto find your answer at www.irs.gov/faqs\"\\n6\\n7 Changes for 2022 that can affect tax refund:\\n8 Changes in the number of dependents, employment or self-employment income and divorce, among other factors, may affect\\nyour tax-filing status and refund. No additional stimulus payments. Unlike 2020 and 2021, there were no new stimulus\\npayments for 2022 so taxpayers should not expect to get an additional payment.\\n9 Some tax credits return to 2019 levels. This means that taxpayers will likely receive a significantly smaller refund\\ncompared with the previous tax year. Changes include amounts for the Child Tax Credit (CTC), the Earned Income Tax Credit\\n(EITC) and the Child and Dependent Care Credit will revert to pre-COVID levels.\\n10 For 2022, the CTC is worth $2,000 for each qualifying child. A child must be under age 17 at the end of 2022 to be a\\nqualifying child. For the EITC, eligible taxpayers with no children will get $560 for the 2022 tax year. The Child and\\nDependent Care Credit returns to a maximum of $2,100 in 2022.\\n11 No above-the-line charitable deductions. During COVID, taxpayers were able to take up to a $600 charitable donation tax\\ndeduction on their tax returns. However, for tax year 2022, taxpayers who don’t itemize and who take the standard deduction,\\nwon’t be able to deduct their charitable contributions.\\n12 More people may be eligible for the Premium Tax Credit. For tax year 2022, taxpayers may qualify for temporarily expanded\\neligibility for the premium tax credit.\\n13 Eligibility rules changed to claim a tax credit for clean vehicles. Review the changes under the Inflation Reduction Act\\nof 2022 to qualify for a Clean Vehicle Credit.\\nFigure 8: LlamaIndex example prompt for IRS chatbot guidelines.\\n26', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='b3aa86a0-04d3-465d-8836-1db7e3fb6f6c', embedding=None, metadata={'page_label': '27', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nD M ODULES\\nD.1 P REDICT\\n1 class Predict(dspy.Module):\\n2 def __init__(self, signature, **config):\\n3 self.signature = dspy.Signature(signature)\\n4 self.config = config\\n5\\n6 # Module Parameters.\\n7 self.lm = dspy.ParameterLM(None) # use the default LM\\n8 self.demonstrations = dspy.ParameterDemonstrations([])\\n9\\n10 def forward(self, **kwargs):\\n11 lm = get_the_right_lm(self.lm, kwargs)\\n12 signature = get_the_right_signature(self.signature, kwargs)\\n13 demonstrations = get_the_right_demonstrations(self.demonstrations, kwargs)\\n14\\n15 prompt = signature(demos=self.demos, **kwargs)\\n16 completions = lm.generate(prompt, **self.config)\\n17 prediction = Prediction.from_completions(completions, signature=signature)\\n18\\n19 if dsp.settings.compiling is not None:\\n20 trace = dict(predictor=self, inputs=kwargs, outputs=prediction)\\n21 dspy.settings.traces.append(trace)\\n22\\n23 return prediction\\nD.2 C HAIN OF THOUGHT\\n1 class ChainOfThought(dspy.Module):\\n2 def __init__(self, signature):\\n3\\n4 # Modify signature from ‘*inputs -> *outputs‘ to ‘*inputs -> rationale, *outputs‘.\\n5 rationale_field = dspy.OutputField(prefix=\"Reasoning: Let’s think step by step.\")\\n6 signature = dspy.Signature(signature).prepend_output_field(rationale_field)\\n7\\n8 # Declare a sub-module with the modified signature.\\n9 self.predict = dspy.Predict(self.signature)\\n10\\n11 def forward(self, **kwargs):\\n12 # Just forward the inputs to the sub-module.\\n13 return self.predict(**kwargs)\\n27', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c8ee365e-5900-4aee-9827-2cd2f8dac14f', embedding=None, metadata={'page_label': '28', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nE T ELEPROMPTERS\\nE.1 B OOTSTRAP FEWSHOT\\n1 class SimplifiedBootstrapFewShot(Teleprompter):\\n2 def __init__(self, metric=None):\\n3 self.metric = metric\\n4\\n5 def compile(self, student, trainset, teacher=None):\\n6 teacher = teacher if teacher is not None else student\\n7 compiled_program = student.deepcopy()\\n8\\n9 # Step 1. Prepare mappings between student and teacher Predict modules.\\n10 # Note: other modules will rely on Predict internally.\\n11 assert student_and_teacher_have_compatible_predict_modules(student, teacher)\\n12 name2predictor, predictor2name = map_predictors_recursively(student, teacher)\\n13\\n14 # Step 2. Bootstrap traces for each Predict module.\\n15 # We’ll loop over the training set. We’ll try each example once for simplicity.\\n16 for example in trainset:\\n17 if we_found_enough_bootstrapped_demos(): break\\n18\\n19 # turn on compiling mode which will allow us to keep track of the traces\\n20 with dspy.setting.context(compiling=True):\\n21 # run the teacher program on the example, and get its final prediction\\n22 # note that compiling=True may affect the internal behavior here\\n23 prediction = teacher(**example.inputs())\\n24\\n25 # get the trace of the all interal Predict calls from teacher program\\n26 predicted_traces = dspy.settings.trace\\n27\\n28 # if the prediction is valid, add the example to the traces\\n29 if self.metric(example, prediction, predicted_traces):\\n30 for predictor, inputs, outputs in predicted_traces:\\n31 d = dspy.Example(automated=True, **inputs, **outputs)\\n32 predictor_name = self.predictor2name[id(predictor)]\\n33 compiled_program[predictor_name].demonstrations.append(d)\\n34\\n35\\n36 return compiled_program\\nE.2 B OOTSTRAP FEWSHOT WITH RANDOM SEARCH\\n1 class SimplifiedBootstrapFewShotWithRandomSearch(Teleprompter):\\n2 def __init__(self, metric = None, trials=16):\\n3 self.metric = metric\\n4 self.trials = trials\\n5\\n6 def compile(self, student, *, teacher=None, trainset, valset=None):\\n7 # we can do forms of cross-validation if valset is unset.\\n8 valset = trainset if valset is None else valset\\n9\\n10 candidates = []\\n11 for seed in range(self.trials):\\n12 # Create a new basic bootstrap few-shot program.\\n13 shuffled_trainset = shuffle(trainset, seed=seed)\\n14 tp = BootstrapFewShot(metric=metric, max_bootstrap_demos=random_size())\\n15 candidate_program = tp.compile(student, shuffled_trainset, teacher)\\n16\\n17 # Step 2: Evaluate the generated candidate program.\\n18 score = evaluate_program(candidate_program, self.metric, valset)\\n19 candidates.append((score, candidate_program))\\n20\\n21 # return the best candidate program.\\n22 return max(candidates, key=lambda x: x[0])[1]\\n28', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='06fa5146-be9c-4a9d-86ab-cc7578738115', embedding=None, metadata={'page_label': '29', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nE.3 B OOTSTRAP FEWSHOT WITH OPTUNA\\n1 class SimplifiedBootstrapFewShotWithOptuna(Teleprompter):\\n2 def __init__(self, metric, trials=16):\\n3 self.metric = metric\\n4 self.trials = trials\\n5\\n6 def objective(self, trial):\\n7 pool = self.pool\\n8\\n9 # Step 1: Create copy of student program.\\n10 candidate_program = self.student.reset_copy()\\n11\\n12 # Step 2: Based on trial, select demos for each predictor in program.\\n13 # Note. For simplicity, we can just select a single demo for each predictor.\\n14 # But we can easily tune the number of demonstrations to select here.\\n15 for (name, predictor1), (_, predictor2) in \\\\\\n16 zip(pool.named_predictors(), candidate_program.named_predictors()):\\n17 all_demos = predictor1.demos\\n18 demo_index = trial.suggest_int(f\"demo_index_for_{name}\", 0, len(all_demos) - 1)\\n19 predictor2.demos = [all_demos[demo_index]]\\n20\\n21 # Step 3: Evaluate the modified candidate program.\\n22 score = evaluate_program(candidate_program, self.metric, self.valset)\\n23\\n24 # Step 4: Store the candidate for Optuna to select highest-scoring program.\\n25 trial.set_user_attr(\"program\", candidate_program)\\n26 return score\\n27\\n28 def compile(self, student, trainset, teacher=None, valset=None):\\n29 self.trainset = trainset\\n30 self.valset = trainset if valset is None else valset\\n31\\n32 self.student = student.deepcopy()\\n33 self.teacher = teacher.deepcopy() if teacher else student.deepcopy()\\n34\\n35 # Leverage BootstrapFewshot to create a large number of potential demonstrations.\\n36 tp = BootstrapFewShot()\\n37 self.pool = tp.compile(self.student, self.teacher, self.trainset, self.metric)\\n38\\n39 # Use Optuna to find the best program by optimizing the objective function.\\n40 best_program = optimize_with_optuna(self.objective)\\n41\\n42 print(’Best score:’, best_program.score)\\n43 print(’Best program:’, best_program)\\n44 return best_program\\n29', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='10ac5d97-9dba-4da8-8dae-5907cee4eb33', embedding=None, metadata={'page_label': '30', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nF E XAMPLES OF THE PROMPTS AUTOMATICALLY GENERATED BY DSP Y\\nFor GSM8K, we include the prompt bootstrapped by DSPy for GSM8K llama2-13b-chat for the\\nvanilla program compiled with bootstrap×2 in Figure 9.\\nWe also include a CoT prompt for GSM8K and a generate query prompt from the multihop pro-\\ngram for HotPotQA. All of these, particularly their demonstrations’ labels and their selection, are\\ngenerated by DSPy automatically using llama2-13b-chat.\\n30', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ace6d004-fa99-427a-90c7-ddea8f6e283b', embedding=None, metadata={'page_label': '31', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 Given the fields ‘question‘, produce the fields ‘answer‘.\\n2\\n3 ---\\n4\\n5 Follow the following format.\\n6\\n7 Question: ${question}\\n8 Answer: ${answer}\\n9\\n10 ---\\n11\\n12 Question: Jimmy and Irene go shopping for clothes on a Tuesday, where senior citizens get a 10% discount on their purchases.\\nJimmy picks out 3 shorts from the $15 rack. Irene grabs 5 shirts from the $17 rack. How much money do they give to the\\ncashier?\\n13 Answer: Jimmy picks out 3 shorts at $15 each = $45. Irene grabs 5 shirts at $17 each = $85. Total cost = $45 + $85 = $130.\\nSince senior citizens get a 10% discount, they will pay 10% of $130 = $13. So, they will give the cashier $130 - $13 =\\n$117. ---\\n14\\n15 ---\\n16\\n17 Question:\\nFigure 9: Copy of the prompt automatically generated by DSPy for GSM8K Llama2-13b-chat\\nvanilla program compiled with bootstrap×2.\\n1 Given the fields ‘question‘, produce the fields ‘answer‘.\\n2\\n3 ---\\n4\\n5 Follow the following format.\\n6\\n7 Question: ${question}\\n8 Reasoning: Let’s think step by step in order to $produce the answer. We ...\\n9 Answer: ${answer}\\n10\\n11 ---\\n12\\n13 Question: Mark is baking bread. He has to let it rise for 120 minutes twice. He also needs to spend 10 minutes kneading\\nit and 30 minutes baking it. How many minutes does it take Mark to finish making the bread?\\n14 Reasoning: Let’s think step by step in order to find out how many minutes it takes Mark to finish making the bread. We know\\nthat he needs to let it rise for 120 minutes twice, so that’s 240 minutes. Then, he needs to spend 10 minutes kneading it\\nand 30 minutes baking it. So, in total, it will take Mark 240 + 10 + 30 = 280 minutes to finish making the bread.\\n15 Answer: 280 ---\\n16\\n17 ---\\n18\\n19 Question: Ben has $2000 for his business operations costs. He orders goods from his supplier and writes them a cheque for\\n$600. His debtor pays him$800 from the purchases they had made on credit. Mr. Ben then decides to do equipment maintenance\\nand spends $1200 on the whole operation. How much money is Mr. Ben remaining with?\\n20 Reasoning: Let’s think step by step in order to find out how much money Mr. Ben is remaining with. We know that he had\\n$2000 to begin with, and he spent $600 on goods from his supplier, so he has $2000 - $600 = $1400 left. Then, his debtor\\npaid him $800, so he has $1400 + $800 = $2200. Finally, he spent $1200 on equipment maintenance, so he has $2200 - $1200\\n= $1000 left.\\n21 Answer: $1000 ---\\n22\\n23 ---\\n24\\n25 ... several other demonstrations here ...\\n26\\n27 ---\\n28\\n29 Question:\\nFigure 10: Shortened copy of the prompt automatically generated by DSPy for GSM8K Llama2-\\n13b-chat CoT program compiled with bootstrap.\\n31', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='299cfd49-b1e3-4a06-b750-e8df69cb6a6f', embedding=None, metadata={'page_label': '32', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n1 Given the fields ‘context‘, ‘question‘, produce the fields ‘search query‘.\\n2\\n3 ---\\n4\\n5 Follow the following format.\\n6\\n7 Context: ${context}\\n8 Question: ${question}\\n9 Reasoning: Let’s think step by step in order to ${produce the search query}. We ...\\n10 Search Query: ${search query}\\n11\\n12 ---\\n13\\n14 Context:\\n15 [1] Twilight (novel series) | Twilight is a series of four vampire-themed fantasy romance novels by American author\\nStephenie Meyer. ...\\n16 [2] Harper Connelly Mysteries | The Harper Connelly Mysteries is a series of fantasy mystery novels written by Charlaine\\nHarris, and first published in 2005. ...\\n17 [3] The Dark Heroine | The Dark Heroine is a series of vampire-themed fantasy romance novels written by English author\\nAbigail Gibbs, published by HarperCollins in 2012. ...\\n18\\n19 Question: In which year was the first of the vampire-themed fantasy romance novels for which The Twilight Saga: The\\nOfficial Illustrated Guide serves as a spin-off encyclopedic reference book first published?\\n20\\n21 Reasoning: Let’s think step by step in order to determine the year the first of the vampire-themed fantasy romance novels\\nwas first published. ...\\n22\\n23 Search Query: When was the first of the vampire-themed fantasy romance novels published?\\n24\\n25 ---\\n26\\n27 Context:\\n28 [1] The Victorians | The Victorians - Their Story In Pictures is a 2009 British documentary series which focuses on\\nVictorian art and culture. ...\\n29 [2] The Caxtons | The Caxtons: A Family Picture is an 1849 Victorian novel by Edward Bulwer-Lytton that was popular in its\\ntime.\\n30 [3] Victorian (comics) | The Victorian is a 25-issue comic book series published by Penny-Farthing Press and starting in\\n1999. ...\\n31\\n32 Question: The Victorians - Their Story In Pictures is a documentary series written by an author born in what year?\\n33\\n34 Reasoning: Let’s think step by step in order to produce the search query. We know that the documentary series is about\\nVictorian art and culture, and it was written and presented by Jeremy Paxman. Therefore, we need to find the year in which\\nJeremy Paxman was born.\\n35\\n36 Search Query: Jeremy Paxman birth year\\n37\\n38 ---\\n39\\n40\\n41 Context:\\nFigure 11: Shortened copy of the prompt automatically generated by DSPy for HotPotQA Llama2-\\n13b-chat multi-hop program (generating second hop query) compiled with bootstrap.\\n32', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "docs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3f43cb9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(list, 32)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(docs), len(docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9028b52",
   "metadata": {},
   "source": [
    "## 4. Use Chonkie to chunk the documents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "98559f22",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/fc/experiments/rag-project/.venv/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from chonkie import SemanticChunker\n",
    "from llama_index.core.schema import Document\n",
    "from llama_index.core import Settings\n",
    "from llama_index.embeddings.huggingface import HuggingFaceEmbedding\n",
    "\n",
    "\n",
    "semantic_chunker = SemanticChunker(\n",
    "    embedding_model=\"BAAI/bge-large-en-v1.5\",\n",
    "    threshold=0.5,\n",
    "    chunk_size=512,\n",
    "    min_sentences=1\n",
    ")\n",
    "\n",
    "embed_model = HuggingFaceEmbedding(model_name=\"BAAI/bge-large-en-v1.5\",\n",
    "                                   trust_remote_code=True)\n",
    "\n",
    "Settings.embed_model = embed_model\n",
    "\n",
    "all_chunks = []\n",
    "for doc in docs:\n",
    "    chunks = semantic_chunker.chunk(doc.text)\n",
    "    for chunk in chunks:\n",
    "        # Use LlamaIndex's embedding model to embed the chunk text\n",
    "        chunk_embedding = Settings.embed_model.get_text_embedding(chunk.text)\n",
    "        all_chunks.append(\n",
    "            Document(\n",
    "                text=chunk.text,\n",
    "                metadata=doc.metadata,\n",
    "                embedding=chunk_embedding\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a53758e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "76"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e220cfd7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(id_='7c2c64c2-b403-43ed-9bc2-785422e02483', embedding=[0.038891248404979706, 0.00458358833566308, -0.0032363533973693848, -0.011541174724698067, -0.023720134049654007, -0.015372456051409245, -0.01644018106162548, -0.017184259369969368, -0.017161991447210312, 0.06521951407194138, -0.003091790247708559, -0.01796267181634903, -0.006126547232270241, -0.03504977002739906, -0.02182835154235363, 0.002376331016421318, -0.02055387571454048, -0.03153911232948303, -0.07666144520044327, 0.0014957647072151303, 0.03511612117290497, -0.01860874705016613, -0.0852985605597496, 0.0051113395020365715, -0.03072628378868103, 0.023758085444569588, 0.02069648914039135, -0.0028157311026006937, 0.07397174835205078, 0.06731146574020386, 0.017167920246720314, 0.0034706720616668463, 0.015570398420095444, -0.03472590073943138, -0.03713826462626457, -0.07597390562295914, 0.007801176514476538, -0.008913443423807621, -0.02500114217400551, -0.010506954975426197, 0.03661350905895233, -0.0425884835422039, 0.057719942182302475, -0.0666344091296196, -0.06981883198022842, -0.018708759918808937, 0.0068021356128156185, -0.010363771580159664, -0.003951976075768471, -0.021141160279512405, -0.01383129134774208, 0.01923905871808529, 0.005892965942621231, 0.00249409768730402, -0.028074905276298523, 0.009196070022881031, -0.007377236150205135, -0.013389396481215954, -0.044529158622026443, -0.006795923691242933, -0.003026443300768733, 0.025121377781033516, -0.00721862493082881, -0.06537768989801407, -0.01717441901564598, 0.015934349969029427, 0.007135470397770405, -0.004555927123874426, -0.016972826793789864, -0.015753649175167084, -0.07298984378576279, 0.004729440901428461, -0.037378501147031784, -0.02757292240858078, -0.010955046862363815, 0.004294109996408224, 0.04852171614766121, 0.004397729877382517, -0.03833451122045517, 0.06144125387072563, 0.02945433370769024, 0.046633582562208176, -0.0021446296013891697, 0.014794668182730675, -0.02306981012225151, -0.040891923010349274, 0.05778519809246063, -0.015055008232593536, -0.035925328731536865, -0.009669060818850994, -0.020198184996843338, 0.03860074281692505, -0.0004887411487288773, 0.01984228752553463, 0.04414210096001625, 0.0482541099190712, -0.007371031679213047, 0.03440973162651062, -0.010696127079427242, -0.009815405122935772, 0.027610599994659424, 0.06836452335119247, -0.022646140307188034, 0.01761750876903534, -0.04858241602778435, -0.016201097518205643, 0.007946459576487541, 0.0043395934626460075, -0.02159774675965309, -0.01447866391390562, 0.0018561509205028415, 0.0035498985089361668, -0.021052716299891472, 0.01905355602502823, -0.031850457191467285, 0.015702281147241592, 0.009441152215003967, 0.0020175089593976736, -0.03911514952778816, -0.0236835740506649, -0.005549451801925898, -0.007424292620271444, 0.019586922600865364, -0.005869637243449688, 0.022337382659316063, -0.02996717020869255, -0.004152243956923485, 0.0723445937037468, -0.04303072765469551, -0.0037155079189687967, -0.012560092844069004, 0.014413490891456604, 0.0016483806539326906, 0.06140860170125961, -0.001153837889432907, 0.006782726384699345, 0.00858211051672697, 0.017224688082933426, 0.02604319527745247, 0.0034502027556300163, 0.020345425233244896, -0.0382830835878849, 0.013364078477025032, 0.11069445312023163, 0.008932597003877163, 0.016418082639575005, -0.007073292974382639, -0.020749539136886597, -0.0378870889544487, 0.024387309327721596, 0.0006128360982984304, 0.007815316319465637, -0.0020966995507478714, 0.024667339399456978, -0.027928855270147324, 0.019421374425292015, -0.027149757370352745, -0.02401018515229225, 0.0035773133859038353, 0.011921902187168598, -0.006459243595600128, -0.02941683679819107, -0.044896405190229416, 0.017126552760601044, -0.03356219828128815, 0.030808158218860626, -0.05089488625526428, -0.011422880925238132, 0.003081322880461812, -0.02478594332933426, 0.008687183260917664, 0.0004151728644501418, -0.009000939317047596, 0.02887219376862049, 0.06033960357308388, 0.05792892351746559, 0.040982771664857864, 0.017451055347919464, 0.004338697995990515, -0.0008986218017525971, -0.014246996492147446, -0.008564301766455173, 0.017341280356049538, 5.832421720697312e-06, 0.028452709317207336, 0.04467258229851723, 0.013235927559435368, 0.004842511843889952, -0.01613440550863743, 0.012384585104882717, -0.00047469453420490026, 0.06198211759328842, -0.03167398273944855, 0.018350817263126373, -0.012217427603900433, -0.0002595997939351946, -0.019134346395730972, 0.03717423975467682, 0.0006439274875447154, -0.03966657444834709, -0.023496363312005997, 0.04844842106103897, -0.002368121175095439, -0.011498019099235535, -0.05479874461889267, 0.0068819778971374035, -0.0024190042167901993, 0.0509062223136425, -0.05020037665963173, 0.0024137161672115326, 0.038815539330244064, 0.014859328046441078, -0.03208621218800545, -0.011812870390713215, 0.03638452664017677, -0.0029739197343587875, -0.024977639317512512, -0.007784126326441765, 0.01368167344480753, 0.011169898323714733, -0.009632149711251259, -0.0036771867889910936, 0.0014922800473868847, -0.006501943338662386, -0.028234276920557022, -0.02742689847946167, 0.012658433057367802, 0.0359143428504467, -0.010454499162733555, 0.006745415739715099, 0.01499700266867876, 0.01669631525874138, -0.015537269413471222, 0.049320559948682785, 0.03072635643184185, 0.027848852798342705, 0.06729087233543396, 0.07839494198560715, -0.009970486164093018, 0.0191842932254076, -0.013038481585681438, 0.024496279656887054, -0.0009139536996372044, 0.035123009234666824, 0.018651125952601433, 0.017836779356002808, 0.007259242702275515, -0.006647587288171053, -0.03988306596875191, 0.010068814270198345, -0.06718273460865021, 0.04374169558286667, 0.028128046542406082, -0.004709561355412006, -0.018527263775467873, -0.032083068042993546, 0.00819277111440897, 0.03543224185705185, -0.018909936770796776, -0.014726653695106506, 0.03925861045718193, 0.0217717457562685, -0.008830605074763298, -0.039033737033605576, 0.024907512590289116, 0.04893232136964798, -0.00015443877782672644, 0.015706246718764305, 0.008760971017181873, -0.016832416877150536, -0.037299975752830505, -0.0450802706182003, -0.06717134267091751, 0.0034999491181224585, -0.020118393003940582, -0.004872270859777927, -0.002554859733209014, -0.049891576170921326, -0.00241632922552526, -0.017228465527296066, 0.02202223427593708, 0.019564300775527954, -0.021350529044866562, 0.03186100721359253, 0.05233420804142952, -0.010959198698401451, -0.06707025319337845, 0.03252999857068062, -0.017328904941678047, 0.06301243603229523, -0.016171671450138092, -0.010653046891093254, -0.002416446339339018, -0.0013348771026358008, 0.01927061937749386, -0.0034155752509832382, 0.016143372282385826, -0.019558172672986984, -0.04486367106437683, -0.01193896122276783, 0.01858483999967575, -0.029275404289364815, 0.027551917359232903, -0.02536296844482422, -0.04545370489358902, 0.05951504781842232, 0.009508299641311169, -0.038751158863306046, 0.047874610871076584, 0.02680770680308342, -0.056119270622730255, 0.03381974250078201, -0.028363771736621857, 0.018550479784607887, -0.03734822943806648, 0.06199493631720543, 0.01971425861120224, -0.020785462111234665, -0.0412730872631073, -0.05975036695599556, -0.03965965658426285, 0.01294487714767456, -0.009256532415747643, -0.027441073209047318, -0.003999605309218168, 0.04631851986050606, -0.008730698376893997, -0.04622979462146759, 0.011760053224861622, -0.03417515009641647, -0.04629553481936455, 0.00012201970821479335, -0.004463403485715389, 0.04487333819270134, 0.023424461483955383, 0.04137903079390526, -0.02529953233897686, 0.024102669209241867, -0.025397898629307747, 0.014583769254386425, 0.011770674027502537, -0.021733203902840614, 0.0047562080435454845, 0.054267313331365585, 0.004219016991555691, 0.0153400469571352, 0.003745411289855838, -0.033237043768167496, -0.0223397146910429, -0.03905117139220238, 0.007348513696342707, 0.030191445723176003, -0.005389188416302204, 0.016093885526061058, -0.01052126009017229, 0.03164168447256088, -0.0316653773188591, -0.02973327785730362, 0.029449867084622383, 0.017312010750174522, -0.00030845540459267795, 0.03894916921854019, -0.02063792385160923, 0.010549063794314861, -0.018756229430437088, -0.021517669782042503, -0.022299492731690407, 0.02459474466741085, 0.04318701848387718, -0.052441854029893875, 0.039470870047807693, -0.01538078859448433, -0.029672833159565926, 0.0013765967451035976, -0.03398025780916214, -0.04265397787094116, 0.03634828329086304, 0.027987191453576088, 0.04387235268950462, -0.010517324320971966, -0.03591882437467575, 0.022521307691931725, -0.0054908678866922855, 0.022691380232572556, 0.049816347658634186, 0.04227543622255325, 0.0032829134725034237, -0.013396489433944225, -0.03497477248311043, 0.011487923562526703, -0.027490252628922462, 0.03453519567847252, 0.0023782660719007254, -0.028373856097459793, -0.004563860595226288, -0.029992595314979553, 0.0447806678712368, 0.04357221722602844, 0.016848040744662285, -0.0006857973639853299, 0.03386017307639122, -0.041916679590940475, 0.046595100313425064, 0.011371733620762825, 0.03539475053548813, -0.008676302619278431, -0.05249679833650589, 0.013563270680606365, -0.023922601714730263, 0.022279974073171616, 0.000640937767457217, -0.002961164340376854, 0.01168270967900753, 0.027054397389292717, -0.002444965299218893, 0.00040882013854570687, -0.019244475290179253, 0.004326025024056435, 0.01258945744484663, 0.026075296103954315, -0.016855686902999878, -0.018222784623503685, -0.024978861212730408, 0.005803314968943596, 0.030932094901800156, -0.05037820711731911, 0.007073186803609133, -0.0201586727052927, 0.004149726592004299, 0.026122651994228363, -0.041923318058252335, -0.022353455424308777, -0.012796464376151562, -0.016551729291677475, -0.03960513323545456, 0.05185781419277191, 0.04071846231818199, -0.04106524586677551, -0.003412704449146986, -0.03212010860443115, 0.014642370864748955, -0.0018061677692458034, 0.010360946878790855, -0.008414638228714466, 0.043792299926280975, -0.02477116324007511, 0.010391656309366226, 0.03283396363258362, 0.007688424549996853, -0.04770505800843239, 0.01213169191032648, -0.051817066967487335, 0.021493513137102127, -0.05642355605959892, -0.026651492342352867, -0.021579474210739136, -0.011305935680866241, -0.009950337931513786, -0.009859872981905937, 0.009321929886937141, 0.000759387097787112, -0.011731232516467571, 0.019962506368756294, -0.032827332615852356, -0.05002462491393089, 0.029210081323981285, 0.027954962104558945, -0.017934564501047134, 0.05538322404026985, 0.0189205352216959, -0.026211045682430267, -0.0173542071133852, 0.008477901108562946, -0.0066117639653384686, 0.022986743599176407, -0.014039344154298306, 0.007722470443695784, -0.019264761358499527, -0.027319295331835747, -0.007147634867578745, -0.04123249650001526, 0.03760673478245735, -0.0013322265585884452, -0.033668167889118195, 0.0013654574286192656, -0.034940075129270554, -0.011289357207715511, 0.010694054886698723, -0.014072537422180176, -0.004594605416059494, -0.010745450854301453, -0.03426705300807953, 0.0267487820237875, -0.032670583575963974, -0.04000023007392883, -0.049535445868968964, -0.006075439043343067, 0.008279661647975445, 0.03305141255259514, 0.07424202561378479, 0.060868922621011734, -0.012419217266142368, -0.04407074302434921, 0.03799143806099892, -0.014298531226813793, -0.02725381962954998, -0.02045198157429695, -0.0006514113047160208, -0.024054350331425667, 0.005420234985649586, -0.0427812784910202, -0.01878397911787033, -0.011658955365419388, -0.016163822263479233, 0.007576322183012962, -0.0018975683487951756, 0.008046401664614677, -0.00809522159397602, -0.02505071833729744, 0.03849519416689873, 0.01727185770869255, -0.09575821459293365, -0.031082065775990486, 0.003316660411655903, -0.030176807194948196, 0.01569347083568573, 0.03371439874172211, -0.006515059154480696, -0.019852908328175545, -0.04383229464292526, 0.038116611540317535, -0.035564448684453964, 0.009836280718445778, -0.03814209997653961, -0.03248167037963867, 0.023844333365559578, -0.01392272487282753, 0.05853342264890671, -0.039043277502059937, -0.05338117107748985, -0.04250241816043854, 0.028174882754683495, -0.04872167110443115, -0.01804807037115097, -0.016965774819254875, -0.016620580106973648, 0.00641072541475296, 0.06454427540302277, -0.010802049189805984, 0.01138318795710802, -0.009602459147572517, 0.03172062709927559, 0.021337110549211502, 0.04130253195762634, -0.01741213910281658, -0.00796361081302166, 0.009575323201715946, 0.013701997697353363, 0.02984144352376461, 0.010850795544683933, -0.037793584167957306, 0.01680866815149784, -0.03563697636127472, -0.0061010681092739105, -0.037748876959085464, -0.0047872732393443584, -0.017456235364079475, -0.01849951036274433, 0.04591824859380722, -0.056732870638370514, 0.014555823989212513, -0.006701783277094364, 0.049058057367801666, -0.018975334241986275, -0.021132471039891243, -0.028094928711652756, 0.012086674571037292, -0.03308754041790962, -0.028946012258529663, 0.0132982162758708, -0.03889203816652298, 0.007635262329131365, 0.01848161406815052, -0.009131155908107758, 0.018211605027318, -0.06394755840301514, 0.033358652144670486, 0.06578302383422852, 0.0394098237156868, 0.011539939790964127, -0.0380818173289299, -0.0002214502019342035, 0.0053137303330004215, -0.016541995108127594, 0.009271935559809208, -0.015508354641497135, -0.014295969158411026, -0.018286101520061493, -0.02260359190404415, -0.046459078788757324, 0.005846656393259764, 0.001957179745659232, 0.0735907256603241, -0.010798817500472069, 0.036882124841213226, 0.008485345169901848, -0.06758220493793488, -0.03132873773574829, 0.03522047400474548, -0.023587509989738464, 0.00533531978726387, 0.02954407036304474, 0.007791641168296337, -0.006384763401001692, 0.00862918421626091, -0.03268137574195862, -0.04406428709626198, -0.01167428307235241, 0.04285768046975136, -0.009343522600829601, -0.02182905562222004, 0.05080421268939972, 0.029915472492575645, -0.03236095979809761, -0.04435040056705475, 0.018404381349682808, -0.00453130854293704, -0.011671587824821472, -0.013995314948260784, -0.012648588046431541, 0.00965105276554823, -0.022621821612119675, -0.0003606253594625741, 0.036743078380823135, -0.025439664721488953, -0.025392618030309677, 0.018488341942429543, 0.010944589972496033, -0.053276803344488144, 0.05981449782848358, 0.05523508042097092, -0.02845856174826622, -0.005028751213103533, -0.016187159344553947, -0.0048223454505205154, 0.004886368289589882, -0.006148698274046183, 0.048850979655981064, -0.010215912945568562, 0.02232145331799984, 0.021932583302259445, 0.00543487723916769, 0.048387039452791214, -0.024205178022384644, 0.012128044851124287, 0.023339563980698586, -0.05367907136678696, -0.04846993461251259, -0.021416515111923218, -0.005866145249456167, -0.005849018227308989, 0.05732956901192665, -0.013963633216917515, 0.053160373121500015, 0.02639220841228962, 0.031667374074459076, -0.009585690684616566, -0.05270318314433098, -0.0038737356662750244, -0.05489184334874153, -0.027430329471826553, 0.00692156795412302, -0.04778193309903145, 0.014197232201695442, 0.04251585900783539, -0.0031569465063512325, -0.05460188910365105, -0.00434214249253273, 0.034732721745967865, -0.049042705446481705, -0.012086099945008755, -0.012140006758272648, 0.01529949065297842, -0.05925915390253067, -0.005498979706317186, -0.005568108521401882, -5.9499943745322526e-05, -0.030859695747494698, -0.00011034816998289898, -0.02006661705672741, 0.019413253292441368, 0.019000105559825897, 0.021619683131575584, -0.02543410286307335, -0.0045524220913648605, -0.02517213299870491, 0.011923978105187416, -0.011277027428150177, 0.025451146066188812, -0.025975951924920082, 0.06304123252630234, 0.008441387675702572, -0.019263433292508125, -0.015704890713095665, -0.004676272626966238, 0.004386167973279953, -0.03248419612646103, 0.013281951658427715, 0.045520395040512085, -0.005450491327792406, 0.010232584550976753, -0.021463720127940178, 0.0427476167678833, -0.04307492822408676, -0.015839645639061928, -0.006903153844177723, -0.026798052713274956, -0.0021928180940449238, 0.002532367594540119, 0.03128437325358391, 0.08143740147352219, 0.05371776595711708, 0.01638966053724289, 0.027866816148161888, 0.005633462220430374, 0.023317281156778336, 0.02430926449596882, 0.008276709355413914, -0.004278145730495453, -0.023042146116495132, -0.058343544602394104, 0.05139583721756935, 0.02127530239522457, -0.023276513442397118, 0.03081907331943512, -0.013321535661816597, -0.019132042303681374, -0.04728143289685249, -0.010084831155836582, 0.0242215134203434, 0.039921924471855164, 0.07180741429328918, -0.04896213486790657, -0.014414751902222633, -0.004070030525326729, -0.0032639182172715664, 0.0016845724312588573, -0.04679693281650543, -0.03179815039038658, 0.008962694555521011, -0.023332618176937103, -0.002582005923613906, 0.005984955932945013, 0.007175465580075979, 0.011461298912763596, 0.025046784430742264, 0.05236823484301567, 0.02521493099629879, 0.03584379330277443, 0.007191220764070749, -0.003184949979186058, -0.03924618661403656, -0.033086083829402924, -0.012204118072986603, 0.01829814538359642, -0.06604281067848206, -0.05992848798632622, 0.008699185214936733, 0.0718822032213211, 0.005735362879931927, -0.009357724338769913, -0.06500405073165894, 0.0168048944324255, -0.018218927085399628, 0.028434481471776962, -0.08814532309770584, 0.017702003940939903, -0.004120327066630125, 0.0027369996532797813, -0.018386173993349075, 0.015769867226481438, -0.0025213107001036406, 0.01634739153087139, 0.007665588520467281, 0.009012792259454727, -0.01124691590666771, 0.05606997385621071, 0.027970153838396072, -0.029640641063451767, 0.06612008810043335, 0.0018782122060656548, 0.0339222177863121, 0.01677573472261429, -0.008549598045647144, 0.02461967058479786, 0.03764595463871956, 0.025855517014861107, 0.05587272718548775, -0.011278522200882435, 0.04619394987821579, 0.04366951435804367, -0.02973860874772072, 0.0042433664202690125, 0.042006753385066986, 0.032932672649621964, -0.02443707175552845, -0.0009647051338106394, -0.07305216044187546, 0.019354524090886116, -0.023580923676490784, 0.02843824028968811, 0.018309587612748146, -0.014610945247113705, 0.02292490378022194, -0.014324520714581013, -0.05117266997694969, 0.03195115923881531, -0.022344626486301422, -0.046786557883024216, -0.012160818092525005, 0.023659801110625267, 0.0342702679336071, 0.022210529074072838, 0.02779771015048027, -0.023790696635842323, 0.04580158367753029, 0.033394262194633484, 0.04148898273706436, -0.006842012982815504, 0.004061262123286724, 0.019674956798553467, 0.006118163466453552, 0.016368743032217026, -0.024101093411445618, 0.013817308470606804, 9.573216084390879e-05, -0.017257733270525932, -0.015876509249210358, 0.05981234461069107, -0.019078444689512253, -0.054915137588977814, 0.004719624295830727, -0.005657311994582415, -0.01509829517453909, -0.04060083255171776, 0.055287912487983704, -0.027558157220482826, 0.008668757975101471, 0.041168585419654846, -0.029424455016851425, -0.018329555168747902, 0.05135278403759003, 0.007664515636861324, 0.005756334867328405, 0.03793046995997429, 0.05099028721451759, -0.007146281190216541, 0.08038850128650665, 0.046319231390953064, 0.018666690215468407, 0.015147849917411804, 0.008222151547670364, -0.006768443156033754, -0.022702235728502274, 0.008293616585433483, -0.0023743831552565098, -0.001555641065351665, -0.03356710448861122, -0.06221091002225876, 0.02734345942735672, -0.0042731622233986855, -0.017972147092223167, 0.024822719395160675, 0.011460289359092712, -0.0036802696995437145, -0.043696820735931396, 0.0002668050874490291, 0.049319565296173096, 0.017196809872984886, 0.02061045914888382, 0.005321593023836613, 0.00034362575388513505, -0.05480192229151726, 0.011925483122467995, -0.02162366732954979, 0.018072912469506264, -0.025023894384503365, -0.026938175782561302, 0.03383207321166992, -0.0403398796916008, -0.024481935426592827, -0.02934255823493004, -0.004206004086881876, -0.035673514008522034, 0.021611817181110382, 0.007692263927310705, 0.039518892765045166, 0.011517650447785854, -0.0414276123046875, -0.005847841035574675, 0.04822281748056412, 0.04933534935116768, -0.00570336589589715, 0.06898438185453415, 0.03503948077559471, -0.007189110387116671, -0.030613966286182404, 0.013928523287177086, -0.006431499030441046, -0.005174768157303333, 0.013674362562596798, -0.011373273096978664, 0.02049020491540432, -0.009470302611589432, -0.04982997104525566, 0.006443762220442295, 0.03785330802202225, 0.04007834568619728, -0.0145386578515172, -0.038352418690919876, -0.013982158154249191, -0.047418419271707535, -0.004989976063370705, -0.03764874115586281, 0.026718193665146828, 0.017634328454732895, -0.009185880422592163, -0.004921864252537489, -0.004214640706777573, 0.23436743021011353, 0.08068658411502838, 0.046009283512830734, 0.020866014063358307, 0.015723755583167076, 0.05863684043288231, 0.02444264478981495, -0.02406143583357334, 0.04707930237054825, -0.046035584062337875, 0.03447984158992767, -0.035798050463199615, 0.01697150617837906, 0.013429058715701103, -0.022882606834173203, 0.01647825911641121, -0.05477942153811455, -0.011341200210154057, -0.025149725377559662, -0.024496546015143394, -0.04964454472064972, 0.025847461074590683, 0.00010466797539265826, -0.004647107794880867, 0.030932622030377388, -0.00035787810338661075, 0.007485037203878164, -0.027070140466094017, 0.04039417952299118, -0.029203111305832863, -0.0074676088988780975, -0.04346231743693352, 0.026146281510591507, -0.02357323281466961, -0.021007638424634933, 0.020840773358941078, -0.005971065256744623, -0.020981835201382637, -0.006581130437552929, 0.03876534476876259, -0.019353140145540237, -0.01744076795876026, -0.009600679390132427, -0.014430658891797066, -0.03782062232494354, 0.0606585294008255, -0.011295001022517681, 0.025250360369682312, 0.03898625820875168, -0.07658645510673523, 0.02118826098740101, -0.01819334737956524, 0.014644294045865536, -0.03459557518362999, -0.05548713728785515, -0.02862551249563694, 0.006421122699975967, -0.03453298658132553, -0.03041466698050499, 0.005182293709367514, -0.00872642919421196, 0.013557497411966324, 0.007076470647007227, 0.057506345212459564, -0.009153865277767181, 0.012406722642481327, 0.030429081991314888, -0.034354839473962784, -0.05744592845439911, 0.007609190884977579, 0.015462678857147694, 0.006969127804040909, -0.007862894795835018, -0.04698854312300682, 0.03715115040540695, -0.0029838879127055407, -0.007409924175590277, 0.047417204827070236, 0.010535518638789654, -0.04542612284421921, -0.009697357192635536, -0.00891469419002533, -0.027469897642731667, -0.023848842829465866, 0.029772358015179634, 0.0633176937699318, -0.04145793244242668, -0.004392560571432114, -0.015446043573319912, 0.02161571756005287, -0.01977265253663063, 0.04479902982711792, -0.016112258657813072, -0.017052819952368736, -0.003942769020795822], metadata={'page_label': '1', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\nDSP Y: C OMPILING DECLARATIVE LANGUAGE\\nMODEL CALLS INTO SELF -IMPROVING PIPELINES\\nOmar Khattab,1 Arnav Singhvi,2\\nParidhi Maheshwari,4 Zhiyuan Zhang,1\\nKeshav Santhanam,1 Sri Vardhamanan,6 Saiful Haq,6\\nAshutosh Sharma,6 Thomas T. Joshi,7 Hanna Moazam,8\\nHeather Miller,3,9 Matei Zaharia,2 Christopher Potts1\\n1Stanford University, 2UC Berkeley, 3Carnegie Mellon University,\\n4Amazon Alexa AI, 5Dashworks Technologies, Inc.,\\n6IIT Bombay, 7Calera Capital, 8Microsoft, 9Two Sigma Investments\\nokhattab@cs.stanford.edu\\nABSTRACT\\nThe ML community is rapidly exploring techniques for prompting language mod-\\nels (LMs) and for stacking them into pipelines that solve complex tasks. Un-\\nfortunately, existing LM pipelines are typically implemented using hard-coded\\n“prompt templates”, i.e. lengthy strings discovered via trial and error. Toward a\\nmore systematic approach for developing and optimizing LM pipelines, we intro-\\nduce DSPy, a programming model that abstracts LM pipelines astext transforma-\\ntion graphs, i.e. imperative computation graphs where LMs are invoked through\\ndeclarative modules. DSPy modules are parameterized, meaning they can learn\\n(by creating and collecting demonstrations) how to apply compositions of prompt-\\ning, finetuning, augmentation, and reasoning techniques. We design a compiler\\nthat will optimize any DSPy pipeline to maximize a given metric. We conduct\\ntwo case studies, showing that succinct DSPy programs can express and optimize\\nsophisticated LM pipelines that reason about math word problems, tackle multi-\\nhop retrieval, answer complex questions, and control agent loops. Within minutes\\nof compiling, a few lines of DSPy allow GPT-3.5 and llama2-13b-chat to self-\\nbootstrap pipelines that outperform standard few-shot prompting (generally by\\nover 25% and 65%, respectively) and pipelines with expert-created demonstra-\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='ba331993-5892-4315-979b-e4cbe36297c2', embedding=[0.05816654488444328, -0.014844326302409172, -0.021997705101966858, 0.0171565730124712, -0.01856244169175625, -0.028691481798887253, -0.024228472262620926, 0.004176276735961437, -0.017090026289224625, 0.05487688630819321, -0.01342292781919241, -0.006431418005377054, -0.015169038437306881, -0.034408848732709885, -0.021808821707963943, 0.020514685660600662, -0.01396198756992817, -0.02278905361890793, -0.05581799894571304, 0.005926418583840132, 0.03394365683197975, 0.011840985156595707, -0.07517926394939423, -0.005426900461316109, -0.00973525084555149, 0.04104338958859444, 0.03251213952898979, 0.0042537846602499485, 0.09006783366203308, 0.03362635523080826, 0.015719642862677574, -0.01199293602257967, 0.013268761336803436, -0.023051749914884567, -0.05023892968893051, -0.07027174532413483, 0.012148900888860226, -0.005565513391047716, -0.019893653690814972, -0.02308189682662487, 0.03788124769926071, -0.055420584976673126, 0.06535421311855316, -0.06459136307239532, -0.06500477343797684, 0.012957096099853516, 0.01421897578984499, -0.022126346826553345, -0.0002005783171625808, -0.03511228784918785, -0.020559296011924744, 0.027635902166366577, 0.011816173791885376, 0.009246873669326305, -0.011027468368411064, -0.009145873598754406, -0.009261642582714558, -0.002368175657466054, -0.04049673303961754, 0.002955508651211858, 0.009945875965058804, 0.05175720527768135, -0.012496990151703358, -0.06441568583250046, -0.005899857729673386, 0.007068478502333164, 0.000621132378000766, -0.02565930038690567, -0.02179889753460884, -0.02904139831662178, -0.05379081889986992, 0.019191032275557518, -0.03965965658426285, -0.030142150819301605, -0.016128888353705406, -0.015476355329155922, 0.02363969199359417, -0.0019376322161406279, -0.03580468147993088, 0.05434321239590645, 0.04736347123980522, 0.057203829288482666, 0.0007874930161051452, -0.0025504985824227333, -0.016685722395777702, -0.027135316282510757, 0.06727036088705063, -0.001040228526107967, 0.005716066807508469, -0.004072734620422125, -0.009147420525550842, 0.04125891253352165, -0.0046798973344266415, 0.030666202306747437, 0.03725090250372887, 0.027728371322155, 0.003097591456025839, 0.043818265199661255, -0.010414090007543564, -0.004468646366149187, 0.02755703218281269, 0.06589630991220474, -0.01198140624910593, 0.010066704824566841, -0.06218154728412628, -0.015234783291816711, 0.030300796031951904, -0.013102786615490913, -0.009468447417020798, -0.016103053465485573, -0.008151577785611153, 0.014784283004701138, -0.02677023783326149, -0.016016190871596336, -0.03333123400807381, 0.01919735223054886, 0.01947939023375511, -0.003588047344237566, -0.05153881013393402, 0.021351799368858337, 0.0007827817462384701, -0.01928056962788105, -0.011651280336081982, -0.0064763268455863, 0.03441036120057106, -0.015609080903232098, 0.0013120209332555532, 0.04535483568906784, -0.055877018719911575, -0.0073335724882781506, -0.015172511339187622, 0.015092764981091022, -0.0009903413010761142, 0.04966746270656586, 0.0291027519851923, 0.0028364474419504404, 0.022896969690918922, 0.033702749758958817, 0.02957451343536377, -0.029714299365878105, 0.0007584580453112721, -0.023655390366911888, -0.0037357802502810955, 0.0857439935207367, -0.009109066799283028, 0.0023806714452803135, -0.021705387160182, -0.037090517580509186, -0.04762149974703789, 0.03386564552783966, -0.014728114940226078, 0.029745522886514664, -0.01116823498159647, 0.01775735430419445, -0.015479697845876217, -0.011263778433203697, 0.009321417659521103, -0.012232162058353424, -0.0006782523123547435, 0.005289952736347914, -0.01238933950662613, 0.0049223206005990505, -0.05804618448019028, 0.034940022975206375, -0.023104408755898476, 0.039129357784986496, -0.03231753036379814, -0.01221085898578167, 0.022893518209457397, -0.03678564727306366, 0.016905467957258224, 0.02053677663207054, 7.1132235461846e-05, 0.056839242577552795, 0.04936108738183975, 0.07373978197574615, 0.037766844034194946, 0.007877375930547714, 0.023211045190691948, 0.024037450551986694, -0.012779935263097286, -0.017915289849042892, 0.01664232276380062, 0.002161651849746704, -0.0029485190752893686, 0.027811534702777863, 0.011112197302281857, -0.002617201302200556, -0.013688127510249615, 0.010956918820738792, -0.006344131659716368, 0.04444669559597969, -0.016458718106150627, 0.027824299409985542, 0.01464846171438694, 0.008213446475565434, 0.0015270659932866693, 0.012806961312890053, 0.008774496614933014, -0.05699403956532478, -0.01611371338367462, 0.06480837613344193, 0.009888125583529472, 0.020981553941965103, -0.048843953758478165, 0.04005259647965431, -0.012282161973416805, 0.04838395491242409, -0.017996110022068024, 0.01754056289792061, 0.04081886261701584, 0.017614761367440224, -0.03899350389838219, -0.024940431118011475, 0.019740572199225426, -0.02751266583800316, -0.025105111300945282, 0.0004515738401096314, 0.002480850089341402, 0.016330575570464134, 0.004312588833272457, 0.001911550178192556, 0.040597233921289444, -0.023630956187844276, 0.005797244608402252, -0.010965882800519466, 0.014571179635822773, 0.026900146156549454, -0.010376364924013615, 0.0023541252594441175, 0.006601269356906414, 0.05173445865511894, -0.0070042661391198635, 0.05646272748708725, 0.03243890032172203, 0.0029565277509391308, 0.07030926644802094, 0.07424608618021011, -0.0005854851915501058, 0.007681443355977535, -0.0006120232865214348, 0.014066854491829872, 0.004451876971870661, 0.049757979810237885, 0.023989280685782433, 0.01741928420960903, -0.0015065869083628058, 0.002590116113424301, -0.022839199751615524, 0.015523592010140419, -0.07303767651319504, 0.04471291974186897, 0.030002983286976814, -0.006804178934544325, -0.029285084456205368, -0.016831735149025917, 0.017181003466248512, 0.038422077894210815, -0.04902321845293045, -0.05254669860005379, 0.020298190414905548, 0.03347596526145935, -0.005197764374315739, -0.010764986276626587, 0.021235331892967224, 0.02025250345468521, -0.025791848078370094, 0.03829735890030861, 0.02347581647336483, -0.016053693369030952, -0.030590511858463287, -0.04092154651880264, -0.07230060547590256, 0.0024724649265408516, -0.010089022107422352, -0.0018255364848300815, -0.01904073916375637, -0.043306153267621994, -0.0033817668445408344, -0.04419620335102081, -0.01254225056618452, -0.004970867652446032, -0.021985003724694252, 0.03794201463460922, 0.045004166662693024, 0.007765595335513353, -0.05775194987654686, 0.022626830264925957, 0.0022213454358279705, 0.06251762807369232, 0.0006190286949276924, -0.014977449551224709, -0.025315897539258003, -0.011626750230789185, 0.02700154110789299, 0.006415367592126131, 0.013955271802842617, -0.017957275733351707, -0.03114224039018154, -0.016969989985227585, 0.02250373363494873, -0.0358731709420681, 0.05211362615227699, -0.023307962343096733, -0.04504731297492981, 0.04638172686100006, 0.0044999136589467525, -0.014584028162062168, 0.0521853081882, 0.038175176829099655, -0.05814753845334053, 0.028211507946252823, -0.008067077025771141, 0.03743118792772293, -0.02360328659415245, 0.047221168875694275, 0.022484207525849342, -0.030545951798558235, -0.03413141518831253, -0.04743344709277153, -0.04930099472403526, -0.007733501959592104, 0.015029465779662132, -0.019268568605184555, 0.018354620784521103, 0.03881237655878067, -0.018448570743203163, -0.06672253459692001, 0.015809936448931694, -0.056265413761138916, -0.032622966915369034, 0.012486527673900127, -0.02170315943658352, 0.02540990710258484, 0.02027745172381401, 0.018906215205788612, -0.026218367740511894, -0.03124774619936943, -0.04746080935001373, 0.023920554667711258, 0.01207216177135706, -0.03173758089542389, -0.0047712139785289764, 0.04106341302394867, 0.004109695553779602, -0.0033178196754306555, 0.019023528322577477, -0.04313353821635246, -0.01550967711955309, -0.02112027071416378, 0.012007254175841808, 0.021819422021508217, 0.022661035880446434, 0.02016194351017475, 0.011448567733168602, 0.02611679956316948, -0.015411997213959694, -0.024859292432665825, 0.034732379019260406, 0.011362106539309025, -0.0256086103618145, 0.030767546966671944, -0.0021167488303035498, 0.0036061936989426613, -0.02084812894463539, -0.011469589546322823, -0.0031306592281907797, 0.007189557887613773, 0.0555252805352211, -0.04976528137922287, 0.03368769958615303, 0.0034899816382676363, -0.0351484939455986, 3.7514284485951066e-05, -0.03383517265319824, -0.06104842945933342, 0.03116459958255291, 0.002852177480235696, 0.04724198952317238, -0.024857427924871445, -0.022192737087607384, 0.028115950524806976, 0.0009929236257448792, 0.03187943249940872, 0.0318249948322773, 0.034289002418518066, -0.002541912253946066, -0.014016556553542614, -0.008351655676960945, 0.017810000106692314, -0.002896843943744898, 0.013747891411185265, -0.022729454562067986, -0.005525962915271521, -0.014540374279022217, -0.03838631883263588, 0.036047469824552536, 0.03403507545590401, 0.01107743103057146, -0.0006203383090905845, 0.05033491179347038, -0.03403734043240547, 0.035419583320617676, 0.016989413648843765, 0.033980466425418854, -0.021730594336986542, -0.06219226121902466, -0.00020702602341771126, -0.036157891154289246, -0.009874565526843071, 0.019274426624178886, -0.024069154635071754, -0.010728124529123306, 0.04000350832939148, -0.016419250518083572, 0.0010384288616478443, -0.007725208532065153, -0.017124615609645844, 0.01415914949029684, 0.014400909654796124, -0.023648502305150032, -0.03153397887945175, -0.04375685751438141, 0.029157083481550217, 0.015773538500070572, -0.04254060238599777, 0.004625184927135706, -0.025547904893755913, 0.0003785094595514238, 0.03035460226237774, -0.04414090886712074, -0.02280574105679989, -0.008643358945846558, -0.0276023056358099, -0.034785568714141846, 0.0607077032327652, 0.02748638205230236, -0.029312051832675934, 0.0033539487048983574, -0.060336701571941376, 0.006470909807831049, -0.008379348553717136, 0.0017228382639586926, -0.000283963221590966, 0.04792499169707298, -0.006357430014759302, 0.025662893429398537, 0.03421998396515846, -0.00423864321783185, -0.03061133623123169, 0.01504621934145689, -0.03978091478347778, 0.008462362922728062, -0.038775861263275146, -0.0032605354208499193, -0.03062242828309536, -0.03295452892780304, -0.004528386052697897, 0.006188454106450081, 0.0349218025803566, -0.003907917067408562, 0.00919185671955347, 0.04759099334478378, -0.0153488265350461, -0.026023019105196, 0.025268632918596268, 0.014461792074143887, -0.020556103438138962, 0.06579208374023438, 0.015353423543274403, -0.01762060448527336, 0.006231398321688175, 0.007768761832267046, 0.008391170762479305, 0.018185239285230637, -0.01635979488492012, 0.017927492037415504, -0.018167976289987564, -0.034443579614162445, 0.007764338981360197, -0.03183954954147339, 0.056916456669569016, 0.008397163823246956, -0.022712890058755875, 0.002892129123210907, -0.0404246523976326, -0.028141947463154793, 0.025085968896746635, -0.017317555844783783, -0.008535111322999, -0.0021302306558936834, -0.03324160352349281, 0.02760414034128189, -0.0472877062857151, -0.059315089136362076, -0.037319086492061615, 0.004418018739670515, -0.007396972272545099, 0.02542438544332981, 0.057460326701402664, 0.034129124134778976, -0.025682514533400536, -0.04510020464658737, 0.059088610112667084, -0.016695190221071243, -0.02609560266137123, -0.0335986502468586, -0.004971872549504042, -0.01433389913290739, 0.00812247209250927, -0.02864380180835724, -0.00583101250231266, 0.013270612806081772, -0.0021486436016857624, 0.02130822092294693, -0.02269674465060234, 0.022129882127046585, -0.023228490725159645, -0.03767315298318863, 0.05117496848106384, -0.010019844397902489, -0.07322286814451218, -0.03377802297472954, 0.013269620016217232, 0.007073282264173031, 0.013037294149398804, 0.030767370015382767, 0.005819983780384064, -0.02150982804596424, -0.04455214738845825, 0.04645279794931412, -0.032026223838329315, 0.008614946156740189, -0.027928730472922325, -0.02627735584974289, 0.029946397989988327, 0.004090519621968269, 0.04697813838720322, -0.03456897661089897, -0.032283175736665726, -0.03241458907723427, 0.052490029484033585, -0.04887185990810394, -0.024819133803248405, -0.020202169194817543, -0.005962205119431019, -0.023422839120030403, 0.054059386253356934, 0.006305036135017872, 0.00552941532805562, -0.0026995581574738026, 0.014170315116643906, 0.015933414921164513, 0.04322218522429466, -0.037610333412885666, -0.01336726825684309, 0.011332589201629162, 0.015395582653582096, 0.030306311324238777, -0.008894423954188824, -0.03589322790503502, 0.018768712878227234, -0.02884644828736782, 0.012518144212663174, -0.04247618839144707, -0.004177476745098829, -0.027836056426167488, -0.028249062597751617, 0.04514253884553909, -0.054019682109355927, -0.01591106876730919, -0.022987069562077522, 0.03964501991868019, 0.000684377911966294, 0.015210114419460297, -0.05769820511341095, -0.005282641854137182, -0.04441092908382416, -0.005167517811059952, -0.009633613750338554, -0.04795396700501442, 0.009756715968251228, 0.007217180449515581, -0.006720818113535643, 0.024685144424438477, -0.07521794736385345, 0.031163565814495087, 0.07333942502737045, 0.008139979094266891, 0.011212793178856373, -0.05969620496034622, 0.012478210031986237, -0.00044678724952973425, 0.012150971218943596, 0.000915181590244174, -0.017145121470093727, -0.04460355266928673, -0.017492324113845825, -0.03742222860455513, -0.007489321753382683, -0.014716443605720997, -0.001909521990455687, 0.07212593406438828, -0.030457044020295143, 0.02086229994893074, 0.02309148944914341, -0.05381259322166443, -0.04599872604012489, 0.038458049297332764, -0.0018362809205427766, 0.016241205856204033, 0.007117790170013905, 0.011378935538232327, -0.03307993710041046, -0.016962647438049316, -0.028349660336971283, -0.027866046875715256, 0.006054244469851255, 0.05746278539299965, -0.007174611557275057, -0.049830012023448944, 0.04363517835736275, 0.0489736907184124, -0.021227456629276276, -0.03238637000322342, 0.03003162145614624, -0.0025458515156060457, -0.005935838911682367, -0.014085915870964527, -0.008812643587589264, 0.008055328391492367, -0.0019017887534573674, -0.008997712284326553, 0.03607131540775299, -0.028895100578665733, -0.005271571222692728, 0.018623990938067436, -0.0035320983733981848, -0.05187532305717468, 0.0411769300699234, 0.046034492552280426, -0.024052070453763008, -0.006611563265323639, -0.0180189311504364, -9.046764171216637e-05, -0.0013363705947995186, -0.01109592616558075, 0.05635589733719826, -0.02753707766532898, -0.006787409074604511, 0.03307242691516876, -0.008776381611824036, 0.044368039816617966, -0.023106465116143227, -0.009216480888426304, 0.042108338326215744, -0.060145072638988495, -0.029762206599116325, -0.03195519372820854, 0.032155826687812805, 0.013806566596031189, 0.052146438509225845, -0.0021297368220984936, 0.03318589925765991, 0.008283103816211224, 0.036039985716342926, 0.019601643085479736, -0.04689612612128258, -0.008443613536655903, -0.04162639379501343, -0.014875363558530807, 0.012410225346684456, -0.035425301641225815, 0.020737923681735992, 0.03573666512966156, 0.006213260814547539, -0.032118912786245346, -0.0038716744165867567, 0.01383889839053154, -0.0706089586019516, -0.01842935010790825, -0.02922486700117588, 0.03305228054523468, -0.06728245317935944, 0.016857493668794632, 0.01492823101580143, -0.012443234212696552, 0.005702362861484289, -0.00697386683896184, -0.024347180500626564, 0.02150171808898449, 0.022938735783100128, 0.02799355983734131, -0.028682038187980652, 0.003500882303342223, -0.031020184978842735, 0.010022226721048355, -0.022329382598400116, -0.0010904795490205288, -0.046638213098049164, 0.03793700411915779, -0.004792453721165657, -0.04052578657865524, -0.010488877072930336, -0.022376811131834984, 0.0015806978335604072, -0.04051604121923447, 0.0016340797301381826, 0.04833922162652016, -0.01751229166984558, 0.011743584647774696, -0.01054221298545599, 0.01902167685329914, -0.02125333622097969, -0.01203024573624134, -0.016905013471841812, -0.025007275864481926, 0.0065840245224535465, 0.03241833299398422, 0.023398257791996002, 0.06236065924167633, 0.06574700772762299, 0.02800336293876171, 0.02823498100042343, 0.030604878440499306, 0.029987581074237823, 0.026948612183332443, 0.026557954028248787, -0.009138315916061401, -0.03644939139485359, -0.034186579287052155, 0.0389738529920578, 0.03678770735859871, -0.016849305480718613, 0.025147011503577232, 0.0013797851279377937, -0.0015548091614618897, -0.029906604439020157, -0.0073496634140610695, 0.02650834433734417, 0.03699988126754761, 0.04683385416865349, -0.04008367285132408, -0.006353575736284256, 0.003299425356090069, -0.018530504778027534, 0.017549410462379456, -0.05231817066669464, -0.03470717743039131, -0.005597244016826153, -0.02007497102022171, -0.012972255237400532, -0.004777590278536081, -0.010754276067018509, 0.009544341824948788, 0.017191104590892792, 0.007692091632634401, 0.008491139858961105, 0.02150367572903633, -0.002269218908622861, -0.0031035258434712887, -0.04081778600811958, -0.06413307040929794, -0.026348691433668137, 0.01988593302667141, -0.05076722428202629, -0.051906436681747437, 0.011166045442223549, 0.0644899234175682, 0.012498580850660801, -0.006507910322397947, -0.06394095718860626, 0.004209428559988737, -0.009768565185368061, 0.011301449500024319, -0.08666082471609116, 0.019332781434059143, -0.023067766800522804, -0.010995603166520596, 0.002178963040933013, 0.005042775068432093, -0.007520362734794617, 0.0180867537856102, 0.012589036487042904, 0.015856456011533737, -0.015226338058710098, 0.017447136342525482, 0.03443794697523117, -0.022877614945173264, 0.04730742797255516, 0.013716209679841995, 0.01777208037674427, 0.014938023872673512, 0.019929971545934677, 0.021967783570289612, 0.02113046869635582, 0.043026261031627655, 0.03380690515041351, -0.01855550706386566, 0.044924844056367874, 0.030961833894252777, -0.045725446194410324, -0.01342758908867836, 0.04909726232290268, 0.0021698931232094765, -0.03042691759765148, -0.01783246546983719, -0.05350847169756889, 0.017566995695233345, -0.002335717435926199, 0.0021022497676312923, 0.003915050532668829, -0.01392976101487875, 0.008091862313449383, -0.035514023154973984, -0.029417172074317932, 0.0260948333889246, -0.013995390385389328, -0.06554634869098663, -0.014511855319142342, 0.015548193827271461, 0.008196821436285973, 0.027511226013302803, 0.035031914710998535, 0.0018135013524442911, 0.057646457105875015, 0.022638145834207535, 0.04523225128650665, 0.02079041860997677, -0.0011310736881569028, 0.021849416196346283, -0.005835651885718107, 0.016394956037402153, -0.046823736280202866, -0.007432672195136547, 0.006494087167084217, -0.008796253241598606, -0.02165284752845764, 0.04713316261768341, 0.007034373935312033, -0.029087087139487267, -0.0019565715920180082, -0.00906333141028881, -0.023831216618418694, -0.027724241837859154, 0.014549681916832924, -0.04528189077973366, -0.0011758083710446954, 0.053955916315317154, -0.05311838164925575, -0.027009708806872368, 0.025522330775856972, -0.003477785037830472, 0.025943350046873093, 0.03370000049471855, 0.053739484399557114, -0.005392652470618486, 0.08233147114515305, 0.030095579102635384, 0.02681918255984783, 0.011663194745779037, 0.03063046559691429, -0.006665337365120649, 0.007051933091133833, 0.016070345416665077, -0.008983544073998928, 0.01025949977338314, -0.0029396938625723124, -0.06868571788072586, 0.02868238091468811, 0.0032947291620075703, -0.009485755115747452, 0.008293848484754562, 0.018359443172812462, 0.027062799781560898, -0.047181107103824615, -0.016918417066335678, 0.06319615989923477, 0.013590814545750618, 0.026912808418273926, -0.01047134306281805, 0.0002569833886809647, -0.07099545747041702, 0.023739604279398918, -0.006704430095851421, 0.04181794822216034, -0.011593218892812729, -0.04861767217516899, 0.02987518161535263, -0.05907382443547249, -0.02973766252398491, -0.018681515008211136, -0.0023042706307023764, -0.03857363015413284, 0.026338564231991768, 0.006391997914761305, 0.053096115589141846, 0.002691439585760236, -0.02623743563890457, -0.05236935615539551, 0.04971812665462494, 0.037413474172353745, 4.798103327630088e-05, 0.05278157815337181, 0.0648600310087204, -0.007067573256790638, -0.035603344440460205, 0.005866542924195528, 0.0009633955196477473, -0.008833719417452812, 0.004256025888025761, -0.026081178337335587, -0.0010210926411673427, -0.035841964185237885, -0.0659271702170372, 0.012486638501286507, 0.034562692046165466, 0.056193023920059204, -0.02545693889260292, -0.02769426815211773, -0.0024827132001519203, -0.056904617697000504, -0.010975382290780544, -0.0395621657371521, 0.028085244819521904, 0.005715442355722189, -0.017459135502576828, 0.010116341523826122, -0.029338788241147995, 0.25463151931762695, 0.0716642513871193, 0.028357192873954773, 0.03890451788902283, 0.014323195442557335, 0.02596404030919075, 0.03839344158768654, -0.01633695513010025, 0.041884176433086395, -0.04486702382564545, 0.00209932797588408, -0.022694367915391922, 0.007188068702816963, 0.03608684614300728, -0.04565180465579033, 0.006010027136653662, -0.05089734494686127, -0.0035136376973241568, -0.03386697545647621, -0.025337843224406242, -0.03257627412676811, 0.01845681108534336, 0.009634420275688171, 0.017740599811077118, 0.012231048196554184, -0.01846317946910858, -0.003272464033216238, -0.034153882414102554, 0.03115384466946125, -0.0191359780728817, -0.009513938799500465, -0.04535571485757828, 0.035391949117183685, -0.011723049916327, -0.024879025295376778, 0.0030617062002420425, -0.00653942720964551, -0.05744599550962448, 0.00653440784662962, 0.02534973807632923, -0.015912547707557678, 0.002940735314041376, -0.0036047445610165596, -0.024414191022515297, -0.020538942888379097, 0.06782546639442444, 0.005274514202028513, 0.03456665202975273, 0.04940968006849289, -0.07699199765920639, 0.04190004616975784, -0.03859223052859306, 0.03344801068305969, -0.04119391366839409, -0.05555375665426254, -0.011592630296945572, -0.003911474719643593, -0.051825135946273804, -0.025263726711273193, 0.006515040528029203, -0.002689637942239642, 0.0110677070915699, -0.005141955800354481, 0.04190057888627052, -0.01863771490752697, 0.01642271876335144, 0.027925096452236176, -0.006806899327784777, -0.03745333105325699, -0.02440793067216873, 0.014376227743923664, -0.006584885064512491, -0.011366811580955982, -0.03418954089283943, 0.04068939387798309, 0.016148535534739494, 0.004008094314485788, 0.0402822270989418, 0.015414346009492874, -0.03344324976205826, -0.01823928952217102, -0.007062249816954136, -0.016977583989501, -0.04751558229327202, 0.033079516142606735, 0.043174292892217636, -0.01283009722828865, 0.01198237482458353, -0.024115338921546936, 0.0384632833302021, -0.03459926322102547, 0.018286647275090218, -0.013939186930656433, -0.022174308076500893, 0.0069691832177340984], metadata={'page_label': '1', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='tions (by up to 5–46% and 16–40%, respectively). On top of that, DSPy pro-\\ngrams compiled to open and relatively small LMs like 770M-parameter T5 and\\nllama2-13b-chat are competitive with approaches that rely on expert-written\\nprompt chains for proprietary GPT-3.5.\\nDSPy is available at https://github.com/stanfordnlp/dspy.\\n1 I NTRODUCTION\\nLanguage models (LMs) are enabling researchers to build NLP systems at higher levels of abstrac-\\ntion and with lower data requirements than ever before (Bommasani et al., 2021). This is fueling an\\nexploding space of “prompting” techniques—and lightweight finetuning techniques—for adapting\\nLMs to new tasks (Kojima et al., 2022), eliciting systematic reasoning from them (Wei et al., 2022;\\nWang et al., 2022b), andaugmenting them with retrieved sources (Guu et al., 2020; Lazaridou et al.,\\n2022; Khattab et al., 2022) or with tools (Yao et al., 2022; Schick et al., 2023). Most of these tech-\\nniques are explored in isolation, but interest has been growing in building multi-stage pipelines and\\nagents that decompose complex tasks into more manageable calls to LMs in an effort to improve\\nperformance (Qi et al., 2019; Khattab et al., 2021a; Karpas et al., 2022; Dohan et al., 2022; Khot\\net al., 2022; Khattab et al., 2022; Chen et al., 2022; Pourreza & Rafiei, 2023; Shinn et al., 2023).\\nUnfortunately, LMs are known to be sensitive to how they are prompted for each task, and this is\\nexacerbated in pipelines where multiple LM calls have to interact effectively. As a result, the LM\\n1\\narXiv:2310.03714v1  [cs.CL]  5 Oct 2023', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d1d8d5d2-b0da-4eed-a23e-a49ed515ccf4', embedding=[0.030446961522102356, -0.0044907270930707455, -0.003785894252359867, -0.013359595090150833, -0.02220918796956539, -0.02943582274019718, -0.016300639137625694, -0.035079676657915115, -0.007342954631894827, 0.06663914769887924, -0.011830538511276245, -0.016180861741304398, -0.014593931846320629, -0.022818835452198982, -0.0228523388504982, 0.0004109170404262841, -0.017983393743634224, -0.022213788703083992, -0.06374999135732651, -0.007363693788647652, 0.03346504271030426, -0.004221966955810785, -0.08261122554540634, -0.014605882577598095, -0.04462534934282303, 0.029987329617142677, 0.013356436975300312, 0.004559672903269529, 0.07907582819461823, 0.056075599044561386, 0.012335950508713722, -0.009332846850156784, 0.0072099086828529835, -0.036418307572603226, -0.031245768070220947, -0.05883434787392616, -0.00043822010047733784, -0.018943343311548233, -0.017322886735200882, -0.005042339209467173, 0.04489298164844513, -0.02398790419101715, 0.04559137672185898, -0.06459023058414459, -0.08465403318405151, -0.00965107325464487, 0.006526458077132702, -0.01389541570097208, -0.012836278416216373, -0.037836577743291855, -0.012722766026854515, 0.015577846206724644, 0.008711433969438076, -0.0003740050597116351, -0.03046605736017227, -0.0058137113228440285, -0.008394161239266396, -0.0199082363396883, -0.03228425979614258, 0.0007569340523332357, -0.00560660008341074, 0.005228389985859394, -0.010121311992406845, -0.05504792183637619, -0.0023667425848543644, 0.018047384917736053, 0.0054846652783453465, -0.013709616847336292, -0.025280464440584183, -0.017417334020137787, -0.07904960215091705, 0.025630848482251167, -0.02630280889570713, -0.04521671310067177, -0.009169463068246841, -0.020726636052131653, 0.030105765908956528, -0.001364253112114966, -0.034294139593839645, 0.052919406443834305, 0.021162960678339005, 0.05507213994860649, -0.012898560613393784, 0.02202177792787552, -0.015081420540809631, -0.03947758302092552, 0.05133446678519249, -0.007040636148303747, -0.023610221222043037, -0.02300977148115635, 0.002411474473774433, 0.026021281257271767, 0.02628922648727894, 0.02500993199646473, 0.043485138565301895, 0.07484319061040878, -0.00558562483638525, 0.04360125586390495, -0.018427181988954544, -0.007319827564060688, 0.04872249811887741, 0.08136139810085297, -0.029480135068297386, 0.02714209072291851, -0.05667576566338539, -0.00983023177832365, 0.05000780522823334, -0.016490362584590912, -0.02213129587471485, -0.038530535995960236, 0.004298102576285601, 0.000547446368727833, -0.023156454786658287, 0.006769840139895678, -0.044244252145290375, 0.024571560323238373, 0.024445008486509323, 0.01636727713048458, -0.022712938487529755, -0.016871822997927666, 0.0012103506596758962, -0.025222355499863625, -0.009131659753620625, 0.0019828856457024813, 0.015245315618813038, -0.025562206283211708, 0.007588742766529322, 0.04977544769644737, -0.029996508732438087, -0.006825966294854879, 0.006115240510553122, 0.013801131397485733, -0.012150583788752556, 0.07714793086051941, 0.009011960588395596, 0.00251961313188076, 0.017742952331900597, 0.01564948819577694, 0.019901178777217865, -0.0015841486165300012, 0.009993722662329674, -0.045441433787345886, 0.011769657023251057, 0.11142987012863159, 0.0005531276110559702, -0.003809057641774416, -0.017052728682756424, -0.01172378845512867, -0.04663063585758209, 0.05718950927257538, -0.00653979042544961, 0.012743508443236351, 0.019557418301701546, 0.018237970769405365, -0.02455127239227295, 0.007848509587347507, -0.016284286975860596, -0.013684582896530628, 0.006075074430555105, 0.020298272371292114, -0.011973286047577858, -0.013559181243181229, -0.026560889557003975, 0.02503340318799019, -0.017582880333065987, 0.04826447740197182, -0.05520882457494736, -0.028897281736135483, 0.004284224938601255, -0.04045788571238518, 0.02460160292685032, -0.0054610189981758595, -0.014285511337220669, 0.02298576571047306, 0.07514090090990067, 0.04442288726568222, 0.03397538512945175, -0.003208835143595934, 0.032254528254270554, -0.003279957454651594, -0.017402226105332375, -0.003245083848014474, 0.013705866411328316, -0.0060579897835850716, 0.013903639279305935, 0.0534106083214283, -0.0017250677337870002, 0.011494250036776066, -0.008753341622650623, 0.014335141517221928, 0.011968269944190979, 0.05029680207371712, -0.020527107641100883, 0.01683127135038376, 0.023761091753840446, 0.0066177211701869965, -0.01232973299920559, 0.03898933157324791, 0.033263251185417175, -0.04219759255647659, -0.02047419361770153, 0.05280686542391777, 0.0007167367148213089, -0.023461226373910904, -0.060180261731147766, 0.008396929129958153, -0.010131927207112312, 0.06990129500627518, -0.03829367458820343, 0.01837247610092163, 0.027019362896680832, 0.008455400355160236, -0.04196184128522873, 0.011780614033341408, 0.01974586583673954, -0.020323894917964935, -0.03397459164261818, -0.012939678505063057, 0.02453266642987728, 0.015378235839307308, -0.003402625909075141, -0.00804199930280447, 0.012951895594596863, -0.023056726902723312, -0.00997807364910841, -0.0037414622493088245, 0.0320863239467144, 0.029298588633537292, -0.0006862803129479289, -0.007789977360516787, 0.02267889864742756, 0.025248723104596138, -0.015435904264450073, 0.05303950607776642, 0.02520846016705036, 0.01509528886526823, 0.06082439050078392, 0.07015222311019897, -0.00280701438896358, 0.00426093814894557, -0.0054838936775922775, 0.014614508487284184, 0.0036496345419436693, 0.04698755219578743, 0.0085779232904315, 0.017347022891044617, -2.064581713057123e-05, 0.005906015168875456, -0.038005806505680084, 0.013473853468894958, -0.06920146197080612, 0.04473210126161575, 0.020655693486332893, -0.021809250116348267, -0.02205093763768673, -0.027786383405327797, -0.006430270150303841, 0.024714576080441475, -0.020336057990789413, -0.01928972266614437, 0.04370473325252533, 0.03299162536859512, -0.010088352486491203, -0.009235359728336334, 0.029411640018224716, 0.011999526992440224, -0.0007754267426207662, 0.041173651814460754, 0.001761571504175663, -0.016260627657175064, -0.04280078411102295, -0.046884454786777496, -0.08126650750637054, 0.009933671914041042, -0.0411091111600399, -0.0038612238131463528, 0.0013325400650501251, -0.05010966956615448, 0.017958717420697212, -0.03452560678124428, 0.013575133867561817, 0.002944857580587268, -0.025620296597480774, 0.03292454779148102, 0.05998409539461136, 0.013994012027978897, -0.06550249457359314, 0.03300754725933075, -0.04042841121554375, 0.06734273582696915, -0.005612150300294161, -0.004330368246883154, -0.014338052831590176, 0.00630298163741827, 0.03708898648619652, -0.001564865349791944, 0.004043631721287966, -0.03369583934545517, -0.049271270632743835, -0.01499002706259489, -0.0006339455139823258, -0.03891649842262268, 0.029296254739165306, -0.028179652988910675, -0.045684583485126495, 0.06614800542593002, 0.0028847367502748966, -0.04548581317067146, 0.05254748463630676, 0.03323741629719734, -0.045295339077711105, 0.036921851336956024, -0.004114973358809948, 0.017625581473112106, -0.028782108798623085, 0.08066385984420776, 0.013354996219277382, -0.018962804228067398, -0.01826898381114006, -0.06954683363437653, -0.043645381927490234, 0.013574819080531597, -0.004180808551609516, -0.032982081174850464, -0.020909540355205536, 0.04557296633720398, -0.013199451379477978, -0.07531769573688507, -0.00278755696490407, -0.03890911489725113, -0.03787684068083763, 0.012754926458001137, 0.009309889748692513, 0.05061773583292961, 0.01820489950478077, 0.027746064588427544, -0.027324112132191658, 0.018090948462486267, -0.023512354120612144, 0.010171594098210335, 0.006625363137573004, -0.0301015917211771, -0.003295602509751916, 0.0397237166762352, -0.001172028249129653, 0.01774790696799755, 0.018207786604762077, -0.05056627094745636, -0.00813962984830141, -0.03242630511522293, -0.002179842907935381, 0.011080892756581306, -0.002932298695668578, 0.019041847437620163, 0.01976519264280796, 0.016497232019901276, -0.041691891849040985, -0.031061705201864243, -0.0025179816875606775, 0.03989604860544205, -0.0003647085395641625, 0.06304703652858734, -0.015376810915768147, -0.0006199803901836276, -0.04010831192135811, -0.02285928465425968, -0.03184407204389572, 0.012656381353735924, 0.04351617395877838, -0.033338215202093124, 0.04626913741230965, 0.0030739768408238888, -0.03229060024023056, -0.006308367941528559, -0.028130022808909416, -0.057265281677246094, 0.02466673031449318, 0.027851872146129608, 0.049678463488817215, -0.01571047119796276, -0.04373394697904587, 0.018673304468393326, 0.017024299129843712, 0.0305417962372303, 0.03508756682276726, 0.05074768885970116, 0.013778683729469776, 0.001588722807355225, -0.028185470029711723, 0.009029736742377281, -0.00842520222067833, 0.02894965186715126, -0.011360637843608856, -0.011043558828532696, -0.022164631634950638, -0.04116082563996315, 0.032600339502096176, 0.04552767425775528, 0.018449626863002777, 0.00701539171859622, 0.036651402711868286, -0.025058934465050697, 0.03741678223013878, 0.012327042408287525, 0.022722523659467697, 0.0008591992664150894, -0.06641338020563126, 0.0038643560837954283, -0.02299058996140957, 0.017874443903565407, 0.007180380169302225, -0.016248049214482307, 0.002161461627110839, 0.026448754593729973, -0.016518598422408104, 0.0019586256239563227, -0.003934609703719616, -0.019204039126634598, 0.035951245576143265, 0.0355849415063858, -0.039727047085762024, -0.01922519877552986, -0.03234655782580376, -0.0032470757141709328, 0.04240887239575386, -0.029794631525874138, -0.0036410330794751644, -0.023936264216899872, 0.003806676482781768, 0.03377235680818558, -0.049879007041454315, -0.01998727209866047, 0.0071514686569571495, -0.03484702482819557, -0.05274207890033722, 0.07928893715143204, 0.029582349583506584, -0.05146292597055435, 0.015333888120949268, -0.03541112318634987, 0.011452649720013142, 0.009132103994488716, -0.004429092165082693, -0.001490752911195159, 0.03295169398188591, -0.02021455578505993, 0.032474979758262634, 0.03120529279112816, -0.016854355111718178, -0.035637225955724716, 0.014298457652330399, -0.06656453013420105, 0.02988147735595703, -0.04995505139231682, 0.014791524037718773, -0.03374941647052765, -0.025613944977521896, -0.007631711196154356, 0.0046592517755925655, 0.018267642706632614, -0.0020314273424446583, 0.010166645981371403, 0.02425956539809704, -0.04342469573020935, -0.05099421739578247, 0.041884928941726685, 0.013304363936185837, -0.0013899662299081683, 0.053977709263563156, 0.0015071408124640584, -0.02511471137404442, -0.0038151016924530268, 0.007140561006963253, -0.01600704900920391, 0.0038127396255731583, -0.017027003690600395, 0.011922265402972698, -0.018784958869218826, -0.03630788251757622, 0.005919171497225761, -0.052063073962926865, 0.03940703719854355, -0.023082658648490906, -0.03419489786028862, -0.0036640481557697058, -0.041700579226017, -0.018892372027039528, 0.012896864674985409, -0.016655508428812027, -0.008257897570729256, -0.004175492096692324, -0.026156922802329063, 0.029232719913125038, -0.022557925432920456, -0.04858731850981712, -0.031326260417699814, -0.018840176984667778, -0.019411412999033928, 0.02258387766778469, 0.055403001606464386, 0.048986274749040604, -0.024568917229771614, -0.052896689623594284, 0.04509184882044792, -0.01236283965408802, -0.022319357842206955, -0.018080493435263634, -0.0018192664720118046, -0.010852481238543987, -0.006124152336269617, -0.02857906185090542, -0.011254968121647835, 0.0025264983996748924, -0.005565166939049959, 0.015014810487627983, 0.00036493525840342045, 0.020520009100437164, -0.003389471909031272, -0.018274756148457527, 0.05510043725371361, -0.0035832193680107594, -0.07986557483673096, -0.03805553913116455, 0.02402435801923275, -0.026472285389900208, 0.010646775364875793, 0.025639429688453674, -0.011214194819331169, -0.033249225467443466, -0.037421248853206635, 0.0544622540473938, -0.045393917709589005, 0.0065803914330899715, -0.04182172566652298, -0.02510615810751915, 0.026919521391391754, -0.008601026609539986, 0.027639681473374367, -0.029533376917243004, -0.0399988628923893, -0.032940249890089035, 0.021505184471607208, -0.025627894327044487, -0.010928938165307045, -0.014966282993555069, -0.02436697483062744, -0.02278156951069832, 0.08345573395490646, -0.014063967391848564, -0.00719832070171833, -0.016021784394979477, 0.02139432355761528, 0.012328608892858028, 0.04686545208096504, -0.03304580599069595, -0.011929537169635296, -0.004046987276524305, 0.008333567529916763, 0.03702336549758911, 0.01564083620905876, -0.026294415816664696, -0.009089713916182518, -0.019424835219979286, -0.0008337441249750555, -0.034427061676979065, -0.01773206889629364, -0.013504177331924438, -0.0021444917656481266, 0.04542359709739685, -0.061915356665849686, 0.011523079127073288, -0.032760556787252426, 0.0414116308093071, -0.01914368011057377, 0.004234358202666044, -0.04112818092107773, 0.0012095823185518384, -0.04503478854894638, -0.03533252328634262, -0.0006813709624111652, -0.03551341965794563, 0.012239440344274044, 0.013734453357756138, -0.010586093179881573, 0.05193287506699562, -0.08529293537139893, 0.032533928751945496, 0.058976978063583374, 0.029385080561041832, 0.0008375428733415902, -0.028437599539756775, 0.00861184112727642, 0.0033862751442939043, -0.008951694704592228, 0.008039066568017006, -0.010140468366444111, -0.021481871604919434, -0.009671058505773544, -0.016801904886960983, -0.009255850687623024, -0.00239980174228549, 0.015553968027234077, 0.0549226813018322, -0.046785619109869, 0.027570052072405815, 0.005550284404307604, -0.0585818812251091, -0.03334738686680794, 0.03299391269683838, -0.008721868507564068, 0.016237767413258553, 0.016888616606593132, -0.007724161259829998, 0.00838905293494463, 0.001425514928996563, -0.035252660512924194, -0.04301440343260765, -0.0070585529319942, 0.061808738857507706, -0.005234072916209698, -0.01637161336839199, 0.03146202489733696, 0.03925550356507301, -0.019769709557294846, -0.04538038745522499, 0.015556616708636284, 0.008883642964065075, -0.0015315515920519829, -0.03405822813510895, -0.0067593553103506565, 0.007115201558917761, -0.033133648335933685, -0.0038061197847127914, 0.051837120205163956, -0.013059999793767929, 0.013503987342119217, 0.019379349425435066, -0.016223059967160225, -0.037783510982990265, 0.05579277500510216, 0.042357269674539566, -0.025898393243551254, -0.005664039868861437, -0.019182994961738586, -0.004489140119403601, 0.004357824567705393, -0.017106523737311363, 0.05715608224272728, -0.00866279099136591, 0.007995819672942162, 0.042071741074323654, 0.01409655250608921, 0.051071979105472565, -0.02658867835998535, -0.0011902762344107032, 0.019137343391776085, -0.024672960862517357, -0.04569188505411148, -0.031254373490810394, 0.00828642025589943, -0.017005378380417824, 0.039250727742910385, -0.0059476629830896854, 0.02488255873322487, 0.03216589242219925, 0.030429262667894363, 0.0032984071876853704, -0.06393003463745117, -0.009525255300104618, -0.052461571991443634, -0.012281589210033417, 0.019807498902082443, -0.04260151460766792, 0.019297106191515923, 0.03460538759827614, -0.008536524139344692, -0.018106652423739433, -0.033539190888404846, 0.018356505781412125, -0.04893248528242111, -0.012774263508617878, -0.015814974904060364, 0.016916293650865555, -0.044430460780858994, 0.009097118861973286, -0.0089698676019907, 0.00267593702301383, -0.015981249511241913, -0.01587824523448944, -0.032184094190597534, -0.00272228941321373, 0.011895672418177128, 0.024168118834495544, -0.00776322279125452, 0.00478935893625021, -0.019721806049346924, 0.004296041093766689, -0.014524843543767929, 0.009467348456382751, -0.03021182492375374, 0.05307820811867714, 0.007394770160317421, -0.021301014348864555, 0.01046496257185936, -0.005672832485288382, -0.013704780489206314, -0.028528552502393723, 0.0056284223683178425, 0.03989648446440697, -0.020095156505703926, 0.02060248702764511, -0.025822903960943222, 0.039220117032527924, -0.037773001939058304, -0.018468692898750305, 0.005021779332309961, -0.02361968904733658, 0.002216577995568514, 0.008335873484611511, 0.017851928249001503, 0.06402809172868729, 0.03307430073618889, 0.03866814821958542, 0.02976500429213047, 0.012979887425899506, 0.03184836357831955, 0.01636534556746483, 0.01791958138346672, -0.010349131189286709, -0.010815180838108063, -0.04715961217880249, 0.035797037184238434, 0.020006364211440086, -0.014191132970154285, 0.025485778227448463, 0.0045956517569720745, -0.033437587320804596, -0.032471634447574615, 0.007274322677403688, 0.016640203073620796, 0.03896837309002876, 0.047020323574543, -0.033028893172740936, -0.01226440817117691, -0.01014760322868824, -0.012319225817918777, 0.014760017395019531, -0.0614328607916832, -0.02511783130466938, 0.016587842255830765, -0.04134248569607735, -0.017510706558823586, -0.005799179896712303, 0.010057742707431316, -0.010408114641904831, 0.028980104252696037, 0.027382902801036835, -0.011238829232752323, 0.019330721348524094, 0.001479743281379342, -0.0038410425186157227, -0.04627061262726784, -0.04046645015478134, -0.0033923627343028784, 0.012671491131186485, -0.04298965260386467, -0.05182827636599541, 0.012505823746323586, 0.05271243304014206, 0.00812448374927044, -0.009584559127688408, -0.06274933367967606, 0.005113615188747644, -0.017709990963339806, 0.03989335522055626, -0.07080138474702835, 0.03264883905649185, -0.009218603372573853, 0.01887190341949463, -0.010615803301334381, 0.0147529486566782, -0.014898673631250858, 0.03760785609483719, 0.0270107239484787, 0.004661137238144875, -0.018585937097668648, 0.037656258791685104, 0.01806807518005371, -0.030918041244149208, 0.05162891745567322, -0.015151211991906166, 0.022601068019866943, 0.01738705113530159, -0.012526814825832844, 0.02862369641661644, 0.015542985871434212, 0.03499346226453781, 0.020587852224707603, -0.013667559251189232, 0.07194191217422485, 0.041993364691734314, -0.028247032314538956, 0.006822593044489622, 0.025765763595700264, 0.02001482993364334, -0.017973946407437325, -0.027036838233470917, -0.05658242106437683, 0.009375443682074547, -0.026219891384243965, 0.01917208731174469, 0.022496899589896202, -0.018542926758527756, 0.009832197800278664, -0.02486901544034481, -0.04791610687971115, 0.025081099942326546, 0.01344890147447586, -0.07387110590934753, -0.006556362845003605, -0.0010525289690122008, 0.04863948002457619, 0.032105181366205215, 0.030429450795054436, 0.012515900656580925, 0.05243328586220741, 0.018852688372135162, 0.03051317296922207, -0.01111147552728653, -0.0003307470469735563, 0.020010827109217644, -0.010701458901166916, 0.008655944839119911, -0.0068145813420414925, 0.034307073801755905, 0.013293096795678139, -0.00573409628123045, 0.005229330621659756, 0.07966382801532745, 0.000896990008186549, -0.028165092691779137, -0.003923469688743353, -0.013700895011425018, -0.015615829266607761, -0.048854000866413116, 0.04448168724775314, -0.022672800347208977, 0.00438150716945529, 0.04456522315740585, -0.01840301603078842, -0.02623218484222889, 0.03156929835677147, 0.00334984646178782, 0.018397213891148567, 0.0216936357319355, 0.04664004221558571, 0.0046801576390862465, 0.07078710943460464, 0.052748169749975204, 0.026759201660752296, 0.013939973898231983, 0.030312368646264076, 0.0015634505543857813, -0.022257139906287193, 0.006718763615936041, -0.019516007974743843, -0.016742972657084465, -0.022249111905694008, -0.061563290655612946, 0.027701186016201973, 0.009203854016959667, -0.018324339762330055, 0.016582265496253967, -0.0030726026743650436, 0.006603164132684469, -0.049911003559827805, 0.000513510312885046, 0.05151863396167755, 0.010091259144246578, 0.038025014102458954, 0.007907584309577942, 0.01576094515621662, -0.054259996861219406, 0.01856185495853424, -0.017522327601909637, 0.01141861081123352, -0.011560512706637383, -0.026438791304826736, 0.02160370908677578, -0.05028514191508293, -0.021633554250001907, -0.05415993928909302, -0.0028543686494231224, -0.02734767273068428, 0.023450007662177086, 0.0018843706930056214, 0.04878685995936394, 0.004836661741137505, -0.03293281048536301, -0.004495309200137854, 0.062115419656038284, 0.04321589320898056, 0.015537680126726627, 0.07304326444864273, 0.06424449384212494, -0.0016449785325676203, -0.029337720945477486, 0.004420022945851088, -0.005227141547948122, -0.0050501576624810696, 0.01033030916005373, -0.00428706593811512, 0.007526655215770006, -0.008605814538896084, -0.04654083400964737, 0.014327911660075188, 0.04351599141955376, 0.030024023726582527, -0.013276121579110622, -0.03147830069065094, -0.017511077225208282, -0.0392637774348259, -0.0104835145175457, -0.05233846604824066, 0.00960463471710682, 0.014949509873986244, -0.0039355759508907795, 0.006406751461327076, -0.01449627336114645, 0.24607829749584198, 0.07234038412570953, 0.013224299997091293, 0.019560301676392555, 0.02303536795079708, 0.05776841193437576, 0.029211444780230522, -0.029990462586283684, 0.0198582261800766, -0.03640998899936676, 0.031785883009433746, -0.039771754294633865, 0.007030778098851442, 0.02945215441286564, -0.0263499915599823, 0.024391761049628258, -0.06521657854318619, -0.015886113047599792, -0.04625057801604271, -0.03016495518386364, -0.0473034530878067, 0.029212798923254013, -0.012729024514555931, 0.0009927789214998484, 0.019824422895908356, 0.00042282321373932064, 0.0008486605365760624, -0.01853065751492977, 0.04310400038957596, -0.03991067036986351, -0.007636757101863623, -0.026233676820993423, 0.026154987514019012, -0.032390981912612915, -0.008707398548722267, 0.01860562525689602, -0.014483180828392506, -0.0244113989174366, 0.002797951688989997, 0.05172976851463318, -0.004776634741574526, -0.018556129187345505, 0.001941847731359303, -0.01388457603752613, -0.03508495166897774, 0.035857465118169785, 0.005837967153638601, 0.034450072795152664, 0.02494015358388424, -0.08507992327213287, 0.030965300276875496, -0.024902308359742165, 0.011520979925990105, -0.03830923140048981, -0.05087649077177048, 0.0017966051818802953, 0.016933277249336243, -0.03818947449326515, -0.04780491068959236, 0.012861392460763454, -0.0027676366735249758, 0.026823805645108223, 0.002647284884005785, 0.0464082732796669, -0.005638965871185064, 0.024829134345054626, 0.02899465523660183, -0.009976301342248917, -0.028098352253437042, -0.018774179741740227, 0.0008923103450797498, 0.0004147045547142625, -0.006140362937003374, -0.035702940076589584, 0.04691745340824127, 0.005139510612934828, 0.0019355973927304149, 0.04172935336828232, 0.0189674012362957, -0.052605628967285156, 0.0027130639646202326, -0.0074662198312580585, -0.03237036243081093, -0.02577214315533638, 0.0480303093791008, 0.05943034961819649, -0.0312713198363781, 0.002837762236595154, -0.019476793706417084, 0.01725955493748188, -0.009119781665503979, 0.0305648073554039, -0.006697481963783503, -0.008303780108690262, 0.005492343567311764], metadata={'page_label': '2', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\ncalls in existing LM pipelines and in popular developer frameworks are generally implemented using\\nhard-coded ‘prompt templates’, that is, long strings of instructions and demonstrations that are hand\\ncrafted through manual trial and error. We argue that this approach, while pervasive, can be brittle\\nand unscalable—conceptually akin to hand-tuning the weights for a classifier. A given string prompt\\nmight not generalize to different pipelines or across different LMs, data domains, or even inputs.\\nToward a more systematic approach to designing AI pipelines, we introduce theDSPy programming\\nmodel.1 DSPy pushes building new LM pipelines away from manipulating free-form strings and\\ncloser to programming (composing modular operators to build text transformation graphs) where a\\ncompiler automatically generates optimized LM invocation strategies and prompts from a program.\\nWe draw inspiration from the consensus that emerged around neural network abstractions (Bergstra\\net al., 2013), where (1) many general-purpose layers can be modularly composed in any complex\\narchitecture and (2) the model weights can be trained using optimizers instead of being hand-tuned.\\nTo this end, we propose the DSPy programming model(Sec 3). We first translate string-based\\nprompting techniques, including complex and task-dependent ones like Chain of Thought (Wei et al.,\\n2022) and ReAct (Yao et al., 2022), into declarative modules that carrynatural-language typed sig-\\nnatures. DSPy modules are task-adaptive components—akin to neural network layers—that abstract\\nany particular text transformation, like answering a question or summarizing a paper. We then pa-\\nrameterize each module so that it can learn its desired behavior by iteratively bootstrapping useful\\ndemonstrations within the pipeline. Inspired directly by PyTorch abstractions (Paszke et al., 2019),\\nDSPy modules are used via expressive define-by-run computational graphs. Pipelines are expressed\\nby (1) declaring the modules needed and (2) using these modules in any logical control flow (e.g.,\\nifstatements, for loops, exceptions, etc.) to logically connect the modules.\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c46fd112-5972-4141-85e5-9976eda7c393', embedding=[0.04351940378546715, 0.01375462394207716, -0.026599036529660225, -0.014547454193234444, -0.029913680627942085, -0.028854526579380035, -0.03592690825462341, 0.012038079090416431, -0.011782894842326641, 0.05149834603071213, 0.0013484214432537556, -0.0004849111719522625, 0.001003704615868628, -0.036726031452417374, -0.012398501858115196, -0.026386383920907974, -0.01590718887746334, -0.023914102464914322, -0.07453031092882156, 0.0009474329417571425, 0.02675972320139408, -0.011255418881773949, -0.060911666601896286, 0.005220451857894659, -0.035799261182546616, 0.0331626757979393, 0.012238558381795883, 0.015304343774914742, 0.07230058312416077, 0.0470772385597229, 0.030441757291555405, -0.00737646222114563, 0.004721856210380793, -0.04289478808641434, -0.027351945638656616, -0.044983066618442535, 0.008442921563982964, -0.003167032031342387, -0.02871686965227127, -0.002055536489933729, 0.014752797782421112, -0.026794496923685074, 0.045066602528095245, -0.07371769845485687, -0.088802769780159, -0.002820514375343919, 0.004307915456593037, -0.03991790488362312, -0.0032807437237352133, -0.009628135710954666, 0.0008734455332159996, 0.013570843264460564, 0.016719667240977287, -0.011492901481688023, -0.005463022738695145, 0.007266711443662643, 0.007561451755464077, -0.011531582102179527, -0.030274467542767525, 0.006460289470851421, 0.010946415364742279, 0.02742205187678337, -0.034479234367609024, -0.07221761345863342, -0.01266174204647541, 0.018622446805238724, 0.015359140932559967, -0.026668475940823555, -0.027263175696134567, -0.023619990795850754, -0.07871411740779877, 0.012887920252978802, -0.006847202777862549, -0.04294022172689438, -0.009589079767465591, -0.01032985094934702, 0.06519490480422974, 0.00045387737918645144, -0.04099423810839653, 0.0508519746363163, 0.02026296593248844, 0.04544481262564659, -0.006393331568688154, 0.016262482851743698, -0.027928143739700317, -0.059559836983680725, 0.07196713238954544, -0.016996830701828003, -0.0066851722076535225, -0.013630269095301628, -0.018389418721199036, 0.021945923566818237, 0.010477566160261631, 0.025838790461421013, 0.07153052091598511, 0.04771489277482033, -0.0035419873893260956, 0.024261904880404472, -0.0043822950683534145, 0.01298807468265295, 0.045048788189888, 0.05491887405514717, -0.011593938805162907, 0.029146255925297737, -0.04985671490430832, -0.017261631786823273, 0.0341268889605999, -0.010812724940478802, -0.02115430310368538, -0.024707984179258347, 0.0022193226031959057, 0.01716267131268978, -0.00964182335883379, 0.010230446234345436, -0.041026610881090164, 0.015186374075710773, 0.005296687129884958, 0.01577562652528286, -0.030241025611758232, -0.0022269785404205322, -0.004374031443148851, -0.01243570540100336, 0.009276749566197395, -0.004055400379002094, 0.033587317913770676, -0.035235874354839325, -0.003522520652040839, 0.0412001758813858, -0.04169624298810959, -0.014837018214166164, -0.0186410304158926, 0.010256080888211727, -0.0026327085215598345, 0.06554161012172699, 0.013931934721767902, 0.01457592286169529, -0.00777036976069212, 0.021115681156516075, 0.010523187927901745, -0.008930730633437634, 0.019163863733410835, -0.03473614156246185, 0.0035526270512491465, 0.10105550289154053, 0.01223541609942913, 0.0060396213084459305, -0.035736553370952606, -0.01322892028838396, -0.04014294221997261, 0.04287419468164444, -0.0050361244939267635, 0.012645943090319633, 0.0005934889777563512, 0.013273053802549839, -0.007325584534555674, -0.00877472572028637, -0.032199908047914505, -0.011717861518263817, 0.0049277786165475845, -0.0038085298147052526, -0.024475090205669403, -0.01682932861149311, -0.036788538098335266, 0.024849465116858482, -0.032843444496393204, 0.050644177943468094, -0.04442545026540756, -0.015571728348731995, 0.008410913869738579, -0.011766063049435616, 0.03104035183787346, -0.0026387900579720736, 0.014404259622097015, 0.02517283894121647, 0.05705849826335907, 0.07455120980739594, 0.053579241037368774, -0.006554946303367615, 0.011936059221625328, 0.0016440959880128503, -0.012331557460129261, -0.016679223626852036, 0.0022636286448687315, 0.007804470602422953, 0.004491702653467655, 0.037724100053310394, -0.0010750327492132783, 0.00149366888217628, -0.026734400540590286, 0.003992536570876837, -0.004326735157519579, 0.0523223876953125, -0.03352201730012894, 0.002061354462057352, 0.01021414715796709, 0.011895976029336452, 0.0051296548917889595, 0.03377833589911461, 0.010996461845934391, -0.04531874507665634, -0.0403645895421505, 0.07773221284151077, 0.017400674521923065, -0.003400459885597229, -0.04123145341873169, 0.008738593198359013, -0.023444173857569695, 0.05625109001994133, -0.05521231144666672, 0.0010839032474905252, 0.03133208304643631, 0.004217828623950481, -0.026866115629673004, 0.006932312622666359, 0.019765794277191162, -0.017705010250210762, -0.015208175405859947, -0.02658686414361, 0.02509141154587269, 0.0036911063361912966, 0.0027718935161828995, -0.013034299947321415, 0.009100721217691898, -0.019345587119460106, -0.010436192154884338, 0.00048108858754858375, 0.024892698973417282, 0.043396804481744766, -0.024622837081551552, 0.0180326160043478, 0.03250792250037193, 0.02359730750322342, -0.010718530975282192, 0.054220665246248245, 0.007397189736366272, 0.01941382698714733, 0.04225747287273407, 0.05655907839536667, -0.004180710297077894, -0.013091148808598518, -0.010000495240092278, 0.012211848050355911, 0.02411438524723053, 0.04652068763971329, -0.0070745451375842094, 0.03715750575065613, 0.004265724681317806, 0.02207597903907299, -0.047734688967466354, -0.011746174655854702, -0.074924997985363, 0.05020889639854431, 0.009115506894886494, -0.000613813113886863, -0.030792539939284325, -0.01843409612774849, 0.031118270009756088, 0.04453698545694351, -0.02150421030819416, -0.019042696803808212, 0.016036413609981537, 0.015574431046843529, 0.0047157336957752705, -0.015432154759764671, 0.01974549889564514, 0.01875767670571804, 0.012501043267548084, 0.04923845827579498, 0.0016806218773126602, -0.007369636092334986, -0.028166761621832848, -0.04323685169219971, -0.07436539977788925, -0.013859884813427925, -0.021398162469267845, -0.01737179048359394, -0.014867253601551056, -0.05062888562679291, -0.012170952744781971, -0.05079369619488716, 0.030422959476709366, -0.019760649651288986, -0.013797063380479813, 0.02500445954501629, 0.05520429462194443, 0.017908761277794838, -0.05794477462768555, 0.03043215349316597, -0.014482919126749039, 0.052473947405815125, 0.009554345160722733, -0.0038173620123416185, -0.012741473503410816, -0.0064895846880972385, 0.04116109013557434, -0.011685599572956562, 0.014055701903998852, -0.0076972488313913345, -0.04566119611263275, -0.030339041724801064, 0.0005481840926222503, -0.02636939100921154, 0.04159758612513542, -0.02156575210392475, -0.04943586885929108, 0.056419648230075836, 0.021032700315117836, -0.02257760614156723, 0.06372607499361038, 0.029817868024110794, -0.03504771366715431, 0.03242156282067299, -0.01996069960296154, 0.03314061462879181, -0.03716529533267021, 0.05250917747616768, 0.017023097723722458, -0.017384618520736694, -0.036292366683483124, -0.05858534947037697, -0.033142026513814926, 0.0009193443693220615, -0.00587015924975276, -0.03531515970826149, -0.012676031328737736, 0.042964499443769455, -0.02615579217672348, -0.0688469260931015, 0.009446617215871811, -0.046855174005031586, -0.0488261915743351, 0.028240442276000977, 0.009164724498987198, 0.036042116582393646, 0.017347125336527824, 0.020281219854950905, -0.021006396040320396, 0.018896453082561493, -0.03409969061613083, 0.017836371436715126, 0.0036167881917208433, -0.02526383101940155, 0.014593140222132206, 0.033903561532497406, 0.010169347748160362, 0.015554340556263924, 0.007278881035745144, -0.027098309248685837, -0.03865863382816315, -0.01830415613949299, 0.009225431829690933, 0.03327025845646858, 0.0036526701878756285, -0.0017235975246876478, 0.020550958812236786, 0.010665999725461006, -0.026181191205978394, -0.019096773117780685, 0.04315657168626785, 0.03233913332223892, -0.017536025494337082, 0.03057735040783882, -0.010248860344290733, 0.011896932497620583, -0.010668734088540077, -0.024434374645352364, -0.006175929680466652, 0.018978513777256012, 0.05141182243824005, -0.046196114271879196, 0.04577646777033806, 0.004942090250551701, -0.029284222051501274, 0.022969968616962433, -0.031201792880892754, -0.06316208839416504, 0.01598401553928852, 0.03186069428920746, 0.04414280131459236, -0.02114228531718254, -0.04088704288005829, 0.008219237439334393, 0.01942458748817444, 0.026311280205845833, 0.051698897033929825, 0.024071456864476204, 0.01984376646578312, -0.02512160688638687, -0.023263905197381973, 0.018479425460100174, -0.006289113312959671, 0.0317302830517292, -0.011057266034185886, -0.01983351819217205, -0.013344867154955864, -0.049831654876470566, 0.025366827845573425, 0.0329526849091053, 0.011924815364181995, -0.013129805214703083, 0.036276910454034805, -0.049237996339797974, 0.04122478514909744, 0.030016526579856873, 0.03218580037355423, -0.021871289238333702, -0.06776917725801468, -0.013775002211332321, -0.02945137768983841, 0.013150591403245926, -0.003661674214527011, -0.021552156656980515, 0.010645432397723198, 0.01888352446258068, -0.004341794177889824, -0.002517436631023884, -0.027531977742910385, -0.02090897411108017, -0.0022545382380485535, 0.017285427078604698, -0.00900201965123415, -0.016227522864937782, -0.03792949765920639, 0.016266170889139175, 0.02654571458697319, -0.04094753414392471, -0.011748031713068485, -0.014620869420468807, 0.0021201844792813063, 0.020262138918042183, -0.04795488342642784, -0.023134252056479454, 0.012741095386445522, -0.015675587579607964, -0.054771438241004944, 0.044682517647743225, 0.04493126645684242, -0.027166005223989487, 0.009179451502859592, -0.054620761424303055, 0.009723815135657787, 0.00902126170694828, -0.0005287813255563378, -0.015305235981941223, 0.03079850785434246, -0.012053357437252998, 0.014391418546438217, 0.040714796632528305, 0.01589466817677021, -0.036797769367694855, 0.024010684341192245, -0.03935042768716812, 0.037425484508275986, -0.03921203687787056, -0.00681398157030344, -0.028350315988063812, -0.014866598881781101, -0.022738805040717125, -0.001572666340507567, 0.015629207715392113, 0.014043384231626987, -0.003007142571732402, 0.0301355067640543, -0.033201269805431366, -0.05248752608895302, 0.016752054914832115, -0.01651918701827526, -0.006498416885733604, 0.044718749821186066, 0.0032228126656264067, -0.014443665742874146, -0.004690905101597309, 0.008649788796901703, -0.01449649315327406, 0.016918130218982697, -0.014204476960003376, 0.02456122450530529, -0.021826447919011116, -0.03196847438812256, -0.005277558695524931, -0.032783087342977524, 0.024189261719584465, -0.010762104764580727, -0.055986251682043076, 0.0014534619404003024, -0.057199180126190186, -0.019829923287034035, 0.03229132294654846, -0.028417065739631653, 0.0017051773611456156, 0.0015837076352909207, -0.029484068974852562, 0.014259087853133678, -0.04702362045645714, -0.06094507873058319, -0.024510769173502922, -0.015814363956451416, -0.0008596635307185352, 0.020280878990888596, 0.05955162271857262, 0.042560409754514694, -0.01553408894687891, -0.05919095128774643, 0.03337465599179268, -0.02207600511610508, -0.02580747753381729, -0.03212660551071167, -0.019584376364946365, -0.006978089455515146, 0.006854842882603407, -0.0426621213555336, 0.010077579878270626, -0.00419020839035511, 0.0029758394230157137, 0.014275366440415382, 0.002551564946770668, 0.022004490718245506, -0.012201826088130474, -0.037515345960855484, 0.05557858198881149, 0.0037213265895843506, -0.08624574542045593, -0.049251604825258255, 0.016561854630708694, -0.01748133823275566, 0.014839166775345802, 0.005948732141405344, -0.013007492758333683, -0.02494368702173233, -0.05056900903582573, 0.03766896575689316, -0.03363926336169243, -0.003009217558428645, -0.046607617288827896, -0.0436268113553524, 0.01825486682355404, 0.008573001250624657, 0.03637263923883438, -0.01795217953622341, -0.038540102541446686, -0.03800298273563385, 0.027037397027015686, -0.04310034587979317, -0.002931252820417285, -0.016016941517591476, -0.03201558440923691, 0.006608680821955204, 0.06095973774790764, 0.017330091446638107, 0.0005789969000034034, -0.0038799073081463575, 0.008105126209557056, 0.01575661636888981, 0.046554625034332275, -0.05861826241016388, -0.006228476297110319, -0.0021492629311978817, -0.0017999892588704824, 0.03193177282810211, 0.008455915376543999, -0.04185056686401367, 0.0039007614832371473, -0.02779107168316841, 0.012372707016766071, -0.05502115562558174, -0.009322483092546463, -0.023868918418884277, -0.010250555351376534, 0.03520025685429573, -0.038010627031326294, 0.013130954466760159, -0.03382024168968201, 0.04066678509116173, 0.0070251901634037495, 0.003631361061707139, -0.04185732081532478, -0.004649454727768898, -0.026399735361337662, -0.03123641572892666, -0.002123488811776042, -0.02029465138912201, 0.031293462961912155, 0.028649363666772842, -0.004749918356537819, 0.0457790233194828, -0.05161347985267639, 0.05004103109240532, 0.06926006823778152, 0.029527582228183746, 0.009542841464281082, -0.039826441556215286, 0.004146625753492117, -0.009494030848145485, 0.01919233240187168, 0.002973313909024, -0.032603077590465546, -0.008717074990272522, -0.024652468040585518, -0.031174009665846825, -0.03671558201313019, 0.00110710971057415, 0.0022113793529570103, 0.06186682730913162, -0.0323091559112072, 0.029492700472474098, 0.021790724247694016, -0.07397899776697159, -0.031911108642816544, 0.024327343329787254, -0.010452335700392723, 0.015401632525026798, 0.019545847550034523, 0.011907534673810005, -0.03916152939200401, -0.026043109595775604, -0.023463072255253792, -0.030839860439300537, 0.009926922619342804, 0.042939797043800354, -0.009548249654471874, -0.030825814232230186, 0.04251989349722862, 0.02808450348675251, -0.030081599950790405, -0.03488237038254738, 0.026316920295357704, -0.0038854528684169054, 0.015393991954624653, -0.028459032997488976, -0.023857316002249718, 0.03230966255068779, -0.01640041545033455, 0.006651196628808975, 0.045472435653209686, -0.03991645202040672, -0.009162142872810364, 0.025152089074254036, -0.00486933346837759, -0.06591352820396423, 0.05984271317720413, 0.043092336505651474, -0.01987188495695591, -0.0011741050984710455, -0.01696106232702732, 0.005581586621701717, 0.01213741209357977, -0.030339347198605537, 0.05019865930080414, -0.02092907205224037, -0.018263310194015503, 0.02861429750919342, 0.016795216128230095, 0.04917779192328453, -0.04198070243000984, 0.00281269708648324, 0.016873370856046677, -0.06349866092205048, -0.0307146143168211, -0.014957483857870102, 0.014672025106847286, -0.013790701515972614, 0.061004240065813065, 0.00037848425563424826, 0.022383349016308784, 0.047690361738204956, 0.0465252660214901, -0.009859785437583923, -0.06144760921597481, 0.0015634786104783416, -0.037197161465883255, -0.024521157145500183, -0.0028603742830455303, -0.06346065551042557, 0.008208817802369595, 0.03453730419278145, 0.012416558340191841, -0.023991523310542107, -0.015126209706068039, 0.029213322326540947, -0.04602697864174843, -0.02118842862546444, -0.041167329996824265, 0.02285601571202278, -0.04047028720378876, 0.005486557260155678, 0.008686346933245659, -0.010749476961791515, -0.04238099232316017, 0.009090842679142952, -0.04091688245534897, 0.014809893444180489, 0.027113353833556175, 0.035987015813589096, -0.022167455404996872, 0.022362053394317627, -0.04016244038939476, 0.001691881800070405, -0.00047004458610899746, 0.028051013126969337, -0.02387927658855915, 0.05144331231713295, 0.015204789116978645, -0.033556222915649414, -0.009969793260097504, -0.004118581302464008, 0.002337647834792733, -0.026307551190257072, 0.020875027403235435, 0.02605116181075573, -0.00679898913949728, 0.016583677381277084, -0.00440626684576273, 0.035672273486852646, -0.03992389142513275, -0.02032100409269333, -0.021756967529654503, -0.023602372035384178, -0.006547128781676292, 0.00475764786824584, 0.042212557047605515, 0.0900823175907135, 0.031441882252693176, 0.029431425034999847, 0.027247367426753044, 0.009997047483921051, 0.024875694885849953, 0.019649500027298927, -0.013807695358991623, -0.003083924762904644, -0.030741767957806587, -0.04451931640505791, 0.05992915853857994, 0.009462913498282433, -0.01865311525762081, 0.038032758980989456, -0.005109816323965788, -0.025186913087964058, -0.027680398896336555, 0.005689558107405901, 0.025355644524097443, 0.03393004089593887, 0.06414070725440979, -0.022333119064569473, -0.019004885107278824, -0.005198008380830288, -0.01817956194281578, 0.018544819205999374, -0.04527556151151657, -0.033417969942092896, 0.015914343297481537, -0.019270582124590874, -0.007860871031880379, -0.003057097317650914, -0.00335527490824461, 0.01994495838880539, 0.026677513495087624, 0.03739027678966522, -0.005704318173229694, 0.04772866517305374, -0.005936493631452322, 0.004730456508696079, -0.029123637825250626, -0.03786315768957138, -0.02912805788218975, -0.00796116515994072, -0.051278579980134964, -0.041371479630470276, 0.01663174293935299, 0.053219836205244064, 0.036683548241853714, -0.016260378062725067, -0.05015435069799423, 0.014962536282837391, 0.0016566149424761534, 0.025388717651367188, -0.08443184196949005, 0.04306986927986145, -0.0078337537124753, -0.00862962193787098, -0.023475535213947296, 0.011862206272780895, 0.013816562481224537, 0.02972300723195076, 0.011168109253048897, 0.015358545817434788, -0.013768250122666359, 0.03231435641646385, 0.015913331881165504, -0.021492138504981995, 0.0528787299990654, -0.0008797624032013118, 0.029570508748292923, 0.010744539089500904, -0.007179510314017534, 0.05353409796953201, 0.05005194619297981, 0.04172681272029877, 0.05215119943022728, -0.0260823592543602, 0.05645017325878143, 0.04068722948431969, -0.02734202705323696, -0.007499588653445244, 0.021948151290416718, 0.015315395779907703, -0.010202616453170776, -0.010379938408732414, -0.0629357323050499, 0.017041711136698723, -0.018833383917808533, 0.018682239577174187, 0.005101737566292286, -0.029316671192646027, 0.015248720534145832, -0.02531757391989231, -0.06742563098669052, 0.04104908928275108, 0.007223974913358688, -0.05391693860292435, -0.0031969447154551744, 0.011045818217098713, 0.025509100407361984, 0.015422333963215351, 0.020734895020723343, -0.017567995935678482, 0.04303210228681564, 0.011384494602680206, 0.02938462793827057, 0.00979415699839592, -0.00896088220179081, -0.008045874536037445, -0.008472760207951069, 0.0060056899674236774, -0.02572956122457981, 0.024798637256026268, -0.0029253484681248665, -0.025718633085489273, -0.02057456597685814, 0.06621301174163818, 0.008715311996638775, -0.037842992693185806, 0.013845358043909073, -0.029181145131587982, -0.01634996198117733, -0.016302218660712242, 0.03143545612692833, -0.02090466022491455, 0.0032460454385727644, 0.0396098755300045, -0.011578242294490337, -0.03777657076716423, 0.04667718708515167, 0.021320905536413193, 0.012767630629241467, 0.010791553184390068, 0.054614003747701645, 0.020160650834441185, 0.09022553265094757, 0.06724962592124939, 0.03306785598397255, 0.025935567915439606, 0.025702252984046936, 0.00507165864109993, -0.006389365531504154, -0.004742983728647232, 0.009956728667020798, -0.01088281162083149, -0.05222692713141441, -0.05768226087093353, 0.022098081186413765, -0.01507710199803114, -0.015130151063203812, 0.026172375306487083, 0.021520419046282768, -0.0009409277117811143, -0.02609412372112274, -0.001475114026106894, 0.05971750617027283, 0.013654705137014389, 0.03507528081536293, 0.006793407257646322, 0.008466862142086029, -0.05652143061161041, 0.04153463989496231, -0.01337857823818922, 0.029381416738033295, -0.011784354224801064, -0.03773006796836853, 0.02924390323460102, -0.037011705338954926, -0.038759924471378326, -0.02878083847463131, -0.013751865364611149, -0.036021165549755096, 0.04172259941697121, -0.0058691250160336494, 0.030600588768720627, 0.02307405322790146, -0.007790106348693371, -0.025639576837420464, 0.05177326127886772, 0.028148403391242027, -0.012139985337853432, 0.05246767774224281, 0.050636421889066696, -0.018166558817029, -0.0012395704397931695, 0.007741496432572603, -0.0019586351700127125, -0.01608637347817421, 0.021426407620310783, -0.013522869907319546, 0.009373794309794903, -0.02143879421055317, -0.048716068267822266, -0.02353777177631855, 0.04345906898379326, 0.02210431918501854, 0.00035290486994199455, -0.04033910483121872, -0.009214158169925213, -0.05743059888482094, -0.002573299454525113, -0.04059397056698799, 0.010745537467300892, 0.005638194736093283, -0.011898756958544254, -0.007667551748454571, -0.03489794209599495, 0.2452940046787262, 0.0673762857913971, 0.031891971826553345, 0.03430486470460892, 0.027479656040668488, 0.04806836321949959, 0.03864523023366928, -0.028417032212018967, 0.04149281978607178, -0.016466829925775528, 0.015461293049156666, -0.025554534047842026, 0.017327558249235153, 0.004288553260266781, -0.02690521813929081, 0.0008541897404938936, -0.050541914999485016, -0.013170759193599224, -0.021430781111121178, -0.010432641953229904, -0.04678582400083542, 0.05063746124505997, -0.001657280488871038, -0.009996233507990837, 0.03250131011009216, 0.0002600068983156234, 0.0028160347137600183, -0.03427362069487572, 0.024387400597333908, -0.023041779175400734, 0.01441845390945673, -0.025941794738173485, 0.03335603326559067, -0.03135162964463234, 0.0034327886532992125, 0.04398249462246895, 0.005067335907369852, -0.027342751622200012, -0.008953726850450039, 0.03670738264918327, 0.0018733092583715916, -0.004620920401066542, -0.03006388060748577, -0.025537556037306786, -0.04629913717508316, 0.04447280243039131, -0.004136800765991211, 0.031560469418764114, 0.040123436599969864, -0.07269198447465897, 0.019763560965657234, -0.03998749330639839, 0.015030978247523308, -0.02291468158364296, -0.051926519721746445, -0.0032211747020483017, 0.018896348774433136, -0.05561523884534836, -0.035692766308784485, 0.02908528409898281, 0.00798407755792141, 0.004371582996100187, 0.006551054771989584, 0.043838124722242355, -0.009306980296969414, 0.0006013587117195129, 0.04460013285279274, -0.0006843728478997946, -0.02894800342619419, 0.014008813537657261, 0.018622202798724174, -0.0017047772416844964, -0.017336158081889153, -0.03377297893166542, 0.049976006150245667, -0.0029369674157351255, -0.013575809076428413, 0.05101613700389862, 0.012475281953811646, -0.05772697553038597, -0.007696710992604494, -0.002662001410499215, -0.031951405107975006, -0.03384825587272644, 0.013227196410298347, 0.05198294296860695, -0.031881850212812424, 0.003599451621994376, -0.025916317477822304, 0.02738814800977707, -0.018949655815958977, 0.01874852366745472, -0.007989819161593914, -0.0038287139032036066, 0.013139322400093079], metadata={'page_label': '2', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='We then develop theDSPy compiler(Sec 4), which optimizes any DSPy program to improve quality\\nor cost. The compiler inputs are the program, a few training inputs with optional labels, and a valida-\\ntion metric. The compiler simulates versions of the program on the inputs and bootstraps example\\ntraces of each module for self-improvement, using them to construct effective few-shot prompts\\nor finetuning small LMs for steps of the pipeline. Optimization in DSPy is highly modular: it is\\nconducted by teleprompters,2 which are general-purpose optimization strategies that determine how\\nthe modules should learn from data. In this way, the compiler automatically maps the declarative\\nmodules to high-quality compositions of prompting, finetuning, reasoning, and augmentation.\\nProgramming models like DSPy could be assessed along many dimensions, but we focus on the role\\nof expert-crafted prompts in shaping system performance. We are seeking to reduce or even remove\\ntheir role through DSPy modules (e.g., versions of popular techniques like Chain of Thought) and\\nteleprompters. We report on two expansive case studies: math word problems (GMS8K; Cobbe et al.\\n2021) and multi-hop question answering (HotPotQA; Yang et al. 2018) with explorations of chain\\nof thought, multi-chain reflection, multi-hop retrieval, retrieval-augmented question answering, and\\nagent loops. Our evaluations use a number of different compiling strategies effectively and show\\nthat straightforward DSPy programs outperform systems using hand-crafted prompts, while also\\nallowing our programs to use much smaller and hence more efficient LMs effectively.\\nOverall, this work proposes the first programming model that translates prompting techniques into\\nparameterized declarative modules and introduces an effective compiler with general optimiza-\\ntion strategies (teleprompters) to optimize arbitrary pipelines of these modules. Our main contri-\\nbutions are empirical and algorithmic: with DSPy, we have found that we can implement very\\nshort programs that can bootstrap self-improving multi-stage NLP systems using LMs as small as\\nllama2-13b-chat and T5-Large (770M parameters). Without hand-crafted prompts and within\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='c2e4673c-d970-4601-bae5-0ccbd269ab70', embedding=[0.024457816034555435, 0.010120070539414883, -0.007891489192843437, -0.00872644130140543, -0.04114297032356262, -0.030439753085374832, -0.018755409866571426, -0.01729259453713894, -0.007133361883461475, 0.060119062662124634, -0.010439404286444187, -0.025714211165905, 0.005478934850543737, -0.015070324763655663, -0.027607742697000504, 0.0018937510903924704, -0.021416228264570236, -0.039248157292604446, -0.08191442489624023, 0.01927085593342781, 0.05212054401636124, 0.0015176923479884863, -0.059512022882699966, -0.008279182016849518, -0.016081172972917557, 0.03699541836977005, 0.004474629648029804, 0.02149430476129055, 0.07685563713312149, 0.047784507274627686, 0.03114256262779236, -0.009122439660131931, 0.02395966649055481, -0.027729999274015427, -0.020290784537792206, -0.07814221829175949, 0.010498429648578167, -0.002512914128601551, 0.002694424707442522, -0.01756371557712555, 0.037687476724386215, -0.03139244019985199, 0.04102866351604462, -0.061026494950056076, -0.06870729476213455, -0.019421329721808434, 0.012268450111150742, -0.031193722039461136, -0.004268231336027384, -0.021048016846179962, -0.001605635043233633, 0.03571997582912445, 0.008156931959092617, -0.005787959322333336, -0.016666335985064507, 0.014629143290221691, 0.003067553509026766, -0.007955217733979225, -0.05095697566866875, 0.012171790935099125, 0.006010763812810183, 0.02417820319533348, -0.018799327313899994, -0.05350832641124725, -0.0001542338723083958, 0.02668188139796257, 0.004632385913282633, -0.01772817224264145, -0.04271107167005539, -0.004829161334782839, -0.042788971215486526, 0.025738012045621872, -0.016499437391757965, -0.04111728072166443, -0.014105330221354961, -0.013617899268865585, 0.04118047654628754, 0.03125268220901489, -0.05786281079053879, 0.05906900390982628, 0.02215125411748886, 0.053458988666534424, 0.01787624880671501, 0.010651512071490288, -0.035849086940288544, -0.05183425545692444, 0.06589770317077637, -0.02355189248919487, -0.024946080520749092, -0.003922557923942804, -0.003423485206440091, 0.024431882426142693, 0.027834797278046608, 0.022361688315868378, 0.03894544392824173, 0.051712945103645325, -0.002260013483464718, 0.020922230556607246, -0.01425043772906065, -0.004197206348180771, 0.042044442147016525, 0.06784184277057648, -0.02504628710448742, 0.030611246824264526, -0.046271879225969315, -0.01474488154053688, 0.021969584748148918, -0.03392596170306206, -0.01938113383948803, -0.04558310657739639, 0.01875729113817215, 0.01966370828449726, -0.021708637475967407, 0.010249461978673935, -0.041212864220142365, 0.021514223888516426, 0.006889282260090113, 0.040114741772413254, -0.03625697270035744, 0.004430267959833145, -0.005529101472347975, -0.02262098900973797, 0.003731830744072795, 0.0041246493346989155, 0.020731478929519653, -0.023781731724739075, 0.01124965213239193, 0.053340453654527664, -0.03532584011554718, -0.022098226472735405, -0.012708031572401524, 0.008264027535915375, -0.0024021263234317303, 0.06417873501777649, 0.01539725624024868, 0.009539345279335976, 0.004411808215081692, 0.015549269504845142, 0.01956033892929554, -0.019059481099247932, 0.017838306725025177, -0.02449057810008526, 0.0013024441432207823, 0.10628747195005417, 0.005554991774260998, 0.003773938864469528, -0.02816092036664486, 0.0016249265754595399, -0.035558007657527924, 0.0331946425139904, 0.010611037723720074, -0.010251243598759174, -0.012998177669942379, 0.013500421307981014, 0.001249946653842926, 0.0006417802069336176, -0.023864375427365303, -0.021911496296525, 0.025562122464179993, 0.001458547543734312, -0.013820127584040165, -0.008561071939766407, -0.02242620289325714, 0.02297816053032875, -0.03244966268539429, 0.05376218259334564, -0.045296359807252884, -0.022679893299937248, 0.01441397238522768, 0.0025294150691479445, 0.0299934484064579, 0.0032764121424406767, -0.010332394391298294, 0.01810484379529953, 0.055583223700523376, 0.05351277440786362, 0.03095155395567417, -0.007842161692678928, 0.02489481307566166, 0.010030264966189861, -0.024020297452807426, 0.008651209063827991, 0.020835788920521736, 0.0035411526914685965, 0.0034353923983871937, 0.061356522142887115, -0.001551183289848268, 0.007605579681694508, -0.020391318947076797, -0.009109100326895714, -0.01349253673106432, 0.03884851932525635, -0.03651253134012222, 0.007821828126907349, -0.006165492348372936, 0.005594199523329735, -9.43351406021975e-05, 0.042420923709869385, 0.007278142496943474, -0.06166185066103935, -0.032477013766765594, 0.06033101677894592, 0.019030779600143433, -0.0028727485332638025, -0.04469330981373787, -0.005616782698780298, -0.007245352491736412, 0.05432475730776787, -0.04906150698661804, 0.01424670871347189, 0.037309423089027405, 0.004516698885709047, -0.02791016362607479, -0.008215981535613537, 0.013614828698337078, -0.043251655995845795, -0.011499841697514057, -0.007349011022597551, 0.03609287738800049, 0.0185403935611248, 0.018309812992811203, 0.02069108374416828, 0.008862056769430637, -0.03400899097323418, -0.024587327614426613, 0.0071156700141727924, -0.00871156807988882, 0.04071137309074402, -0.005663675721734762, 0.004353750962764025, -0.005500828381627798, 0.048733923584222794, -0.033078476786613464, 0.048121318221092224, 0.01925487071275711, -0.015087136998772621, 0.056720223277807236, 0.05890752375125885, -0.017373524606227875, 0.019285468384623528, -0.013869326561689377, -0.0024097030982375145, -0.003500556107610464, 0.03404301032423973, 0.01024481002241373, 0.019653214141726494, 0.025535637512803078, -0.00983806699514389, -0.03728371486067772, 0.0230157058686018, -0.06734362244606018, 0.06872721761465073, 0.012494374066591263, 0.0005895559443160892, -0.03726104646921158, -0.01682862639427185, 0.029758093878626823, 0.03667730093002319, -0.03723929449915886, -0.011956228874623775, 0.04083844646811485, 0.027264641597867012, -0.0036874429788440466, -0.030913062393665314, -0.001696817809715867, 0.021225500851869583, -0.02160697989165783, 0.0409587062895298, -0.0036289829295128584, -0.007793930824846029, -0.0312640480697155, -0.03182277828454971, -0.0769181177020073, 0.005076298024505377, -0.029714368283748627, -0.02012917958199978, -0.02720152959227562, -0.046920839697122574, 0.004744451493024826, -0.03180920332670212, 0.004197908099740744, 0.006143991835415363, 0.003649655496701598, 0.03374136984348297, 0.04429097846150398, 0.018595702946186066, -0.06051833555102348, 0.04245079681277275, -0.022433703765273094, 0.05544945225119591, 0.00033393525518476963, -0.009354027919471264, -0.021920768544077873, 0.00925620086491108, 0.05514528229832649, -0.018220942467451096, 0.028004275634884834, 0.007451781537383795, -0.029384460300207138, -0.0009012820664793253, 0.0019003372872248292, -0.0381150059401989, 0.024921737611293793, -0.028647586703300476, -0.03189394250512123, 0.04744388908147812, -0.005730422679334879, -0.00867951475083828, 0.07407661527395248, 0.050198595970869064, -0.03947237879037857, 0.012565139681100845, -0.0008029033779166639, 0.02229396253824234, -0.05219121277332306, 0.07729599624872208, 0.0189367663115263, -0.0327606126666069, -0.024650488048791885, -0.050860270857810974, -0.035545434802770615, 0.012115209363400936, 0.009910224005579948, -0.03573344275355339, -0.020924022421240807, 0.03822590410709381, -0.014599578455090523, -0.04820661246776581, 0.01976514607667923, -0.03870689123868942, -0.03585679829120636, 0.018519600853323936, -0.010894911363720894, 0.04626474902033806, 0.034117765724658966, 0.02010362781584263, -0.04728184640407562, 0.0022295459639281034, -0.03916555270552635, -0.002649438800290227, -0.0028500533662736416, -0.037963833659887314, 0.021357186138629913, 0.01864469051361084, 0.010200452990829945, 0.00985556747764349, 0.007594910915941, -0.02529258094727993, -0.010370144620537758, -0.010887673124670982, -0.0018897097324952483, 0.03066421113908291, 0.015505651012063026, 0.008621305227279663, -0.002465644618496299, 0.03335961699485779, -0.03680731728672981, -0.03558119386434555, 0.037397585809230804, 0.008419312536716461, -0.0033454603981226683, 0.026062052696943283, 0.003838426200672984, 0.03312528878450394, -0.04650339484214783, -0.014772041700780392, -0.02039075456559658, 0.008851490914821625, 0.04176947474479675, -0.05272156745195389, 0.03499455749988556, -0.021992487832903862, -0.03665366396307945, 0.02517222985625267, -0.028765343129634857, -0.04822581633925438, 0.04424462094902992, 0.007989620789885521, 0.04402289167046547, -0.0025670842733234167, -0.027018923312425613, 0.029527079313993454, -0.00014261092292144895, 0.0384042002260685, 0.009964757598936558, 0.013587543740868568, -0.001335504581220448, -0.008080413565039635, -0.04649902135133743, -0.00826551765203476, -0.0031172384042292833, 0.02663947269320488, -0.0006105476059019566, -0.02106938324868679, -0.030930355191230774, -0.04894436523318291, 0.043378666043281555, 0.03198081627488136, 0.019354404881596565, 0.0052104820497334, 0.012662352062761784, -0.042896855622529984, 0.04334372282028198, -0.006270380225032568, 0.027930419892072678, 0.0029265806078910828, -0.08507327735424042, -0.012039448134601116, -0.0191558375954628, -0.002302330918610096, -0.008240106515586376, -0.025067003443837166, 0.0074215419590473175, 0.02760126441717148, 0.003915091045200825, 0.008928081952035427, -0.021516874432563782, -0.004269814118742943, 0.0034426862839609385, 0.03827974945306778, -0.015437379479408264, -0.01647557131946087, -0.021603135392069817, 0.0231887549161911, 0.013175987638533115, -0.05098270624876022, -0.027806216850876808, -0.002741386415436864, -0.011235557496547699, 0.01924852468073368, -0.03659479320049286, -0.030795415863394737, 0.000404207909014076, -0.011439869180321693, -0.04743311181664467, 0.06157033517956734, 0.05783883482217789, -0.03364650905132294, 0.022228697314858437, -0.03513611853122711, 0.008007497526705265, 0.007643603719770908, -0.018290678039193153, -0.01756398379802704, 0.02466108649969101, -0.010660047642886639, 0.037000324577093124, 0.05469193682074547, 0.008173477835953236, -0.03879670798778534, 0.021126819774508476, -0.04910450428724289, 0.03434685990214348, -0.03413126617670059, -0.021840618923306465, -0.04148402810096741, -0.003816720098257065, -0.011243780143558979, 0.002734088571742177, 0.006227526813745499, 0.011705689132213593, 0.003350878367200494, 0.02909228578209877, -0.039916492998600006, -0.03950783982872963, 0.036721792072057724, -0.008526701480150223, -0.004341053310781717, 0.05340299382805824, 0.008006730116903782, -0.035026464611291885, -0.01279942411929369, 0.012564344331622124, -0.017385592684149742, 0.03354007750749588, -0.007798250764608383, 0.017762284725904465, -0.024294521659612656, -0.01790848933160305, -0.011625377461314201, -0.03542637452483177, 0.030158547684550285, 0.013912839815020561, -0.04295700043439865, -0.02016856148838997, -0.0388280414044857, -0.006521806586533785, 0.013463802635669708, -0.022278068587183952, 0.008580837398767471, 0.004103687591850758, -0.017200078815221786, 0.03085590898990631, -0.04281780868768692, -0.06352798640727997, -0.03366073966026306, -0.0024576359428465366, -0.017468072474002838, 0.03667466342449188, 0.056500352919101715, 0.033126797527074814, -0.0024553246330469847, -0.06551595777273178, 0.015178842470049858, -0.015294906683266163, -0.04483332857489586, -0.009345347061753273, 0.011441326700150967, -0.02523878961801529, -0.016200514510273933, -0.0491178072988987, 0.0029247708152979612, -0.0014292652485892177, 0.002181329531595111, 0.01166129857301712, 0.02561948634684086, 0.028427690267562866, 0.0006758147501386702, -0.04760226979851723, 0.04132978245615959, 0.013041702099144459, -0.07970333099365234, -0.025457074865698814, 0.00940756220370531, -0.019324716180562973, 0.02582554705440998, 0.017966771498322487, -0.02386263944208622, -0.028566507622599602, -0.06896946579217911, 0.04331475868821144, -0.0682477056980133, 0.010954605415463448, -0.0360456183552742, -0.03275849297642708, 0.03109508752822876, 0.0007437252206727862, 0.03369661048054695, -0.02290116623044014, -0.05592396482825279, -0.04474547505378723, 0.035116907209157944, -0.04810265451669693, 0.002490986604243517, 0.0016169933369383216, -0.003996646497398615, -0.004975967109203339, 0.09030278772115707, -0.019865985959768295, 0.004321292974054813, -0.017087183892726898, 0.03184771165251732, -0.0024815360084176064, 0.034935031086206436, -0.04556366801261902, -0.020130565389990807, 0.0026239529252052307, 0.007582652848213911, 0.0319739393889904, 0.009757068008184433, -0.029318561777472496, 0.001365072326734662, -0.042938705533742905, 0.019562700763344765, -0.02974551171064377, 0.006205045152455568, -0.02742321603000164, 0.00013668352039530873, 0.04642529413104057, -0.07235213369131088, 0.026350634172558784, -0.026478616520762444, 0.034974146634340286, 0.015529339201748371, 0.015525126829743385, -0.03362008184194565, -0.012611465528607368, -0.03498440980911255, -0.03873645141720772, -0.0037935159634798765, -0.026875115931034088, 0.020291995257139206, 0.007675504311919212, 0.015862535685300827, 0.03697727993130684, -0.06396356225013733, 0.039162468165159225, 0.06182022765278816, 0.0366336852312088, -0.00986047089099884, -0.03959238529205322, 0.01228213682770729, 0.011413217522203922, -0.01723076030611992, 0.0059999944642186165, -0.005599694326519966, -0.016972776502370834, -0.033517688512802124, -0.013491137884557247, -0.02704976312816143, -0.0020193601958453655, -0.0032540676183998585, 0.047905005514621735, -0.018454356119036674, 0.027436699718236923, 0.00665677385404706, -0.06905867904424667, -0.04697507247328758, 0.04251447319984436, 0.003286270424723625, -0.004586696159094572, 0.020553000271320343, 0.02848801761865616, -0.025984203442931175, -0.0003548740060068667, -0.02064293622970581, -0.032690707594156265, 0.0036786694545298815, 0.056949980556964874, -0.02460830844938755, -0.038174547255039215, 0.0392933115363121, 0.047372568398714066, -0.044025566428899765, -0.051867444068193436, 0.0038010210264474154, 0.007961826398968697, -0.008655717596411705, -0.04503626003861427, -0.024441324174404144, 0.004692783113569021, -0.009965414181351662, -0.0012504745973274112, 0.05360201373696327, -0.013615382835268974, -0.007576552219688892, 0.03159688040614128, 0.0009337764931842685, -0.041094228625297546, 0.049427203834056854, 0.05665590614080429, -0.03133942186832428, -0.023023594170808792, -0.01735612563788891, 0.008160443976521492, -0.009737072512507439, -0.02526571787893772, 0.06236423924565315, -0.029081517830491066, 0.021063178777694702, 0.031636063009500504, 0.005789388436824083, 0.02133132703602314, -0.03225235641002655, 0.008063080720603466, 0.032118912786245346, -0.047736700624227524, -0.04593176022171974, -0.04494017735123634, 0.030360588803887367, -0.01982489973306656, 0.06619520485401154, 0.0066164578311145306, 0.02196674235165119, 0.01691446825861931, 0.007341537158936262, -0.016283288598060608, -0.04781995713710785, -0.025200791656970978, -0.031013047322630882, -0.019224558025598526, 0.009803418070077896, -0.046619486063718796, 0.0245552659034729, 0.024426307529211044, 0.0020664860494434834, -0.019941963255405426, -0.03056207485496998, 0.011878547258675098, -0.025098729878664017, -0.003450446529313922, -0.021641084924340248, 0.024998389184474945, -0.0585436075925827, -0.017998013645410538, -0.01754114218056202, -0.02496085874736309, -0.02436460740864277, -0.014995303936302662, -0.026609031483530998, -0.0005287389503791928, 0.0026813859585672617, 0.039990007877349854, -0.021783271804451942, 0.01332282368093729, -0.035163719207048416, 0.00905965082347393, -0.01787692867219448, 0.009925571270287037, -0.03189899027347565, 0.04181576520204544, 0.006355895195156336, -0.042791079729795456, -0.00046301819384098053, -0.016569824889302254, 0.0017479797825217247, -0.013323822990059853, 0.006487916223704815, 0.03663124516606331, -0.017083914950489998, 0.0037552709691226482, -0.004448703955858946, 0.030543019995093346, -0.04257538169622421, -0.013778320513665676, -0.004601973574608564, -0.03814353048801422, 0.01797976903617382, 0.0015566498041152954, 0.026346832513809204, 0.06927219778299332, 0.044044703245162964, 0.013728862628340721, 0.03303869813680649, -0.001334794913418591, 0.022813748568296432, 0.014725957997143269, -0.006653366610407829, 0.004489481914788485, 0.004401466343551874, -0.025906268507242203, 0.05820182338356972, 0.010096913203597069, 0.01656327024102211, 0.03527872636914253, -0.010532223619520664, -0.01597565971314907, -0.037240441888570786, -0.005920241121202707, 0.006322077475488186, 0.006710444111377001, 0.05055318400263786, -0.015238724648952484, -0.01898261159658432, -0.004737678449600935, -0.013920656405389309, 0.0077188098803162575, -0.055854327976703644, -0.02109011821448803, -0.00018460728460922837, -0.030590511858463287, -0.012411320582032204, -0.0017373817972838879, -0.009324577637016773, 0.01855338364839554, 0.014078762382268906, 0.013415531255304813, 0.015534133650362492, 0.03408302366733551, 0.016764525324106216, 0.018501024693250656, -0.05068138614296913, -0.013207376934587955, -0.01001016329973936, 0.02412009984254837, -0.053535737097263336, -0.036748725920915604, -0.004265207331627607, 0.07523041218519211, 0.01604480855166912, -0.023316053673624992, -0.07011532038450241, 0.004090412985533476, 0.005436039064079523, 0.006726867984980345, -0.06912610679864883, 0.02947661094367504, 8.767610415816307e-05, 0.02616145648062229, -0.022618990391492844, 0.0336359441280365, 0.006613455712795258, 0.03281322866678238, 0.02209492027759552, 0.0031496775336563587, -0.011274664662778378, 0.05683805048465729, 0.009355795569717884, -0.020195240154862404, 0.06684444099664688, -0.016034729778766632, 0.023753419518470764, 0.017980780452489853, -0.003189395647495985, 0.04701964184641838, 0.02153761312365532, 0.019264882430434227, 0.05187298357486725, 0.0021355010103434324, 0.030407309532165527, 0.045009274035692215, -0.051065389066934586, 0.01057154219597578, 0.0249076746404171, 0.02084498107433319, -0.02415018156170845, 0.008611517958343029, -0.05388128384947777, 0.03147338703274727, -0.028300631791353226, 0.013898673467338085, 0.02057868242263794, -0.016392948105931282, 0.009308614768087864, -0.03034967929124832, -0.035773374140262604, 0.01183988619595766, -0.013833859004080296, -0.03529050201177597, -0.0050038364715874195, 0.014843063428997993, 0.04505767300724983, 0.021877389401197433, 0.0053010662086308, -0.029572537168860435, 0.05341259762644768, 0.016459358856081963, 0.01136951707303524, -0.003508201101794839, -0.009215793572366238, 0.017035746946930885, -0.021954452618956566, 0.02527916245162487, -0.011077407747507095, -0.0010640831897035241, 0.017391500994563103, -0.026073984801769257, -0.019192099571228027, 0.062111176550388336, 0.028391070663928986, -0.04330137372016907, 0.007165886461734772, -0.027823323383927345, -0.0021346977446228266, -0.020054670050740242, 0.028329316526651382, -0.02359595336019993, 0.00048057441017590463, 0.03640853986144066, -0.02177570015192032, -0.041036467999219894, 0.032608240842819214, 0.013309643603861332, 0.019317058846354485, 0.030031699687242508, 0.06052952632308006, -0.0008016687934286892, 0.08086726069450378, 0.06057194992899895, 0.02072310633957386, 0.010685916058719158, 0.026887666434049606, -0.020689070224761963, -0.01335691288113594, -0.008029315620660782, -0.00898319948464632, 0.012975716963410378, -0.030706830322742462, -0.03958539664745331, 0.018758200109004974, 0.013290123082697392, -0.0010137688368558884, 0.026034832000732422, -0.0023957460653036833, -0.002481052652001381, -0.05595788359642029, -0.0014656918356195092, 0.05902659520506859, 0.03126610070466995, 0.02242588996887207, 0.006873029749840498, 0.0009100268944166601, -0.0634971633553505, 0.024703752249479294, -0.02252400480210781, 0.030078694224357605, -0.03052983246743679, -0.01273420825600624, 0.029976997524499893, -0.04299449175596237, -0.04953090846538544, -0.044736962765455246, -0.0012439849087968469, -0.03668052330613136, 0.0414649099111557, 0.00608935346826911, 0.0374862365424633, 0.03836756944656372, -0.0270136259496212, -0.0028380004223436117, 0.037072181701660156, 0.060161277651786804, -0.016868067905306816, 0.06223849207162857, 0.038298871368169785, -0.013451313599944115, -0.02668526954948902, 0.025144528597593307, -0.004149675369262695, -0.018641537055373192, 0.029231062158942223, -0.004071637988090515, -0.0007703598821535707, -0.02343784272670746, -0.042884111404418945, 0.005737330298870802, 0.041947972029447556, 0.025882981717586517, 0.010498683899641037, -0.051083024591207504, -0.012640650384128094, -0.07044340670108795, -0.020196029916405678, -0.059162333607673645, 0.008808651007711887, -0.005026410799473524, -0.0032580355182290077, -0.007790763396769762, -0.021265733987092972, 0.24219848215579987, 0.0468786396086216, 0.03495383262634277, 0.017208097502589226, 0.012616446241736412, 0.032032959163188934, 0.03522324562072754, -0.0286164041608572, 0.03981982171535492, -0.03250730410218239, 0.022786859422922134, -0.01525068562477827, 0.0236708652228117, 0.019292697310447693, -0.027173839509487152, 0.013154745101928711, -0.07485060393810272, -0.024837929755449295, -0.0012653340818360448, -0.0419888012111187, -0.051262497901916504, 0.022467710077762604, -0.008522162213921547, -0.0015556488651782274, 0.015715530142188072, 0.008160091936588287, 0.013092209585011005, -0.03761669993400574, 0.033810973167419434, -0.019221007823944092, 0.005803641397505999, -0.03323529288172722, 0.0465201735496521, -0.007189872674643993, -0.01290026493370533, 0.02929220162332058, -0.0035648762714117765, -0.03496750444173813, 0.015273943543434143, 0.01580248400568962, 0.0051688700914382935, 0.020446235314011574, -0.01037626713514328, -0.00244428520090878, -0.031833067536354065, 0.07480252534151077, -0.0004614666977431625, 0.015865588560700417, 0.05904221162199974, -0.07119407504796982, 0.01509998831897974, -0.022105718031525612, 0.044829852879047394, -0.042682766914367676, -0.0671304240822792, -0.013304328545928001, 0.021018700674176216, -0.034216854721307755, -0.033873919397592545, -0.002845585811883211, 0.0073226019740104675, 0.00012308165605645627, -0.0018335111672058702, 0.033822737634181976, -0.022127972915768623, -0.018547751009464264, 0.027903655543923378, -0.0062105851247906685, -0.03811522573232651, 0.0019843238405883312, 0.017717229202389717, -0.005178302526473999, 0.01030639186501503, -0.02091464400291443, 0.059509292244911194, 0.020629659295082092, -0.013541173189878464, 0.050914641469717026, 0.01676824688911438, -0.045307356864213943, -0.005811436101794243, -0.0160061065107584, -0.035501714795827866, -0.036806005984544754, 0.02863226644694805, 0.05351262912154198, -0.03779074549674988, 0.010434988886117935, -0.022486615926027298, 0.027330627664923668, -0.015581476502120495, 0.03197028860449791, -0.013015012256801128, -0.005830900277942419, -0.005418721120804548], metadata={'page_label': '2', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='minutes to tens of minutes of compiling, compositions of DSPy modules can raise the quality of\\nsimple programs from 33% to 82% (Sec 6) and from 32% to 46% (Sec 7) for GPT-3.5 and, simi-\\nlarly, from 9% to 47% (Sec 6) and from 22% to 41% (Sec 7) for llama2-13b-chat.\\n1DSPy is pronounced dee-ess-pie. It’s the second iteration of our earlier Demonstrate–Search–Predict\\nframework (DSP; Khattab et al. 2022). This paper introduces the key concepts in DSPy. For more extensive and\\nup-to-date documentation of the framework, we refer readers to https://github.com/stanfordnlp/dspy.\\n2We derive the name tele-prompters from the notion of abstracting and automating the task of prompting,\\nin particular, such that it happens at a distance, without manual intervention.\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='a7efb7fb-cf24-4959-a2bb-aca955a5dda8', embedding=[0.03957846388220787, -0.02360462211072445, -0.024495039135217667, -0.012673073448240757, 0.0019722688011825085, 0.015270508825778961, -0.04285735264420509, 0.005988744553178549, -0.007698047906160355, 0.05468880012631416, 0.024470333009958267, -0.014919722452759743, 0.02176034450531006, -0.02638789266347885, -0.01830819807946682, -0.010862095281481743, -0.013823951594531536, -0.02004699781537056, -0.07049519568681717, -0.009917663410305977, 0.012753806076943874, 0.019173622131347656, -0.059843361377716064, -0.040436048060655594, -0.018236234784126282, 0.035817697644233704, 0.028304854407906532, -0.013190730474889278, 0.07328438013792038, 0.042394254356622696, 0.010740076191723347, -0.05023447796702385, 0.016572099179029465, -0.020755618810653687, -0.05262571945786476, -0.031200509518384933, 0.004470851272344589, -0.02158934623003006, -0.016872871667146683, -0.03210846707224846, 0.02990642935037613, -0.011765267699956894, 0.036589063704013824, -0.08229972422122955, -0.09426306188106537, -0.01916509121656418, 0.01009098719805479, -0.030231546610593796, -0.006318522151559591, -0.03983057290315628, -0.005952106323093176, 0.019272206351161003, -0.008197613060474396, -0.017302872613072395, 0.013263227418065071, -0.006521607283502817, 0.0057351491414010525, -0.018635040149092674, -0.036546140909194946, -5.638190123136155e-05, 0.023234358057379723, 0.0022459756582975388, 0.004877313505858183, -0.07409092783927917, -0.0016312010120600462, 0.018161647021770477, -0.012043358758091927, -0.023784277960658073, -0.025097191333770752, -0.02112250030040741, -0.06753335148096085, -0.012541144154965878, -0.05088784545660019, -0.035736799240112305, -0.011464281007647514, -0.006826519034802914, 0.03422420844435692, 0.021162014454603195, -0.03386540338397026, 0.011344056576490402, 0.028710590675473213, 0.042934972792863846, -0.004681936465203762, 0.03446106240153313, -0.0006732164183631539, -0.028407130390405655, 0.050460249185562134, -0.0017622688319534063, -0.027455730363726616, -0.0282748993486166, -0.01205054484307766, 0.015629246830940247, -0.028590524569153786, 0.041310716420412064, 0.021948572248220444, 0.035902757197618484, -0.02554740570485592, 0.04577860236167908, 0.011804424226284027, -0.0024724407121539116, 0.022482670843601227, 0.0754709467291832, -0.024324195459485054, 0.045719243586063385, -0.0673127993941307, 0.007608336862176657, 0.022443730384111404, 0.0014411195879802108, -0.0077597154304385185, -0.06164301931858063, 0.0038005507085472345, -0.00565697904676199, 0.0045997221022844315, 0.023097099736332893, -0.03358276188373566, 0.03760283440351486, -0.00827729981392622, 0.010894319042563438, -0.041582558304071426, 0.018531985580921173, -0.017214424908161163, -0.020788678899407387, -0.0116212647408247, -0.048363856971263885, 0.04653167724609375, 0.002691310364753008, 0.011276483535766602, 0.022987136617302895, -0.02316238358616829, -0.007589624263346195, -0.015110606327652931, 0.00404710229486227, -0.014649756252765656, 0.05691084265708923, -0.024326205253601074, -0.0013597063953056931, 0.02289568819105625, 0.032457537949085236, 0.001332582556642592, -0.021569393575191498, -0.005292996298521757, -0.031080905348062515, 0.003403046866878867, 0.08591669052839279, -0.013975048437714577, -0.010150542482733727, -0.021702300757169724, -0.03015865944325924, -0.042459942400455475, 0.007703547365963459, 0.004915667697787285, 0.009109387174248695, 0.009611251763999462, 0.01838211715221405, -0.022884363308548927, 0.0013817112194374204, -0.04506659880280495, 0.009883937425911427, -0.013932323083281517, 0.009620241820812225, -0.021347109228372574, 0.010731871239840984, -0.05493645370006561, 0.04098787158727646, -0.008751275017857552, 0.022006427869200706, -0.019947834312915802, -0.01005386933684349, 0.027670467272400856, -0.04384022206068039, 0.003083661664277315, 0.026325732469558716, -0.01090012863278389, 0.005103473551571369, 0.052105311304330826, 0.05663993954658508, 0.031128713861107826, 0.006521181669086218, 0.028669526800513268, 0.010825615376234055, -0.03322828561067581, -0.001956115709617734, 0.028592118993401527, 0.027950607240200043, 0.011193348094820976, 0.03444194793701172, -0.004562624264508486, 0.018328610807657242, -0.0029230467043817043, 0.02790381759405136, 0.001540660159662366, 0.07101639360189438, -0.05079488083720207, 0.05145284906029701, 0.004667306784540415, 0.0050216070376336575, -0.02046976238489151, 0.003855848452076316, 0.029189109802246094, -0.05436016991734505, -0.03161665052175522, 0.05901798605918884, -0.01980247162282467, 0.00853725429624319, -0.03407614678144455, 0.05126332864165306, 0.007362510543316603, 0.038919057697057724, -0.023006364703178406, 0.004091481678187847, 0.005103993695229292, 0.03800371289253235, -0.024578863754868507, -0.013054373674094677, 0.021800830960273743, -0.001406148076057434, -0.0279623344540596, 0.00023317450541071594, 0.003923557233065367, 0.034182991832494736, 0.008874003775417805, 0.006136877927929163, 0.0059290979988873005, 0.009848798625171185, -0.013418770395219326, -0.0256988275796175, 0.021984538063406944, 0.057072676718235016, -0.010545119643211365, 0.0020080776885151863, 0.020041296258568764, 0.039953820407390594, -0.008862732909619808, 0.048985131084918976, 0.053510405123233795, 0.01490601897239685, 0.0538768544793129, 0.061296846717596054, 0.042055826634168625, 0.028501426801085472, -0.0007796122808940709, -0.005039019510149956, 0.020074721425771713, 0.05453958362340927, 0.007939320988953114, 0.0052489954978227615, 0.0071177310310304165, 0.0023139400873333216, -0.028221454471349716, 0.006854765582829714, -0.07640062272548676, 0.05049952492117882, 0.029333457350730896, -0.007501962594687939, -0.05728313699364662, 0.013629961758852005, 0.020499292761087418, 0.026520738378167152, -0.04949755594134331, -0.029797837138175964, 0.020465729758143425, 0.003704999340698123, -0.013568857684731483, -0.017085576429963112, 0.008383337408304214, 0.03830433636903763, 0.014144094660878181, 0.04937988147139549, 0.011562014929950237, -0.026794366538524628, -0.044300634413957596, -0.052053555846214294, -0.1002923846244812, -0.007486524526029825, -0.038316503167152405, 0.02662649005651474, 0.014471665024757385, -0.029247330501675606, -0.0018714545294642448, -0.011769266799092293, 0.006332502234727144, 0.00854421965777874, -0.010845137760043144, 0.05209753289818764, 0.057152051478624344, 0.017727162688970566, -0.05512794852256775, 0.026226386427879333, -0.02226477675139904, 0.013212230987846851, -0.00551522895693779, -0.03474094346165657, 0.000984372803941369, -0.02143830619752407, 0.03306300565600395, -0.00010122852836502716, -0.006916786544024944, -0.047576043754816055, -0.03719276189804077, -0.0137850446626544, -0.016343118622899055, -0.033138059079647064, 0.02057221718132496, 0.008890247903764248, -0.047070715576410294, 0.04814425855875015, -0.003935886546969414, -0.05269252881407738, 0.03985832259058952, 0.026928924024105072, -0.026673143729567528, 0.0527593232691288, -0.010861558839678764, 0.024105187505483627, -0.010874017141759396, 0.05308528617024422, 0.03501932695508003, -0.003264928236603737, -0.01880878023803234, -0.05223943665623665, -0.04005149006843567, -0.0017050474416464567, 0.0035218640696257353, -0.029017450287938118, -0.034110866487026215, 0.03042159229516983, -0.01620982028543949, -0.05483391880989075, 0.0010006182128563523, -0.05073516443371773, -0.049337103962898254, -0.00597838731482625, 0.0020607071928679943, 0.0502767339348793, 0.01876615174114704, 0.03438475355505943, -0.03280123695731163, 0.014325600117444992, 0.006516667082905769, 0.015409844927489758, 0.01701623760163784, -0.029949726536870003, 0.036710143089294434, 0.04152257740497589, 0.027550509199500084, 0.011064553633332253, 0.001982620218768716, -0.034361209720373154, -0.007798442617058754, -0.0034151070285588503, 0.014304683543741703, 0.020925715565681458, -0.02022717334330082, 0.00994118582457304, -0.012070795521140099, 0.022128479555249214, -0.03800559788942337, -0.007499008439481258, -0.000717124086804688, 0.047547489404678345, 0.015833457931876183, 0.03237054497003555, -0.006917057558894157, 0.005566662643104792, -0.03374737873673439, -0.006568676792085171, 0.002253725426271558, 0.0026251780800521374, 0.04324604570865631, -0.060942392796278, 0.02143949642777443, -0.0010654835496097803, -0.03275503218173981, 0.01367206685245037, -0.043693915009498596, -0.05578579753637314, 0.02310461737215519, 0.05607036501169205, 0.03444303199648857, -0.0382637195289135, 0.00046451829257421196, 0.03701562434434891, 0.013860298320651054, 0.05248278006911278, 0.032730650156736374, 0.014780523255467415, -0.001845377148129046, -0.008385772816836834, -0.014249774627387524, -0.0006993474089540541, 0.019012805074453354, 0.03659734129905701, -0.026402214542031288, -0.02199452556669712, -0.019278347492218018, -0.028788672760128975, 0.02967490255832672, 0.03497932478785515, 0.01992129534482956, 0.026706868782639503, 0.035099051892757416, -0.044392164796590805, -0.0073887864127755165, 0.00639431644231081, 0.016768261790275574, -0.0039952946826815605, -0.034624602645635605, 0.00534448865801096, -0.0203328188508749, -0.03961138799786568, 0.0032688258215785027, -0.006614451762288809, -0.012352505698800087, 0.008707886561751366, 0.004076344892382622, 0.004996967036277056, -0.012802341021597385, -0.022019609808921814, 0.015485143288969994, 0.038588959723711014, -0.029155489057302475, -0.027275778353214264, -0.036375392228364944, 0.05851828306913376, 0.039443712681531906, -0.041243091225624084, 0.014039875008165836, -0.04753583297133446, 0.003967557568103075, 0.02250932715833187, -0.04620321840047836, -0.026326961815357208, -0.0033046638127416372, -0.030231045559048653, -0.08223486691713333, 0.06560248136520386, 0.029379623010754585, -0.05220958590507507, 0.006293388083577156, -0.029687203466892242, -0.014935768209397793, 0.0031826321501284838, 0.0034964827354997396, -0.006272250786423683, 0.021570801734924316, -0.006110723130404949, 0.015330306254327297, 0.016161615028977394, 0.015871457755565643, -0.016202816739678383, 0.005829045083373785, -0.05193479731678963, 0.027874063700437546, -0.023395931348204613, -0.003092974191531539, -0.01574578322470188, -0.0015806128503754735, -0.007958536967635155, -0.003839119803160429, 0.010852428153157234, -0.026010390371084213, -0.0012569826794788241, 0.0461990162730217, -0.01710708811879158, -0.03740034997463226, 0.01345833484083414, -0.005257434211671352, -0.006742582656443119, 0.06414487212896347, 0.00518930284306407, -0.017275912687182426, -0.005128319840878248, 0.02005140110850334, -0.050252556800842285, 0.01718766801059246, 0.009099995717406273, 0.0046490211971104145, 0.005853458307683468, -0.0368519201874733, 0.020851723849773407, -0.06049968674778938, 0.05488593503832817, -0.017663193866610527, -0.0008618113351985812, -0.0018909811042249203, -0.028006047010421753, -0.04139802232384682, -0.0035570813342928886, -0.03994586691260338, -0.00468493951484561, 0.0004851896082982421, 0.005066616460680962, 0.034544024616479874, -0.010123011656105518, -0.03506411612033844, -0.02486109547317028, -0.03460061922669411, -0.0036537563428282738, 0.03825240209698677, 0.0315924733877182, 0.02031465619802475, -0.040712691843509674, -0.018965456634759903, 0.0481041818857193, -0.02828773856163025, -0.00970540288835764, -0.010800372809171677, 0.0026687397621572018, -0.01272770669311285, -0.00047514226753264666, -0.02549631893634796, -0.01858470030128956, 0.008524350821971893, 0.018864575773477554, -0.0010782965691760182, -0.01637844368815422, -0.00896199606359005, -0.011149339377880096, -0.00500222435221076, 0.08311254531145096, -0.02916073240339756, -0.04832618683576584, -0.030774660408496857, 0.029367437586188316, -0.013215715996921062, 0.02072449028491974, 0.02583354152739048, 0.014415077865123749, -0.04135958477854729, -0.0808059573173523, 0.0250529944896698, -0.04688859358429909, 0.01967817358672619, -0.036668211221694946, -0.024679092690348625, 0.04474728927016258, -0.012012064456939697, 0.03259706124663353, -0.010293588973581791, -0.01938844658434391, -0.04461023956537247, 0.008359950967133045, -0.05115295574069023, -0.017042623832821846, -0.03600020334124565, 0.006361580453813076, -0.028985772281885147, 0.056323666125535965, 0.0026297620497643948, -0.008899091742932796, -0.017416400834918022, 0.019819185137748718, 0.02103326842188835, 0.043526992201805115, -0.030301375314593315, -0.01980661414563656, 0.03294529765844345, 0.016566427424550056, 0.045595522969961166, 0.02113056555390358, -0.029342709109187126, 0.021135499700903893, -0.00019148099818266928, 0.013556472025811672, -0.035723425447940826, -0.013704409822821617, -0.020030509680509567, -0.03434456139802933, 0.05595654249191284, -0.05479142442345619, 0.03956298157572746, -0.022243376821279526, 0.01829417422413826, -0.006947813089936972, 0.014244960620999336, -0.043505046516656876, -0.0018895023968070745, -0.04368056729435921, -0.058680277317762375, -0.0030717107001692057, -0.04252762347459793, 0.002304516499862075, -0.0008358096820302308, 0.0010119822109118104, 0.020045898854732513, -0.05518514662981033, 0.02965478226542473, 0.07832277566194534, 0.010077073238790035, -0.02922024391591549, -0.044189248234033585, 0.046151746064424515, 0.052737027406692505, 0.024143178015947342, -0.011655583046376705, -0.023906776681542397, -0.015061575919389725, -0.007111452519893646, -0.0035554186906665564, -0.020749224349856377, -0.02171727456152439, 0.013384440913796425, 0.03798532485961914, -0.020814010873436928, 0.02200665883719921, -0.027909401804208755, -0.0540582612156868, -0.018026193603873253, 0.028488418087363243, 0.0158653873950243, 0.00770567636936903, 0.011138837784528732, 0.027763405814766884, -0.0024011172354221344, 0.028812570497393608, 0.005422672722488642, -0.04267437383532524, 0.0015255730831995606, 0.047912124544382095, -0.009878721088171005, -0.023651964962482452, 0.03538436070084572, 0.03978767246007919, -0.018123308196663857, -0.024888506159186363, 0.013438718393445015, 0.013528471812605858, 0.009274812415242195, -0.016368785873055458, -0.03319010138511658, -0.00026091127074323595, -0.014679452404379845, -0.004586873110383749, 0.025509074330329895, 7.687247125431895e-05, -0.01679125428199768, 0.03272443637251854, -0.00498584657907486, -0.08098437637090683, 0.033227160573005676, 0.041135501116514206, -0.020552413538098335, -0.024541201069951057, -0.014870314858853817, -0.003260064870119095, -0.00508832186460495, -0.01178173627704382, 0.055890221148729324, -0.027209565043449402, 0.0061532603576779366, 0.026531262323260307, -0.03964628279209137, 0.02974644862115383, -0.030247721821069717, -0.01858033426105976, 0.026085684075951576, -0.020998913794755936, -0.05137830972671509, -0.029751049354672432, -0.0032536389771848917, 0.03270229324698448, 0.04815739020705223, -0.031799644231796265, 0.026899144053459167, 0.036903634667396545, 0.028090380132198334, -0.00533187435939908, -0.0353778600692749, -0.02846425399184227, -0.06071636453270912, -0.04442858323454857, 0.002965606050565839, -0.02567128650844097, -0.00209463806822896, 0.003273980226367712, 0.011739890091121197, -0.025458361953496933, 0.010731544345617294, -0.002379442797973752, -0.055567916482686996, -0.012733859941363335, -0.0072062257677316666, 0.002110306406393647, -0.023956546559929848, 0.010292360559105873, -0.0026891250163316727, -0.007867799140512943, 0.010646612383425236, 0.007312305271625519, 0.005861183628439903, 0.02139093540608883, 0.014071590267121792, 0.02434168942272663, -0.006352119147777557, 0.001042000949382782, -0.02985256165266037, 0.02807818539440632, -0.010468460619449615, 0.03369704633951187, -0.009914156049489975, 0.011566421017050743, 0.017000732943415642, -0.011083688586950302, 0.01402741577476263, 0.0014308973914012313, -0.001794113777577877, -0.039497990161180496, 0.02809981070458889, 0.031652361154556274, -0.0002063484425889328, -0.0013780869776383042, -0.010678593069314957, 0.02216428890824318, -0.04099434241652489, -0.026887426152825356, -0.013121536932885647, -0.0042507764883339405, 0.010277763940393925, 0.013813989236950874, 0.041464440524578094, 0.060141123831272125, 0.03211291879415512, 0.05936726927757263, -0.010875879786908627, 0.026409346610307693, 0.01009694766253233, -0.0017264272319152951, 0.009004703722894192, 0.008650096133351326, -0.02216312102973461, -0.07575877010822296, 0.022567924112081528, 0.015442412346601486, -0.039810460060834885, 0.017951177433133125, -0.014490922912955284, -0.014093530364334583, -0.01732943207025528, 0.0006399161065928638, 0.01895703375339508, 0.043834391981363297, 0.022465180605649948, -0.022969866171479225, -0.029334865510463715, 5.200804298510775e-05, -0.008746545761823654, 0.01760862022638321, -0.07141276448965073, -0.03918249160051346, 0.013746818527579308, -0.04491210728883743, -0.03214431554079056, -0.022100653499364853, 0.00361987529322505, 0.002632023300975561, 0.03313222527503967, 0.02343643270432949, -0.0060027106665074825, -0.004334235563874245, -0.003977382555603981, 0.006198350805789232, -0.040210746228694916, -0.026640014722943306, -0.028950171545147896, 0.004930676426738501, -0.056838423013687134, -0.07319063693284988, 0.014187488704919815, 0.06350096315145493, -0.005581224802881479, 0.002531004138290882, -0.0588497556746006, -0.007978128269314766, 0.009439791552722454, 0.029774140566587448, -0.06852079182863235, 0.046975698322057724, -0.03663534298539162, 0.02243962325155735, -0.0016705866437405348, -0.008960812352597713, -0.021956192329525948, 0.04590392857789993, 0.03809681534767151, -0.01031474955379963, -0.012032520957291126, 0.029164744541049004, 0.025784717872738838, -0.04747569188475609, 0.05620037391781807, 0.002992518711835146, 0.014015247114002705, 0.01691436767578125, 0.02471444010734558, 0.031086968258023262, 0.04656876251101494, 0.049866072833538055, 0.017553215846419334, -0.005175927188247442, 0.03278385475277901, 0.03267458453774452, -0.029264213517308235, 0.021814199164509773, 0.06776665151119232, 0.02881477400660515, -0.0036126156337559223, -0.004749826621264219, -0.0818781703710556, 0.023243997246026993, -0.018401488661766052, 0.022793181240558624, 0.027195744216442108, -0.025032389909029007, 0.020570574328303337, 0.008869755081832409, -0.033035650849342346, 0.03833439573645592, -0.003744359826669097, -0.05041581392288208, -0.014331710524857044, 0.018143106251955032, 0.04587385430932045, 0.026649875566363335, 0.021729135885834694, -0.006224488373845816, 0.04084625467658043, 0.05114423856139183, -0.0021271982695907354, 0.012187084183096886, -0.012819879688322544, 0.014885306358337402, -0.004250601399689913, 0.01205488108098507, 0.02054668217897415, 0.019587917253375053, -0.01211189478635788, -0.030553525313735008, -0.009365328587591648, 0.05721055716276169, -0.011954417452216148, -0.03815360367298126, -0.0018870386993512511, 0.008157496340572834, -0.038694292306900024, -0.03388403356075287, 0.03327866271138191, -0.04750627651810646, 0.007888170890510082, 0.03970921039581299, -0.009914088062942028, -0.015789836645126343, 0.035720694810152054, 0.021983297541737556, 0.011537540704011917, 0.008103612810373306, 0.049017589539289474, -0.025610651820898056, 0.07782427221536636, 0.05070899426937103, 0.021977122873067856, 0.0036052826326340437, 0.02135283872485161, -0.009721157141029835, 0.0066360472701489925, 0.017741316929459572, 0.01663694903254509, -0.026158982887864113, -0.0244500283151865, -0.04875266179442406, 0.034371208399534225, -0.010440059006214142, -0.0079031465575099, -0.0073212855495512486, 0.013102956116199493, -0.0016674462240189314, -0.03992196172475815, -0.0014498207019641995, 0.04613228887319565, -0.010869920253753662, 0.016860634088516235, 0.008330672048032284, -0.02116692066192627, -0.06434813141822815, 0.008353517390787601, -0.040302298963069916, 0.05534316226840019, -0.015126404352486134, -0.03973132371902466, 0.0003827953478321433, -0.041135549545288086, -0.014096205122768879, -0.010210616514086723, -0.009025170467793941, -0.035056259483098984, 0.009151321835815907, 0.013545006513595581, 0.03374570980668068, -0.013556988909840584, -0.021753082051873207, -0.04496417194604874, 0.05304636433720589, 0.03882059454917908, 0.023138517513871193, 0.03684712573885918, 0.05122204124927521, 0.0019009907264262438, -0.03594965860247612, 0.0070584057830274105, 0.017035530880093575, 0.004977717995643616, -0.01144414022564888, -0.005097060929983854, 0.0010898822220042348, -0.02941039204597473, -0.03751419484615326, 0.03332163766026497, 0.025613995268940926, -0.011050451546907425, -0.019663074985146523, -0.02339046262204647, -0.041274670511484146, -0.04806673154234886, 0.015529918484389782, -0.03520146384835243, 0.009547583758831024, 0.006860070396214724, -0.02936660684645176, -0.001957690343260765, -0.0036652085836976767, 0.2866895794868469, 0.09344387799501419, 0.015487791039049625, 0.012581935152411461, 0.03434406593441963, 0.04560017213225365, 0.049981217831373215, -0.0033910691272467375, 0.02355043776333332, -0.034592192620038986, 0.02324368618428707, -0.019145864993333817, -0.02496318146586418, 0.018076902255415916, 0.0005326875252649188, 0.0466749481856823, -0.02835766226053238, 0.002317414153367281, -0.00323092401959002, -0.03875868394970894, -0.025238817557692528, 0.018395524471998215, 0.008548404090106487, 0.021682292222976685, -0.0031493029091507196, -0.010580242611467838, 0.011193373240530491, -0.03952186182141304, 0.019178858026862144, -0.02970734052360058, -0.049236565828323364, -0.0477851964533329, 0.003466234775260091, -0.011463340371847153, -0.012878109700977802, 0.045589253306388855, 0.004700401332229376, -0.05643317103385925, -0.03052714839577675, 0.01288765762001276, -0.011654005385935307, -0.02294335328042507, -0.008905303664505482, -0.01056166086345911, -0.021712662652134895, 0.037002839148044586, 0.00543446047231555, 0.0137705709785223, 0.027515340596437454, -0.05906878411769867, 0.04257028549909592, -0.03802800923585892, 0.019658653065562248, -0.005658367648720741, -0.033348627388477325, 0.006603368557989597, -0.01444281917065382, -0.04308272898197174, -0.003827780019491911, 0.03119952604174614, 0.00973883643746376, 0.005565133411437273, -0.029109502211213112, 0.05605610832571983, 0.005115164909511805, 0.030932437628507614, 0.013192424550652504, 0.012812458910048008, -0.025234738364815712, -0.02503521926701069, 0.023767072707414627, -0.002770764287561178, -0.011734852567315102, -0.023799479007720947, 0.02343357913196087, 0.01149965263903141, 0.003787355264648795, 0.02246670611202717, 0.00018035688844975084, -0.05700268968939781, 0.0072499606758356094, -0.02409057877957821, -0.006688128691166639, -0.039328623563051224, 0.025693673640489578, 0.027096517384052277, -0.04122734069824219, 0.009763460606336594, -0.06666900962591171, 0.03646661341190338, -0.0037974119186401367, 0.046318281441926956, 0.010660733096301556, -0.03418205678462982, 0.040934450924396515], metadata={'page_label': '3', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n2 R ELATED WORK\\nThis work is inspired by the role that Torch (Collobert et al., 2002), Theano (Bergstra et al., 2010;\\n2011; Al-Rfou et al., 2016), Chainer (Tokui et al., 2015), and others played in the development in\\ndeep learning by providing powerful abstractions. A similar transformation is emerging with higher-\\nlevel pipelines of LMs, and we are seeking to offer a solid conceptual framework and programming\\nabstractions for what we call foundation model programming. We draw on differentiable program-\\nming (Wang et al., 2018) but applied to LM calls rather than neural networks, and borrow syntactic\\nelements from PyTorch (Paszke et al., 2019).\\nIn-context learning (McCann et al. 2018; Radford et al. 2018; Brown et al. 2020) is a key mechanism\\nfor foundation model programming. A growing body of work has revealed that, especially with\\ninstruction tuning (Ouyang et al., 2022), we can elicit sophisticated behavior via prompting (Wei\\net al., 2022; Wang et al., 2022b; Press et al., 2022; Yao et al., 2022; Khot et al., 2022; Madaan et al.,\\n2023). Similarly, forms of weak supervision that would normally require task-specific (Khattab\\net al., 2021a;b) or hand-built (Ratner et al., 2016; Hancock et al., 2018) heuristics are now done by\\nLMs (Wang et al., 2022b; Zelikman et al., 2022; Zhang et al., 2022; Shao et al., 2023).\\nIn-context learning methods now routinely invoke tools, leading to LM pipelines that use retrieval\\nmodels (Chen et al., 2017; Lewis et al., 2020; Guu et al., 2020; Lazaridou et al., 2022; Izacard et al.,\\n2022), multimodal foundation models, and more traditional tools like APIs (Nakano et al., 2021)\\nand calculators. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='47065889-3de8-465d-ba99-b29429aa78d4', embedding=[0.03540728986263275, 0.011476444080471992, -0.011357917450368404, -0.010939342901110649, -0.0362405963242054, -0.027787327766418457, -0.030537504702806473, -0.019970936700701714, -0.017652887850999832, 0.06939444690942764, -0.014944612979888916, -0.005742068402469158, -0.008369955234229565, -0.019120972603559494, 0.0008927453891374171, -0.0001337460707873106, -0.0022798047866672277, -0.013219384476542473, -0.05904006212949753, -0.004814804065972567, 0.027412980794906616, -0.01875261403620243, -0.0713082104921341, -0.008369271643459797, -0.03323190659284592, 0.024909641593694687, 0.02674507163465023, 0.010362446308135986, 0.0901835709810257, 0.05144635960459709, 0.01282134372740984, -0.005750651936978102, 0.01949417032301426, -0.04288921132683754, -0.054264556616544724, -0.06916096061468124, 0.005177056882530451, -0.012725301086902618, -0.028825530782341957, -0.023327162489295006, 0.03458046168088913, -0.026635583490133286, 0.05456892400979996, -0.07129378616809845, -0.06393544375896454, -0.016547791659832, 0.013959921896457672, -0.023188292980194092, 0.002831842750310898, -0.04048958048224449, -0.012722187675535679, 0.02760566957294941, -0.004865298978984356, -0.0069178007543087006, -0.00830342248082161, 0.008463406004011631, -0.0035857001785188913, 0.002149879466742277, -0.032430924475193024, 0.00924367643892765, -0.0023631476797163486, 0.008523977361619473, -0.0027072031516581774, -0.062460362911224365, -0.0012951033422723413, 0.015476799570024014, 0.011654126457870007, -0.006279952824115753, -0.02615942247211933, -0.02231600321829319, -0.05919744446873665, 0.023823942989110947, -0.03856014832854271, -0.052527278661727905, -0.0024786752182990313, -0.004183952696621418, 0.03716675564646721, 0.008313527330756187, -0.03517640009522438, 0.03572164103388786, 0.04572252929210663, 0.04384181648492813, -0.014514855109155178, 0.0012179897166788578, -0.012636261992156506, -0.035979993641376495, 0.07019221782684326, 0.002843688940629363, -0.01127113588154316, -0.013211729004979134, -0.012840228155255318, 0.035068538039922714, 0.028179781511425972, 0.0447288379073143, 0.047493819147348404, 0.030196506530046463, -0.009165561757981777, 0.04286345839500427, -0.017869368195533752, 0.0010441658087074757, 0.039699845016002655, 0.07613293826580048, -0.02664818987250328, 0.001095198793336749, -0.06243559345602989, -0.020458564162254333, 0.02723834477365017, 0.0028396346606314182, -0.017881246283650398, -0.03257552534341812, 0.02464645355939865, -0.0022370992228388786, -0.030567407608032227, -0.002798387547954917, -0.03996682167053223, 0.028339361771941185, 0.013917801901698112, 0.01189452689141035, -0.026216331869363785, -0.00833478569984436, 0.010729006491601467, -0.016349351033568382, -0.004679502919316292, -0.0007858723984099925, 0.01464057806879282, -0.03059457615017891, 0.005296832416206598, 0.04284108802676201, -0.030810879543423653, -0.01618281751871109, -0.008657926693558693, 0.003116193227469921, -0.0006701909005641937, 0.06327671557664871, 0.026408202946186066, 0.001843366539105773, -0.0035442416556179523, 0.028037210926413536, 0.012989756651222706, 0.0028693729545921087, 0.009107979014515877, -0.0356561504304409, 0.00371504295617342, 0.10246779769659042, 0.007606562692672014, -0.009102115407586098, -0.03375975787639618, 0.00015510634693782777, -0.04521556198596954, 0.03270689398050308, 0.019425133243203163, -0.0009093593107536435, -0.014028960838913918, 0.0228673554956913, -0.007351112551987171, -0.01550355739891529, -0.02647079899907112, -0.008297617547214031, -0.0036599156446754932, 0.005457365419715643, -0.020931260660290718, -0.028733771294355392, -0.05453204736113548, 0.02048964612185955, -0.01477730367332697, 0.04734860360622406, -0.034451380372047424, 0.004899873398244381, -0.0055933753028512, -0.03632211312651634, 0.027181070297956467, -0.0028171036392450333, -0.0015180157497525215, 0.025924427434802055, 0.05373350530862808, 0.0435219444334507, 0.06150352209806442, 0.0066031189635396, 0.02108617126941681, 0.0115619832649827, -0.019778575748205185, -0.017290573567152023, 0.0019056735327467322, -0.008020907640457153, 0.024435631930828094, 0.025738175958395004, 0.021875347942113876, 0.00813345331698656, -0.014595589600503445, -0.0009885040344670415, -0.007204235531389713, 0.055271048098802567, -0.03249106928706169, 0.031497661024332047, 0.01726987212896347, 0.01717807911336422, -0.010476366616785526, 0.031315214931964874, 0.014046111144125462, -0.04256138578057289, -0.034446459263563156, 0.07255685329437256, 0.0069383783265948296, -0.010570390149950981, -0.059224583208560944, 0.034767914563417435, -0.007884149439632893, 0.05746044963598251, -0.047681502997875214, 0.025134354829788208, 0.014116273261606693, 0.015371360816061497, -0.03240717947483063, -0.006408765446394682, 0.019173111766576767, -0.01680290326476097, -0.014017985202372074, -0.019776716828346252, 0.0323498360812664, 0.0005261269980110228, 0.011520623229444027, -0.012572001665830612, 0.0063299997709691525, -0.018996240571141243, -0.02506476454436779, -0.01464915368705988, 0.01684536412358284, 0.04704951494932175, -0.014494476839900017, -0.0023946096189320087, 0.016234152019023895, 0.01423550583422184, -0.016563814133405685, 0.06825453788042068, 0.0316951721906662, 0.014427009038627148, 0.06874554604291916, 0.054473765194416046, -0.006160959135740995, -0.009106047451496124, -0.00214840704575181, 0.005531668663024902, -0.0022951303981244564, 0.045620325952768326, 0.018260478973388672, 0.004025721922516823, 0.009950357489287853, -0.00022999114298727363, -0.018204031512141228, -0.016381846740841866, -0.07567243278026581, 0.04011436924338341, 0.01826578751206398, -0.016456982120871544, -0.031466808170080185, -0.021792765706777573, -0.0012620027409866452, 0.03166763857007027, -0.02114954963326454, -0.02146965079009533, 0.04697791114449501, 0.013691560365259647, -0.008858231827616692, -0.02792431227862835, 0.01802286133170128, 0.03571910783648491, 0.02225821278989315, 0.017390022054314613, 0.004588389303535223, -0.014195655472576618, -0.020039832219481468, -0.04933895543217659, -0.07790612429380417, 0.0067726243287324905, -0.014499823562800884, -0.006520388647913933, -0.004626210778951645, -0.05319729074835777, -0.0020958748646080494, -0.06084543094038963, 0.030255449935793877, -0.002329184440895915, -0.016558915376663208, 0.026691054925322533, 0.060162778943777084, -0.011697608046233654, -0.05437702685594559, 0.03280108422040939, -0.027114175260066986, 0.045447297394275665, 0.011561932042241096, -0.016537262126803398, -0.02537471428513527, -0.008227032609283924, 0.02491655759513378, -0.007748560979962349, 0.0072195688262581825, -0.026469087228178978, -0.04955492913722992, -0.015310951508581638, 0.005907233338803053, -0.013470740057528019, 0.04009956866502762, -0.0332336500287056, -0.05542782321572304, 0.054970819503068924, 0.017953770235180855, -0.03887077793478966, 0.041915591806173325, 0.029534723609685898, -0.03833461552858353, 0.02715465985238552, -0.014829644933342934, 0.01704089716076851, -0.03775394707918167, 0.04853648319840431, 0.029987255111336708, -0.031618863344192505, -0.03483977168798447, -0.05395388603210449, -0.03657901659607887, 0.012091543525457382, 0.007344864774495363, -0.024005215615034103, -0.019958239048719406, 0.04769573360681534, -0.013117081485688686, -0.055363766849040985, 0.013930939137935638, -0.03995879739522934, -0.020024046301841736, 0.026000620797276497, -0.00222986307926476, 0.0552716888487339, 0.02063310518860817, 0.03296493738889694, -0.025405537337064743, 0.007706402335315943, -0.02991235814988613, 0.02105783484876156, 0.011362036690115929, -0.03143449127674103, 0.015146550722420216, 0.024990204721689224, 0.01195333618670702, 0.008823418989777565, 0.010106224566698074, -0.03729487955570221, -0.023941894993185997, -0.02524746023118496, 0.016554754227399826, 0.01895369589328766, -0.011380774900317192, -0.0008132990333251655, 0.03543493524193764, 0.03365952521562576, -0.023601971566677094, -0.022458164021372795, 0.020716683939099312, 0.031726524233818054, -0.009041558019816875, 0.022186294198036194, -0.01882457174360752, 0.009594055823981762, -0.021406223997473717, -0.02160150371491909, -0.030550215393304825, 0.014528322964906693, 0.027772342786192894, -0.05199287459254265, 0.032041892409324646, -0.0005804827669635415, -0.03774883598089218, 0.0014689892996102571, -0.0291117113083601, -0.048112668097019196, 0.0107608363032341, 0.036544319242239, 0.05225927382707596, -0.013061106204986572, -0.030361581593751907, 0.02820761129260063, 0.008846287615597248, 0.02232559211552143, 0.03774433955550194, 0.025389516726136208, 0.011102477088570595, -0.014379886910319328, -0.026449445635080338, 0.011140314862132072, -0.007541745901107788, 0.01996682398021221, -0.008929947391152382, -0.015101277269423008, -0.03134472668170929, -0.04241840913891792, 0.01874198019504547, 0.02496705763041973, 0.020592626184225082, -0.0069884262047708035, 0.031469251960515976, -0.036231279373168945, 0.03629284352064133, 0.024042606353759766, 0.018956640735268593, 0.017045337706804276, -0.056965421885252, 0.0018039800925180316, -0.0337560698390007, 0.004672512412071228, 0.007380233146250248, -0.009662903845310211, 0.00398640800267458, 0.03602876141667366, -0.018460284918546677, 0.0037121542263776064, -0.018511174246668816, 0.0006074221455492079, -0.0007901718490757048, 0.03166115656495094, -0.0043712193146348, -0.019534653052687645, -0.021933000534772873, 0.008743797428905964, 0.014121604152023792, -0.03310990706086159, -0.01991281472146511, -0.011585588566958904, 0.00079397764056921, 0.031437814235687256, -0.05220772325992584, -0.03774232417345047, 0.012770365923643112, -0.021640503779053688, -0.05801105871796608, 0.06314251571893692, 0.060421839356422424, -0.04992885887622833, 7.114057370927185e-05, -0.032064348459243774, 0.006588527001440525, -0.003371110185980797, -0.012259812094271183, -0.007200140506029129, 0.0397910475730896, -0.028095468878746033, 0.025710878893733025, 0.0269766878336668, -0.0034052752889692783, -0.030547669157385826, 0.015563891269266605, -0.054983049631118774, 0.022328896448016167, -0.03974602371454239, 0.003883064491674304, -0.0237469132989645, -0.009823935106396675, 0.0004397005250211805, -0.0047335852868855, 0.020435860380530357, 0.011518468149006367, -0.007153382059186697, 0.022360822185873985, -0.03999442234635353, -0.026756813749670982, 0.034743424504995346, 0.019840704277157784, -0.006832154933363199, 0.0403355173766613, 0.00575391948223114, -0.02456558682024479, -0.004168088082224131, 0.0013937926851212978, -0.014845985919237137, 0.02228613756597042, 0.002018821658566594, 0.022530950605869293, -0.013780076988041401, -0.030048467218875885, -0.0003610362473409623, -0.04903116822242737, 0.03997810557484627, 0.012531163170933723, -0.010744795203208923, 0.009782928042113781, -0.03655165433883667, -0.01752658188343048, 0.017018277198076248, -0.028276711702346802, -0.017183110117912292, -0.006396438926458359, -0.015455435030162334, 0.022741692140698433, -0.03809920698404312, -0.053146202117204666, -0.04120534658432007, -0.005476402584463358, 0.008989431895315647, 0.028697922825813293, 0.07007797807455063, 0.05601375922560692, -0.001045000972226262, -0.04662927985191345, 0.060185231268405914, -0.017775001004338264, -0.03516750782728195, -0.034178510308265686, 0.0010697821853682399, -0.02212521992623806, 0.02496386133134365, -0.05269322916865349, 0.011341153644025326, 0.0030138003639876842, -0.00986313447356224, 0.0021107285283505917, 0.009472525678575039, 0.013254842720925808, -0.0028224980924278498, -0.031630534678697586, 0.055607352405786514, 0.01616637408733368, -0.10017529129981995, -0.02957720123231411, 0.004725587088614702, -0.038207512348890305, 0.0049739861860871315, 0.028039637953042984, 0.0051027280278503895, -0.02795829251408577, -0.03932648524641991, 0.039366353303194046, -0.04193698242306709, 0.013100351206958294, -0.032532405108213425, -0.04974097013473511, 0.02605753391981125, -0.00033123817411251366, 0.04066277667880058, -0.032578811049461365, -0.0676683783531189, -0.0349489189684391, 0.03571635112166405, -0.04365193843841553, -0.01664189249277115, -0.01862954907119274, 0.009886580519378185, 0.021413134410977364, 0.06318783015012741, -0.0038839145563542843, -0.007806089706718922, -0.018237777054309845, 0.013467077165842056, 0.02048206329345703, 0.030113069340586662, -0.03666555881500244, -0.027431784197688103, -0.0002577032137196511, 0.015905721113085747, 0.020808324217796326, 0.02302416041493416, -0.034262556582689285, 0.01343234907835722, -0.029063235968351364, -0.0030271473806351423, -0.0569661445915699, -0.00873284600675106, -0.023874057456851006, -0.04130673408508301, 0.04542819783091545, -0.04141293838620186, 0.010100438259541988, -0.019332347437739372, 0.033994656056165695, 0.007932079955935478, 0.005110938102006912, -0.04903150722384453, 0.002253566402941942, -0.044484298676252365, -0.03317398950457573, 0.003041210351511836, -0.04415035992860794, 0.025425883010029793, 0.0429789163172245, -0.023067675530910492, 0.0331079438328743, -0.06659846007823944, 0.0392095223069191, 0.06350033730268478, 0.015681438148021698, 0.012362978421151638, -0.0478728711605072, -0.0038837401662021875, -0.0038477806374430656, -0.005323162768036127, -0.0009146957308985293, -0.01980012096464634, -0.016025613993406296, -0.028477564454078674, -0.01805015280842781, -0.02041773311793804, -0.007109218277037144, 0.005335869267582893, 0.06078587844967842, -0.017227139323949814, 0.028375521302223206, 0.0002758146438281983, -0.07090340554714203, -0.025547217577695847, 0.035264160484075546, -0.019376473501324654, 0.024687176570296288, 0.019975289702415466, 0.013894772157073021, -0.00985528714954853, -0.017660755664110184, -0.02952297031879425, -0.020254911854863167, -0.01200328953564167, 0.050663791596889496, 0.011613761074841022, -0.031928882002830505, 0.05690290406346321, 0.04109405726194382, -0.008032715879380703, -0.03762592747807503, 0.01015475019812584, 0.020862367004156113, -0.02778942696750164, -0.01808452047407627, -0.013859063386917114, -0.0008598964777775109, -0.007297413423657417, 0.006038529798388481, 0.03815976530313492, -0.027416955679655075, 0.002689978340640664, 0.015185756608843803, 0.008149371482431889, -0.06023527681827545, 0.0499795526266098, 0.035312604159116745, -0.027827387675642967, -0.0038872198201715946, -0.0434630922973156, -0.008657918311655521, 0.005368330515921116, -0.01771382801234722, 0.0436553917825222, -0.024117767810821533, -0.0022980901412665844, 0.0374557189643383, 0.012847659178078175, 0.06215464323759079, -0.02818140760064125, 0.017863823100924492, 0.01889730989933014, -0.0642891526222229, -0.04865874722599983, -0.0217428021132946, 0.02377386949956417, -0.006100357044488192, 0.04468546435236931, -0.002929290756583214, 0.03605727478861809, 0.03910919651389122, 0.03492940217256546, -0.0020931996405124664, -0.0696026012301445, -0.01680089347064495, -0.024961600080132484, -0.006491741631180048, 0.0014115896774455905, -0.05254935473203659, 0.008741919882595539, 0.040839266031980515, -0.005163491237908602, -0.02219548262655735, -0.014496913179755211, 0.017157450318336487, -0.04948921501636505, -0.03544411435723305, -0.024772968143224716, 0.02124902606010437, -0.05678509920835495, 0.008537320420145988, -0.0062897102907299995, 0.004508865997195244, -0.031795673072338104, 0.00806336384266615, -0.03433331847190857, -0.004912997130304575, 0.007233717013150454, 0.028224457055330276, -0.025863567367196083, -0.0024017291143536568, -0.026264408603310585, 0.007341977674514055, -0.011037245392799377, 0.010370377451181412, -0.029950737953186035, 0.06783399730920792, -0.00735437823459506, -0.039530977606773376, 0.0034889953676611185, -0.015028777532279491, 0.015174036845564842, -0.03244328871369362, 0.007060404866933823, 0.04392430931329727, -0.014125049114227295, 0.022355180233716965, -0.010025622323155403, 0.0327753871679306, -0.038242071866989136, -0.018925214186310768, -0.011449900455772877, -0.005167790222913027, 0.00592168839648366, 0.009481620043516159, 0.027359729632735252, 0.06513505429029465, 0.04473288729786873, 0.04746362194418907, 0.03389802575111389, 0.0010052688885480165, 0.028609897941350937, 0.007784465327858925, 0.0011121792485937476, -0.0027258603367954493, -0.025438379496335983, -0.057036299258470535, 0.04842216521501541, 0.018613453954458237, -0.015053554438054562, 0.01839851588010788, -0.016252197325229645, -0.01661374233663082, -0.04740886390209198, -0.025130977854132652, 0.02587570808827877, 0.02695828676223755, 0.06002958118915558, -0.02103138156235218, -0.01715468429028988, -0.002823305781930685, -0.01920836791396141, -0.007877500727772713, -0.05820796266198158, -0.034326985478401184, 0.013680025935173035, -0.014330817386507988, -0.006403176113963127, -0.013175585307180882, -0.004446159116923809, 0.0107802152633667, 0.041316770017147064, 0.01719694957137108, 0.017588065937161446, 0.04974141716957092, -0.006352491211146116, 0.0024379019159823656, -0.046123962849378586, -0.058021917939186096, -0.0061285970732569695, 0.020937101915478706, -0.03985247388482094, -0.047875404357910156, 0.005215513054281473, 0.0811629518866539, 0.019798655062913895, -0.003373874584212899, -0.06759108603000641, 0.00984604749828577, 0.001982001820579171, 0.021663157269358635, -0.08249040693044662, 0.04451688006520271, -0.008243422023952007, -0.0051160636357963085, -0.007787942886352539, 0.008042368106544018, -0.0011479209642857313, 0.02021554298698902, 0.024155793711543083, 0.012320785783231258, -0.013736656866967678, 0.02966814860701561, 0.01771542802453041, -0.042411141097545624, 0.06519852578639984, 0.0025325785391032696, 0.028129881247878075, 0.018193647265434265, -0.007150948978960514, 0.04446418583393097, 0.025265470147132874, 0.055459022521972656, 0.03994940593838692, -0.01853194274008274, 0.05914836376905441, 0.03737611323595047, -0.031215114519000053, -0.009912438690662384, 0.028771786019206047, 0.024887483566999435, -0.02087285928428173, 0.002941804938018322, -0.061720576137304306, 0.032386135309934616, -0.022482281550765038, 0.027630727738142014, 0.005200187209993601, -0.021572254598140717, 0.015978340059518814, -0.020503848791122437, -0.034723639488220215, 0.04237685352563858, 0.0005961951683275402, -0.05400057137012482, -0.020820235833525658, 0.01482327189296484, 0.031132174655795097, 0.012950543314218521, 0.018309909850358963, -0.02101377211511135, 0.05395573750138283, 0.022900789976119995, 0.050701871514320374, 0.0028272506315261126, 0.003675201442092657, 0.008977038785815239, 2.7566111384658143e-05, 0.013768934644758701, -0.024779651314020157, -0.008285955525934696, 0.005615890491753817, -0.010098101571202278, -0.00606968579813838, 0.05998827517032623, -0.001290996209718287, -0.035335611552000046, -0.01614980399608612, -0.011922866106033325, -0.01220753788948059, -0.029802700504660606, 0.03544020280241966, -0.02585599012672901, -0.0002501343551557511, 0.04809597134590149, -0.019627714529633522, -0.02985227108001709, 0.03908829391002655, 0.007283852435648441, 0.00795217975974083, 0.04333154112100601, 0.03982643783092499, 0.011132442392408848, 0.0902412161231041, 0.03870602697134018, 0.012139650993049145, 0.023197012022137642, 0.029530823230743408, 0.011558298952877522, -0.00017675571143627167, 0.004787873942404985, 0.003156309248879552, -0.011533075012266636, -0.03828708454966545, -0.0570092611014843, 0.018866563215851784, -0.008425047621130943, -0.019815906882286072, 0.01876111887395382, 0.008810666389763355, 0.015607851557433605, -0.04075752943754196, -0.0037616074550896883, 0.05695909634232521, 0.03145359456539154, 0.038284726440906525, 0.01305199321359396, 0.012284732423722744, -0.06820555031299591, 0.024939803406596184, -0.018004169687628746, 0.02792387455701828, -0.0024566000793129206, -0.03430073335766792, 0.01806042529642582, -0.03999903425574303, -0.026853341609239578, -0.0501832440495491, -0.022985447198152542, -0.009071558713912964, 0.03029121831059456, 0.014508084394037724, 0.032942160964012146, 0.021475164219737053, -0.02356334775686264, -0.023238860070705414, 0.05004839971661568, 0.05202169343829155, -0.023593725636601448, 0.06867226213216782, 0.061862267553806305, -0.002177582122385502, -0.025717834010720253, 0.021953916177153587, -0.01942284218966961, -0.020113931968808174, 0.03814314305782318, -0.018163129687309265, 0.00718379020690918, -0.01022541243582964, -0.056214340031147, 0.003564567305147648, 0.03272256255149841, 0.03459903597831726, -0.005695978179574013, -0.027742771431803703, -0.004017238970845938, -0.0535631887614727, 0.0011482927948236465, -0.04953138530254364, 0.033842142671346664, 0.0022290123160928488, 0.003890315303578973, -0.007477397099137306, -0.01136241015046835, 0.2441961020231247, 0.0693061351776123, 0.02016352489590645, 0.03604653477668762, 0.04623047634959221, 0.051325149834156036, 0.02701154537498951, -0.03191966190934181, 0.03335218504071236, -0.05440882593393326, 0.014518504962325096, -0.020163167268037796, 0.007541004102677107, 0.023182999342679977, -0.040591463446617126, 0.017707951366901398, -0.08056580275297165, -0.0022082473151385784, -0.03172258660197258, -0.0263870470225811, -0.05248512327671051, 0.05265520140528679, 0.003472711890935898, -0.011143876239657402, 0.01619590073823929, 0.01662510074675083, 0.009760132990777493, -0.01009879820048809, 0.05703355744481087, -0.03362945839762688, -0.0006307288422249258, -0.03583454713225365, 0.022001639008522034, -0.04302918538451195, -0.023428350687026978, 0.03311464190483093, 0.013771398924291134, -0.015747124329209328, -0.0006793225766159594, 0.02936112880706787, 0.01795681193470955, -0.00851796381175518, -0.0197253730148077, -0.023762088268995285, -0.03351974859833717, 0.06331481784582138, 0.0011923968559131026, 0.016127072274684906, 0.03465188294649124, -0.06109924241900444, 0.030358225107192993, -0.03547032177448273, 0.03676247596740723, -0.020290391519665718, -0.054642315953969955, 0.001456443453207612, 0.012024731375277042, -0.05638258904218674, -0.05103157088160515, -0.01871701516211033, 0.011867847293615341, 0.011050335131585598, -0.011935901828110218, 0.0320683978497982, -0.015834474936127663, 0.000457706511951983, 0.026204504072666168, -0.022249756380915642, -0.03502170369029045, 0.004535382613539696, 0.01818060502409935, 0.003925543278455734, -0.004755579400807619, -0.03850262239575386, 0.04765741154551506, -0.018020715564489365, -0.006321994587779045, 0.045899149030447006, 0.0031922119669616222, -0.039836201816797256, -0.01026331726461649, -0.0009901990415528417, -0.010984485037624836, -0.032879941165447235, 0.023933103308081627, 0.04074203595519066, -0.033206865191459656, 0.007080317474901676, -0.01848997361958027, 0.01795889437198639, -0.01797584630548954, 0.028140489012002945, -0.007976658642292023, -0.006839541718363762, 0.014774257317185402], metadata={'page_label': '3', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='A number of toolkits have been developed to facilitate this, including LangChain\\n(Chase, 2022), Semantic Kernel (Microsoft, 2023), LlamaIndex (Liu, 2022), and many other re-\\ntrieval and agent libraries. These toolkits provide pre-packaged chains and agents that connect\\nLMs with numerous accessible tools. However, they suffer from the pervasive prompt engineering\\nchallenges we address in DSPy: they express task-specific behavior through hand-written prompt\\ntemplates (for detailed discussion, see Appendix B).\\nResearchers are starting to apply discrete optimization and RL to find effective prompts, generally\\nfor a single logical LM call (Guo et al., 2023; Pryzant et al., 2023; Huang et al., 2022; Yang et al.,\\n2023). DSPy seeks to generalize this space: it offers a rich framework for optimizing arbitrary\\npipelines from high-level declarative signatures, by bootstrapping high-quality multi-stage demon-\\nstrations with constraints. In this framework, DSPy teleprompters may apply optimization using\\nmodel selection techniques like cross-validation or, in principle, with sophisticated techniques in-\\nvolving RL and LM feedback (Hu et al., 2023; Zhao et al., 2023a; Shinn et al., 2023) or learned or\\nBayesian hyperparameter optimization methods (Bergstra et al., 2013; Akiba et al., 2019).\\nThe present paper seeks to motivate DSPy as a programming model and to report new empirical\\nfindings from applying the DSPy compiler. This is inspired by formative work by Bergstra et al.\\n(2010; 2013), Paszke et al. (2019), and Wolf et al. (2020), who support their respective programming\\nmodels with a mix of benchmark numbers and some qualitative measures. For the current paper, we\\nfocus on showing that DSPy and its compiler allow us to build outstanding LM systems without\\nhand-crafted prompt strings, but instead from truly modular units, and that this opens up doors for\\nsystematically exploring a rich design space at a very high programmatic level of abstraction.\\n3 T HE DSP Y PROGRAMMING MODEL\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='d2c3d9c4-d133-4146-b2e6-69a3430a20bd', embedding=[0.052298132330179214, 0.01635037735104561, -0.010321076959371567, -0.002567320829257369, -0.013036456890404224, -0.02124299295246601, -0.010279212146997452, -0.023781003430485725, -0.0051213717088103294, 0.039572544395923615, 0.005636115092784166, -0.0044717988930642605, 0.0033949152566492558, -0.02546701207756996, -0.021789738908410072, -0.028375934809446335, -0.02319987304508686, -0.027677295729517937, -0.048184990882873535, -0.020115364342927933, 0.004964538849890232, -0.008426206186413765, -0.06228147819638252, 0.0033629380632191896, -0.026538632810115814, 0.0023618389386683702, 0.02005302906036377, 0.03675505518913269, 0.08141834288835526, 0.03522394225001335, 0.03646954149007797, -0.0068093957379460335, -0.011821521446108818, -0.019789312034845352, -0.016981912776827812, -0.07886484265327454, 0.005400415044277906, -0.003204806474968791, -0.00883017759770155, -0.02047811821103096, 0.024216672405600548, -0.04595247656106949, 0.04232173413038254, -0.057640302926301956, -0.07826972752809525, -0.002271167701110244, 0.011912945657968521, -0.02146586775779724, -0.006610294803977013, -0.044051643460989, -0.007244647480547428, 0.01663222722709179, -2.8780335924238898e-05, -0.0063077537342906, -0.005552398972213268, -0.0034776790998876095, -0.007300174329429865, -0.018408363685011864, -0.03172670304775238, 0.029946016147732735, 0.021193398162722588, 0.0444362498819828, 0.006292439065873623, -0.05261623114347458, -0.03375386819243431, -0.014588113874197006, 0.022825097665190697, -0.0008408550056628883, -0.01426254864782095, 0.0009938672883436084, -0.06471910327672958, 0.018954595550894737, -0.010191275738179684, -0.030007019639015198, -0.00023742888879496604, -0.00026850926224142313, 0.043995052576065063, 0.005783050786703825, -0.026599818840622902, 0.059424400329589844, 0.02056504786014557, 0.04425380751490593, -0.012588068842887878, 0.015778914093971252, -0.031710777431726456, -0.07724806666374207, 0.07725313305854797, -0.01819455809891224, -0.004718445241451263, -0.010882319882512093, -0.012844512239098549, 0.018451863899827003, -0.0035097647923976183, 0.00040558475302532315, 0.05144670978188515, 0.06595328450202942, -0.006299684289842844, 0.045183759182691574, 0.000967817148193717, 0.008812658488750458, 0.03962191939353943, 0.05206914618611336, -0.019169297069311142, 0.01303411740809679, -0.05387534946203232, -0.019643153995275497, 0.019854648038744926, -0.025469481945037842, 0.00028878223383799195, -0.011130211874842644, 0.01543938834220171, -0.0002699134056456387, 0.02410307712852955, -0.005935986991971731, -0.038829222321510315, 0.025174418464303017, 0.008809474296867847, 0.017502088099718094, -0.024151891469955444, 0.01246737688779831, -0.021100927144289017, -0.018587924540042877, 0.002739372430369258, -0.006627347785979509, 0.020772021263837814, -0.0493963286280632, -0.016026325523853302, 0.04909369349479675, -0.04471961036324501, -0.004705616272985935, 0.00535394623875618, 0.016019850969314575, 0.006540979258716106, 0.04937802255153656, -0.007397703360766172, 0.006838231347501278, 0.009438465349376202, 0.025775667279958725, 0.034562066197395325, -0.019252996891736984, 0.024284884333610535, -0.050886671990156174, 0.006645555142313242, 0.12425195425748825, 0.0005165296606719494, 0.0047399913892149925, -0.024908319115638733, -0.007261320017278194, -0.06483602523803711, 0.05904581397771835, -0.01462449599057436, -0.002125356113538146, -0.001937506953254342, 0.02930990606546402, -0.017489008605480194, 0.00959150493144989, 0.005948079749941826, -0.04351961612701416, 0.013613958843052387, 0.0050574904307723045, -0.01690640114247799, -0.010715856216847897, -0.04770290479063988, 0.012650453485548496, -0.018772445619106293, 0.03418157249689102, -0.04891881346702576, -0.02183970995247364, -0.015645336359739304, -0.02286195382475853, -0.012822817079722881, 0.00479924539104104, 0.016732996329665184, 0.02963932976126671, 0.03796563297510147, 0.05546344816684723, 0.030981941148638725, -0.0016924211522564292, 0.037321291863918304, -0.001016946043819189, -0.013437861576676369, -0.022579746320843697, 0.024881962686777115, 0.009352115914225578, -0.0001048749327310361, 0.057159069925546646, 0.004393832292407751, 0.010829311795532703, -0.03445630520582199, 0.01062530092895031, 0.00554140517488122, 0.07512736320495605, -0.02092563733458519, 0.0061637889593839645, 0.004468757193535566, 0.010313821025192738, -0.009250272065401077, 0.027466854080557823, 0.02858596295118332, -0.037768516689538956, -0.011473977006971836, 0.06117265671491623, 0.017042871564626694, -0.02986365556716919, -0.04954598471522331, 0.019238760694861412, -0.021172141656279564, 0.06325766444206238, -0.03134899213910103, 0.027348773553967476, 0.054435838013887405, 0.028971251100301743, -0.02654222957789898, 0.010215049609541893, 0.04016317427158356, -0.016875436529517174, -0.0539756640791893, 0.010232044383883476, 0.018411854282021523, 0.002304338151589036, -0.023489730432629585, -0.02428702637553215, 0.00030600145692005754, -0.018259253352880478, -0.023227496072649956, -0.011658115312457085, 0.02605060115456581, 0.044162847101688385, -0.033469509333372116, 0.035899754613637924, 0.007199218962341547, 0.02547144703567028, -0.025164570659399033, 0.05381491035223007, 0.04072152450680733, 0.025170493870973587, 0.07853644341230392, 0.042152293026447296, -0.006483409088104963, 0.010459642857313156, -0.01833023689687252, 0.0124857472255826, 0.012531545013189316, 0.05226442217826843, 0.012385200709104538, 0.029524922370910645, 0.0023287320509552956, 0.010519030503928661, -0.03808598965406418, -0.013283766806125641, -0.05798421427607536, 0.05049308016896248, 0.01338780764490366, 0.00644142460078001, -0.04941226914525032, -0.004159149248152971, 0.00914769247174263, 0.0677720308303833, -0.016748877242207527, -0.05327674373984337, -0.016760587692260742, 0.0443752147257328, 0.009610946290194988, -0.013853544369339943, 0.006771141663193703, 0.01961706578731537, -0.0069149211049079895, 0.043100159615278244, 0.017634619027376175, 0.0008140701102092862, -0.04038973152637482, -0.07248469442129135, -0.07810642570257187, -0.015661001205444336, -0.01981903240084648, 0.00018789699242915958, -0.014125050976872444, -0.049438413232564926, -0.029911326244473457, -0.059332460165023804, -0.003990228287875652, -0.0031085966620594263, -0.012116233818233013, 0.03953560069203377, 0.018584338948130608, 0.011390168219804764, -0.060169853270053864, 0.02840306982398033, -0.02893083728849888, 0.06724122911691666, 0.005689704790711403, -0.0047645848244428635, -0.004737819079309702, -0.01992643252015114, 0.02240731380879879, -0.00015520477609243244, -0.010163309052586555, -0.0024184291251003742, -0.03748851642012596, -0.011298710480332375, -0.005993937142193317, -0.01971442624926567, 0.03549306094646454, -0.016876552253961563, -0.04578243941068649, 0.05127960816025734, 0.026201704517006874, -0.03593308478593826, 0.04798704385757446, 0.03770684078335762, -0.03394840657711029, 0.04717974737286568, -0.002915544668212533, 0.03152991831302643, -0.044861454516649246, 0.05390283092856407, 0.025092333555221558, -0.022154681384563446, -0.01948116160929203, -0.03216700628399849, -0.025364821776747704, -0.0026064012199640274, -0.015138627029955387, -0.02507486194372177, 0.0012377462117001414, 0.034425608813762665, -0.013241089880466461, -0.06878258287906647, -0.0050471932627260685, -0.032790590077638626, -0.04968200623989105, -0.00031939701875671744, -0.007981347851455212, 0.03713145852088928, 0.01531494315713644, 0.02699931710958481, -0.019826143980026245, 0.012240736745297909, -0.03216063976287842, 0.022420896217226982, 0.025194380432367325, -0.03385370969772339, 0.01249770913273096, 0.03870312497019768, 0.020504722371697426, 0.0014526196755468845, 0.019139764830470085, -0.015872681513428688, -0.02089010737836361, 0.017223762348294258, 0.013188185170292854, 0.04298004135489464, 0.013107111677527428, 0.006668563932180405, -0.00025704747531563044, -0.009386585094034672, -0.03147226944565773, -0.01814313791692257, 0.04582018405199051, 0.003032712498679757, -0.04278894141316414, 0.03494971618056297, 0.01406114362180233, 0.014953763224184513, 0.006641858723014593, -0.015034428797662258, -0.01828509010374546, 0.017868807539343834, 0.058531343936920166, -0.04444177448749542, 0.042863741517066956, 0.016879793256521225, -0.03443996608257294, 0.0006458797724917531, -0.03432324528694153, -0.04483499750494957, 0.03615159913897514, 0.008694787509739399, 0.03298458829522133, 0.0016988590359687805, -0.030195634812116623, 0.019340358674526215, 0.0041175661608576775, 0.0278767179697752, 0.02617458626627922, 0.048568349331617355, 0.01841905526816845, -0.014544405974447727, -0.01595839485526085, 0.009463561698794365, -0.010670367628335953, 0.022599276155233383, -0.01672716811299324, -0.014776762574911118, -0.019135653972625732, -0.02402631752192974, 0.03316095098853111, 0.04536798596382141, 0.010585212148725986, -0.027188552543520927, 0.029929600656032562, -0.044944196939468384, 0.051918402314186096, 0.008842827752232552, 0.030925793573260307, -0.011787986382842064, -0.08976306021213531, 0.018138818442821503, -0.000277140352409333, 0.00879739224910736, 0.005157023668289185, -0.014013874344527721, -0.010957197286188602, 0.016078317537903786, 0.022311890497803688, -0.0019950061105191708, -0.015949688851833344, -0.012129862792789936, 0.009632585570216179, 0.019885241985321045, -0.011299739591777325, -0.0012103775516152382, -0.029184121638536453, 0.019954409450292587, 0.014859520830214024, -0.03669105842709541, 0.00847065169364214, -0.024104679003357887, 0.01686551608145237, 0.01723826862871647, -0.036242228001356125, -0.03404601663351059, -0.013510123826563358, -0.03193441405892372, -0.05446336418390274, 0.04613195359706879, 0.03475891426205635, -0.02744336798787117, 0.006232214625924826, -0.03582056984305382, 0.01483541913330555, -0.0019996375776827335, 0.0209061112254858, -0.013059797696769238, 0.03469613194465637, -0.01659134402871132, 0.005307596176862717, 0.039432868361473083, -0.00016705832968000323, -0.05415961518883705, 0.016357658430933952, -0.041597798466682434, 0.037060316652059555, -0.034957095980644226, 0.003128675278276205, -0.040153734385967255, -0.006591557525098324, -0.017815060913562775, -0.0018975600833073258, 0.007903189398348331, 0.028337713330984116, -0.009688694030046463, 0.008431850001215935, -0.038280386477708817, -0.036873795092105865, 0.045904263854026794, -0.0017820920329540968, -0.012201589532196522, 0.03303615748882294, 0.016132574528455734, -0.027841495350003242, -0.016103459522128105, -0.007334097288548946, -0.005963725969195366, 0.018380675464868546, 0.0015544942580163479, 0.02220401167869568, -0.04173334315419197, -0.026539525017142296, 0.011055978015065193, -0.028466980904340744, 0.02673986181616783, -0.012297271750867367, -0.024012507870793343, -0.005461709573864937, -0.044069766998291016, -0.013124081306159496, 0.0309357400983572, -0.03255635127425194, -0.0143514359369874, 0.005813350901007652, -0.030975379049777985, 0.013320294208824635, -0.04452101141214371, -0.04703144729137421, -0.0413028821349144, -0.015439680777490139, 0.006014758720993996, 0.017304588109254837, 0.058137133717536926, 0.04584398493170738, -0.011088152416050434, -0.060560453683137894, 0.04551341012120247, -0.02233230695128441, -0.037332676351070404, -0.04659537971019745, -0.027866052463650703, -0.009289588779211044, -0.0032229574862867594, -0.03733554854989052, -0.0032135634683072567, -0.016635725274682045, 0.01442248746752739, 0.00908846128731966, 0.008554893545806408, -0.0014832885935902596, -0.015486516989767551, -0.01734042540192604, 0.05758385732769966, 0.009945405647158623, -0.07089728862047195, -0.024547362700104713, 0.027913855388760567, -0.036932673305273056, 0.005881596822291613, 0.05491654947400093, 0.004964685067534447, -0.020411524921655655, -0.03818019479513168, 0.018686752766370773, -0.021314552053809166, 0.0263338852673769, -0.0407857745885849, -0.00968247838318348, 0.020529653877019882, -0.0012018261477351189, 0.062086381018161774, -0.024882802739739418, -0.014433962292969227, -0.05046297237277031, 0.028081275522708893, -0.03179841488599777, -0.007013512775301933, -0.021228130906820297, 0.0003416610707063228, -0.002927950583398342, 0.07955116033554077, 0.003948319237679243, 0.014844049699604511, -0.010935296304523945, -0.009996938519179821, 0.0010872645070776343, 0.04838680848479271, -0.04075915738940239, 0.0021148421801626682, 0.009289609268307686, -0.0024941579904407263, 0.032753873616456985, -0.006367165595293045, -0.011074719950556755, 0.01726132072508335, -0.043264418840408325, -0.014393270015716553, -0.03941008076071739, 0.005729978438466787, -0.03732776269316673, -0.02801842987537384, 0.023487942293286324, -0.0679391548037529, -0.003977964632213116, -0.0379377081990242, 0.03170657902956009, 0.0067344894632697105, -0.0035499741788953543, -0.05836979299783707, -0.009535183198750019, -0.04597979784011841, -0.018715405836701393, 0.0017882577376440167, -0.02994438260793686, 0.003932311665266752, 0.006080962251871824, 0.0017217107815667987, 0.034117668867111206, -0.08234386891126633, 0.015834221616387367, 0.06314340978860855, 0.02780301868915558, 0.01741201803088188, -0.0634910985827446, 0.005199350882321596, -0.010531298816204071, -0.008095189929008484, -0.005188878159970045, -0.02961858920753002, -0.029971972107887268, -0.017384571954607964, -0.035098057240247726, -0.03421689197421074, 0.0005080201081000268, 0.02173423394560814, 0.08419965207576752, -0.03446052595973015, 0.03818275406956673, 0.014814169146120548, -0.05626402422785759, -0.03511935472488403, 0.03286697715520859, -0.018854985013604164, 0.00231353472918272, 0.0031486558727920055, 0.004597592633217573, -0.0015786526491865516, -0.0099584199488163, -0.042015500366687775, -0.03876730799674988, 0.008567110635340214, 0.051153697073459625, 0.005155770108103752, -0.030252477154135704, 0.060674265027046204, 0.047646503895521164, -0.013432607054710388, -0.04109751805663109, 0.015314294956624508, -0.00025999691570177674, -0.044539593160152435, -0.033843353390693665, -0.0020119347609579563, 0.026836233213543892, -0.006126290652900934, -0.03337915614247322, 0.029347974807024002, -0.0323309525847435, -0.004704080987721682, 0.015462521463632584, -0.01705670915544033, -0.0437609925866127, 0.05957823991775513, 0.03155079856514931, -0.016146251931786537, -0.0028911959379911423, -0.04088742658495903, 0.006217242684215307, -0.00655133742839098, -0.009031567722558975, 0.0342438668012619, 0.001504903775639832, -0.011016896925866604, 0.020328888669610023, 0.016737068071961403, 0.05277852341532707, -0.023633481934666634, -0.0006944179767742753, 0.023068079724907875, -0.0498918779194355, -0.023004427552223206, -0.023094501346349716, 0.02162470482289791, -0.00795521680265665, 0.05325448140501976, -0.013148839585483074, 0.01180764939635992, 0.040303703397512436, 0.040970221161842346, 0.004082560073584318, -0.05242431163787842, 0.00137803063262254, -0.04355207458138466, -0.014155146665871143, -0.00586298992857337, -0.051420729607343674, 0.015331986360251904, 0.042068611830472946, 0.0022086468525230885, -0.011532585136592388, -0.013000097125768661, 0.04826205223798752, -0.05687670409679413, 0.002066293964162469, -0.02085440419614315, 0.025992002338171005, -0.02927153743803501, 0.00289954268373549, 0.006397911347448826, -0.0016816988354548812, -0.031366605311632156, -0.007402908988296986, -0.03300857171416283, 0.023625573143363, 0.016818048432469368, 0.0070365057326853275, -0.015415441244840622, -0.02226988412439823, -0.0312957838177681, -0.007343836594372988, 0.010727106593549252, 0.01750335469841957, -0.02431880310177803, 0.02870919555425644, 0.0025281801354140043, -0.04151827096939087, -0.0203113816678524, -0.0055839200504124165, 0.014285956509411335, -0.035883828997612, 0.008201466873288155, 0.04185991734266281, -0.007803113665431738, 0.02689949981868267, -0.010680180042982101, 0.027509503066539764, -0.0313459150493145, -0.029872944578528404, -0.023023199290037155, -0.011956896632909775, -0.03802425041794777, 0.029791956767439842, 0.04907849058508873, 0.08294495940208435, 0.054921023547649384, 0.020971551537513733, 0.02230500802397728, 0.024178866297006607, 0.031786203384399414, 0.03397883474826813, -0.0063128103502094746, 0.009317475371062756, -0.02625143900513649, -0.0693826675415039, 0.02963571436703205, 0.018787674605846405, -0.01786075346171856, 0.028358548879623413, -0.019793659448623657, -0.011724380776286125, -0.0450531430542469, -3.12595657305792e-05, 0.02146635577082634, 0.026161832734942436, 0.04713395982980728, -0.015667682513594627, -0.015479754656553268, 0.004879762884229422, -0.006176671478897333, 0.010672985576093197, -0.050570834428071976, -0.029108718037605286, 0.0027301739901304245, -0.009196006692945957, 0.02364676631987095, 0.006195476278662682, -0.030766289681196213, -0.002467287238687277, 0.029964501038193703, 0.033860016614198685, -0.005682824645191431, 0.04971378669142723, -0.0035539439413696527, -0.0017555844970047474, -0.041158344596624374, -0.02121027186512947, 0.009708289988338947, 0.002982520265504718, -0.046541281044483185, -0.05920245125889778, 0.026278046891093254, 0.06831801682710648, 0.0183205958455801, -0.0174294114112854, -0.06156138703227043, 0.004631498362869024, -0.015470397658646107, 0.011515540070831776, -0.06185072660446167, 0.018667329102754593, 0.010553418658673763, 0.0008145339088514447, 0.0019760450813919306, 0.012873717583715916, -0.0007474845624528825, 0.0284836795181036, 0.007655272725969553, 0.016163570806384087, -0.012798222713172436, 0.04125595837831497, 0.02196451835334301, -0.016973579302430153, 0.04612717032432556, -0.0166003555059433, 0.016051379963755608, 0.011583555489778519, -0.0014815119793638587, 0.017790235579013824, 0.020785659551620483, 0.04517136141657829, 0.024662237614393234, -0.02197260968387127, 0.0548064298927784, 0.04285058379173279, -0.039135273545980453, -0.017402408644557, 0.03384062647819519, 0.0028446344658732414, -0.016994658857584, -0.015145733952522278, -0.06629176437854767, 0.017749469727277756, -0.03245353698730469, 0.014519011601805687, -0.017427219077944756, -0.01623971201479435, -0.0050954148173332214, -0.02325328066945076, -0.03840756416320801, 0.03432709723711014, 0.007723825518041849, -0.05239585414528847, -0.01369504164904356, -0.004054594319313765, 0.01558638270944357, 0.01883552595973015, 0.021786732599139214, -0.006445435807108879, 0.039875078946352005, 0.010327855125069618, 0.06105941906571388, 0.006307429634034634, -0.000594825076404959, 0.028135985136032104, 0.010513251647353172, 0.002040182938799262, -0.03981563448905945, 0.0026494930498301983, -0.002367984503507614, -0.009880833327770233, -0.022543014958500862, 0.06799020618200302, 7.704713789280504e-05, -0.024298904463648796, 0.0032339664176106453, -0.03438219800591469, -0.033399175852537155, -0.03689003735780716, 0.014138982631266117, -0.023264048621058464, 0.006644014734774828, 0.05332256481051445, -0.004456817172467709, -0.03431927040219307, 0.023822156712412834, -0.009336584247648716, 0.019258758053183556, 0.0386226586997509, 0.04275922104716301, 0.00608429592102766, 0.06382433325052261, 0.05248623713850975, 0.03451858088374138, 0.018322505056858063, 0.02568189613521099, 0.02878945879638195, 0.012759825214743614, 0.012551162391901016, -0.027091408148407936, -0.010155354626476765, -0.045250918716192245, -0.06881066411733627, -0.0023362585343420506, 0.0006819675909355283, -0.015183558687567711, 0.035712335258722305, -0.012613476254045963, 0.00666710315272212, -0.039027318358421326, -0.018300795927643776, 0.07425801455974579, -0.0033609813544899225, 0.016488244757056236, 0.008311880752444267, 0.028394373133778572, -0.02556752972304821, 0.034157030284404755, -0.0064594317227602005, 0.01457298919558525, -0.004067004658281803, -0.03175901249051094, 0.018364613875746727, -0.03496606647968292, -0.03155482932925224, -0.040056370198726654, 0.002114748815074563, -0.025108393281698227, 0.03810126334428787, 0.007008169312030077, 0.046612177044153214, 0.0028396209236234426, -0.029579373076558113, -0.031741879880428314, 0.06859752535820007, 0.05895055830478668, -0.004696724470704794, 0.08151044696569443, 0.03726958855986595, -0.0034618123900145292, -0.030601348727941513, 0.016943883150815964, -0.010549476370215416, -0.017692655324935913, 0.00898890383541584, -0.02551366575062275, -0.007180722896009684, -0.013969054445624352, -0.06490163505077362, -0.006658457685261965, 0.031559623777866364, 0.05100351199507713, -0.02421683631837368, -0.0405588299036026, 0.011955657973885536, -0.03804750367999077, -0.00853660237044096, -0.042429160326719284, 0.042898453772068024, 0.010233920067548752, -0.005190612748265266, -0.03172863647341728, -0.035171687602996826, 0.20720386505126953, 0.06148127093911171, 0.04446212574839592, 0.02549903281033039, 0.027025338262319565, 0.049736328423023224, 0.057490985840559006, -0.024407265707850456, 0.04564528167247772, -0.014048059470951557, 0.03434407338500023, -0.009364504367113113, 0.018279625102877617, 0.022442834451794624, -0.04041130468249321, 0.018215620890259743, -0.06074269860982895, -0.02093927189707756, -0.040552493184804916, -0.024252867326140404, -0.014931725338101387, 0.029565641656517982, -0.004280814900994301, 0.008285480551421642, 0.026694701984524727, -0.02149873413145542, -0.0017425334081053734, -0.0403110645711422, 0.05148226395249367, -0.014222616329789162, 0.01122043002396822, -0.034461285918951035, 0.04668404161930084, -0.0313614197075367, -0.02328365668654442, 0.03729353845119476, 0.011704438365995884, -0.055374328047037125, -0.013314533978700638, 0.029356691986322403, -0.015546911396086216, -0.019896524026989937, -0.008456747978925705, -0.015736766159534454, -0.015464228577911854, 0.032484229654073715, 0.018733924254775047, 0.056587185710668564, 0.04056127741932869, -0.0790163055062294, 0.02308052033185959, -0.04153857007622719, 0.025247035548090935, -0.028524452820420265, -0.06253983825445175, -0.025692565366625786, 0.009603395126760006, -0.04419439285993576, -0.04041227698326111, 0.036153193563222885, -0.017900260165333748, 0.011601430363953114, 0.013153601437807083, 0.04553826153278351, -0.030703043565154076, 0.012053035199642181, 0.022416988387703896, -0.02037111669778824, -0.05574708431959152, 0.010586787015199661, 0.023179495707154274, 0.0011886510765179992, -0.008005055598914623, -0.0473158173263073, 0.04101567342877388, 0.001065567135810852, -0.007056516595184803, 0.058939095586538315, 0.0239071287214756, -0.02877865359187126, -0.008218017406761646, -0.019040927290916443, -0.0444117933511734, -0.007323100697249174, 0.010884099639952183, 0.06923273950815201, -0.03021317720413208, 0.01472917478531599, -0.032962121069431305, 0.043918296694755554, -0.011156229302287102, 0.0399317666888237, 0.0025176131166517735, 0.012395261786878109, 0.008004927076399326], metadata={'page_label': '3', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='We present DSPy, which treats LMs as abstract devices for text generation,3 and optimizes their us-\\nage in arbitrary computational graphs. DSPy programs are expressed in Python: each program takes\\nthe task input (e.g., a question to answer or a paper to summarize) and returns the output (e.g., an\\nanswer or a summary) after a series of steps. DSPy contributes three abstractions toward automatic\\noptimization: signatures, modules, and teleprompters. Signatures abstract the input/output behavior\\nof a module; modules replace existing hand-prompting techniques and can be composed in arbitrary\\npipelines; and teleprompters optimize all modules in the pipeline to maximize a metric.\\n3We assume access to one or more LMs, which consume a prompt string and return text completions. This\\nmay be a promptable LM capable of in-context learning (e.g., GPT-3.5 or Llama2-7b) or a smaller finetuneable\\nLM (e.g., T5-base). An LM may be selected as the default; operations will use it unless configured otherwise.\\n3', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='107906ee-61bc-4e10-a250-53d77d1a4f71', embedding=[0.00884478073567152, 0.00583227863535285, 0.01000521332025528, -0.013984117656946182, -0.03567705303430557, -0.016085701063275337, 0.006342932116240263, -0.024221735075116158, -0.017163535580039024, 0.07998340576887131, -0.011069834232330322, -0.0006037290440872312, -0.0274233128875494, -0.00494039012119174, -0.04338842257857323, -0.007011278998106718, -0.011210678145289421, -0.01800803653895855, -0.04839804023504257, 0.001467918511480093, 0.0360073447227478, -0.02561868540942669, -0.07411117851734161, 0.007934005931019783, -0.025734426453709602, 0.04152488335967064, 0.013301299884915352, 0.004791639279574156, 0.0871230736374855, 0.05817650631070137, -0.008088202215731144, 0.05214011296629906, -0.0017801549984142184, -0.04812029376626015, -0.04759887233376503, -0.08178572356700897, 0.0035115627106279135, -0.027782293036580086, -0.0013596848584711552, 0.010547696612775326, 0.026853088289499283, -0.0016712729120627046, 0.02985198423266411, -0.05739728361368179, -0.0620756670832634, -0.01607181690633297, -0.008065522648394108, -0.02830849587917328, -0.02714129164814949, -0.0027825767174363136, 0.021121341735124588, 0.030802683904767036, 0.01345045119524002, -0.01606305129826069, -0.045667994767427444, -0.009233064949512482, -0.0026602332945913076, -0.007647193502634764, 0.0014475798234343529, 0.013246406801044941, -0.006119835656136274, 0.023962100967764854, -0.017894288524985313, -0.038926754146814346, -0.045163679867982864, -0.012009277939796448, 0.00198590406216681, 0.02409018762409687, -0.0016534264432266355, -0.016084223985671997, -0.05998188629746437, 0.0287419855594635, -0.02959395758807659, -0.05068797990679741, -0.018362917006015778, -0.0032370970584452152, 0.02911965735256672, -0.006022481247782707, -0.03501977026462555, 0.042254168540239334, 0.03109038807451725, 0.04988730326294899, 0.014690660871565342, -0.006115185562521219, 0.0075513580814003944, -0.02440432831645012, 0.04502389207482338, -0.038276415318250656, 0.032839518040418625, -0.02672378532588482, 0.024438193067908287, 0.03394561633467674, -0.01833120919764042, 0.0030305252876132727, 0.0521266870200634, 0.06467241793870926, -0.0025080207269638777, 0.05063807964324951, -0.007709830068051815, 0.0071280281990766525, 0.041166190057992935, 0.07535652071237564, -0.011234869249165058, 0.03757869452238083, -0.04898003861308098, 0.017604190856218338, 0.03450008109211922, 0.0031184230465441942, -0.014431945979595184, -0.012080886401236057, 0.018971247598528862, -0.0036155101843178272, -0.039552558213472366, -0.02050582878291607, -0.06733222305774689, 0.03681189939379692, 0.005808868445456028, 0.03935747221112251, -0.04465807229280472, -0.026183899492025375, 0.009156359359622002, -0.0013627687003463507, 0.012214606627821922, 0.011740523390471935, -0.023451590910553932, -0.027471166104078293, -0.01418655551970005, 0.05298289656639099, -0.026416242122650146, 0.04336342215538025, 0.004825107753276825, 0.013523989357054234, -0.02191394940018654, 0.02237309142947197, 0.022641802206635475, 0.017102310433983803, 0.0032205700408667326, -0.019279789179563522, 0.04506315663456917, -0.01967284269630909, 0.0004593705525621772, -0.011766924522817135, -0.016096506267786026, 0.08540705591440201, -0.0010577952489256859, -0.0021311556920409203, -0.016744395717978477, 0.008770757354795933, -0.04012018442153931, 0.01127596665173769, -0.0021626621019095182, -0.0025194354820996523, 0.015135754831135273, -0.0004993921029381454, 0.013013928197324276, 0.001735990634188056, -0.013160338625311852, -0.015152194537222385, -0.008447474800050259, -0.0009452240192331374, -0.04967949539422989, 0.0025319948326796293, -0.010719587095081806, 0.010772147215902805, -0.006374145392328501, 0.04173045605421066, -0.033771827816963196, 0.00028477422893047333, 0.006612295750528574, -0.025984754785895348, 0.022360021248459816, -0.006835394538938999, 0.010973394848406315, 0.006200073752552271, 0.04250966012477875, 0.03587214648723602, 0.0498422347009182, 0.002545197494328022, 0.012875697575509548, 0.011321494355797768, -0.014410572126507759, 0.022306647151708603, 0.013709520921111107, -0.0007227938040159643, 0.01479244139045477, 0.03656543791294098, -0.02043865993618965, -0.0008820140501484275, 0.004551217425614595, -0.016985082998871803, -0.014978374354541302, 0.033874694257974625, -0.0014567984035238624, -0.00257060001604259, -0.004085858818143606, 0.05199946090579033, -0.04323113337159157, 0.036067068576812744, 0.015343867242336273, -0.05538008362054825, -0.04583415761590004, 0.05402428284287453, 0.019034313037991524, -0.004018758423626423, -0.037963587790727615, 0.03219816833734512, 0.00554265733808279, 0.04261612519621849, 0.011219671927392483, 0.04286196455359459, 0.06228981167078018, -0.03076902963221073, -0.0619119368493557, 0.012660391628742218, 0.0022855247370898724, -0.01897302269935608, 0.005833444185554981, 0.004847686272114515, -0.0009151113335974514, 0.023805897682905197, -0.010355624370276928, 0.006282087415456772, -0.0014996776590123773, 0.007991407997906208, -0.020945552736520767, 0.0016989436699077487, 0.0029005317483097315, 0.038717202842235565, -0.011396260932087898, -0.01382212433964014, 0.033883411437273026, 0.010029269382357597, 0.004561848472803831, 0.05363289639353752, -0.006360702216625214, -0.014213916845619678, 0.07210947573184967, 0.055812768638134, -0.005156765226274729, -0.0008526170277036726, -0.02053634636104107, 0.008091348223388195, 0.02762756124138832, 0.031499262899160385, 0.019912952557206154, -0.009585862047970295, 0.02729208394885063, -0.008045434020459652, -0.0003714253252837807, 0.017075615003705025, -0.05838042125105858, 0.07622575759887695, 0.02356879785656929, 0.016825297847390175, -0.013828584924340248, -0.03410716354846954, 0.0020407915581017733, 0.04921774938702583, -0.037499986588954926, -0.033312685787677765, 0.03524508327245712, 0.017794523388147354, 0.0252074021846056, -0.0019367929780855775, -0.015411864034831524, 0.013730733655393124, 0.016068631783127785, 0.012423480860888958, -0.037144921720027924, -0.04288746416568756, -0.0291553046554327, -0.04014657810330391, -0.04563432186841965, 0.005792104173451662, -0.01731102727353573, -0.013020522892475128, -0.018345557153224945, -0.05954274907708168, 0.02455047331750393, -0.040773339569568634, 0.009677606634795666, -0.008441547863185406, -0.014469826593995094, -0.008951613679528236, 0.02919611893594265, 0.021716631948947906, -0.05733456462621689, 0.009660456329584122, -0.006486258935183287, 0.07856441289186478, 0.016882890835404396, -0.01648324728012085, -0.027849307283759117, -0.004799736198037863, 0.011881425976753235, 0.04074432700872421, 0.03522583097219467, -0.020439844578504562, -0.03416803851723671, -0.007281052879989147, 0.0160483680665493, -0.04848760366439819, 0.011163202114403248, -0.01822219416499138, -0.052073825150728226, 0.05325820669531822, -0.01572757586836815, -0.022552181035280228, 0.022003337740898132, 0.05270686373114586, -0.01887662149965763, 0.04264024272561073, 0.007104529533535242, -0.0011751205893233418, -0.043535906821489334, 0.017366444692015648, 0.019999993965029716, -0.027674566954374313, -0.021218594163656235, -0.0645684152841568, -0.013002902269363403, -0.0068972972221672535, 0.0199339147657156, -0.011650176718831062, 0.008629963733255863, 0.04709204286336899, -0.015386732295155525, -0.06316214054822922, -0.0024874943774193525, -0.05155392363667488, -0.015352555550634861, 0.01068536564707756, -0.0029064356349408627, 0.03891043737530708, 0.026208722963929176, 0.01961483433842659, -0.028902841731905937, -0.02021912671625614, -0.04377366974949837, 0.01718718744814396, 0.013937681913375854, -0.027050627395510674, 0.0036406051367521286, 0.01767164282500744, 0.00947925727814436, 0.05301467329263687, -0.0015951510285958648, -0.01917221024632454, -0.05791495367884636, -0.02802048623561859, -0.009325538761913776, 0.023881198838353157, -0.022409804165363312, 0.02830500900745392, -0.011252956464886665, 0.038899198174476624, -0.021009666845202446, -0.04153140261769295, 0.035867612808942795, 0.034221865236759186, -0.01326463557779789, 0.03965042904019356, -0.03103335201740265, -0.009563121944665909, 0.006163241341710091, -0.03156871721148491, -0.05048388987779617, 0.02694546803832054, 0.023569948971271515, -0.027879623696208, 0.033335085958242416, 0.031909216195344925, -0.03372659534215927, 0.0022312942892313004, -0.04083934426307678, -0.05958333611488342, 0.04557575285434723, -0.011137828230857849, 0.052802033722400665, -0.021624762564897537, -0.03474999591708183, 0.0010091840522363782, 0.02660449780523777, 0.03892473131418228, 0.02051205188035965, 0.009747709147632122, -0.030329091474413872, -0.03167833015322685, -0.018939439207315445, 0.022508451715111732, -0.014269822277128696, 0.017759623005986214, 0.00020560769189614803, -0.02061903476715088, -0.018768755719065666, -0.021712709218263626, 0.030449261888861656, 0.02418922260403633, 0.02208727039396763, 0.025156548246741295, 0.007317965850234032, -0.008112865500152111, 0.044390831142663956, 0.026783566921949387, -0.027236683294177055, -0.004824338015168905, -0.03745875135064125, 0.004980773199349642, -0.060627009719610214, 0.04801096022129059, 0.01970520429313183, -0.015333536081016064, -0.009693012572824955, 0.027876947075128555, 0.012165587395429611, 0.016831662505865097, -0.02068919874727726, -0.006994181778281927, 0.025717493146657944, 0.020635291934013367, -0.02236306667327881, 0.0022880970500409603, -0.0233966913074255, 0.016007523983716965, 0.03003842569887638, -0.04133351147174835, -0.0026840155478566885, 0.008262069895863533, -0.020228048786520958, -0.010998551733791828, -0.027347728610038757, -0.005973205901682377, -0.011911861598491669, -0.017962932586669922, -0.019471077248454094, 0.06218600645661354, 0.0397128090262413, -0.036524079740047455, 0.00454276567324996, -0.049935825169086456, 0.0010544031392782927, 0.006091338582336903, -0.01918569579720497, -0.005651695653796196, 0.01635364443063736, -0.03817075118422508, 0.024293119087815285, -0.0028471441473811865, 0.001893784967251122, -0.03279462456703186, 0.044752005487680435, -0.03568607568740845, 0.028706731274724007, -0.062361981719732285, 0.020605603232979774, -0.01915588416159153, -0.01893291436135769, -0.008442130871117115, 0.00987921841442585, -0.013186071068048477, 0.011885344050824642, 0.013973113149404526, 0.016640853136777878, -0.07690270990133286, 0.00042426108848303556, 0.056191470474004745, 0.004354961682111025, 0.02708846889436245, 0.0653156116604805, 0.0037076231092214584, -0.008345023728907108, 0.0327070876955986, -0.001441641361452639, -0.012576273642480373, -0.01441148854792118, -0.0213834997266531, 0.0005211615352891386, -0.007630425505340099, -0.024958161637187004, -0.02350192703306675, -0.03191974014043808, 0.04843904823064804, -0.0032071180175989866, -0.056672997772693634, 0.00984929595142603, -0.05975794792175293, -0.019747843965888023, 0.014367938041687012, -0.02737036533653736, -0.009624497033655643, 0.0032217432744801044, -0.03920058161020279, 0.040969688445329666, -0.026499681174755096, -0.05332252383232117, -0.04283839836716652, -0.03257795423269272, -0.04089076444506645, -0.00748122064396739, 0.05554281920194626, 0.07678310573101044, 0.005812435876578093, -0.02093987725675106, 0.0535549521446228, -0.01896435022354126, -0.036257315427064896, -0.021582193672657013, 0.020764179527759552, -0.010665091685950756, 0.01845560222864151, -0.03205997496843338, 0.007024447433650494, 0.006213344167917967, -0.01663014106452465, 0.03506827726960182, 0.014307632111012936, 0.025220755487680435, -0.015289551578462124, -0.0517285093665123, 0.046155642718076706, 0.028727106750011444, -0.05512086674571037, -0.037091709673404694, -0.0010000300826504827, -0.0022965765092521906, 0.002165728248655796, 0.02799130417406559, 0.04736170172691345, -0.027557967230677605, -0.059710681438446045, 0.06283082067966461, -0.0248638354241848, 0.01665659248828888, -0.0503227524459362, -0.02279014326632023, 0.03313988074660301, 0.0013710599159821868, 0.0330648273229599, -0.018842797726392746, -0.057638805359601974, -0.03907865285873413, 0.03214696794748306, -0.05145394057035446, -0.0123585881665349, -0.020302144810557365, -0.038595933467149734, -0.009878483600914478, 0.08155664801597595, -0.03370725363492966, -0.015011821873486042, -0.0008027991279959679, -0.012940851040184498, 0.0058398316614329815, 0.04731343314051628, -0.03937844932079315, -0.006173956207931042, 0.0030009096954017878, 0.006864042952656746, 0.04572964459657669, -0.012800585478544235, -0.0454728901386261, 0.037639982998371124, -0.013573598116636276, 0.022208092734217644, 0.0003172322176396847, -0.008837145753204823, -0.0045702471397817135, -0.01400195062160492, 0.046241383999586105, -0.054974041879177094, -0.018656913191080093, -0.03040611930191517, 0.022614799439907074, -0.01076216995716095, 0.005704917013645172, -0.02466503158211708, -0.006133581046015024, -0.051656439900398254, -0.03567872568964958, 0.005547504406422377, -0.036812376230955124, 0.009904363192617893, 0.029637956991791725, -0.011460335925221443, 0.0375019833445549, -0.07576025277376175, -0.0032248618081212044, 0.07652134448289871, 0.045897409319877625, 0.004215219058096409, -0.06766299158334732, 0.03607809543609619, -0.029247939586639404, -0.014507799409329891, -0.022720899432897568, 0.021669767796993256, -0.024747921153903008, -0.039187345653772354, -0.010471158660948277, -0.03451912850141525, -0.012464949861168861, 0.028092939406633377, 0.045333124697208405, -0.009342624805867672, 0.029398147016763687, 0.01303960382938385, -0.0565766841173172, -0.035732515156269073, 0.0501968078315258, -0.0184415765106678, -0.016237450763583183, 0.036256469786167145, -0.0025871749967336655, -0.0037040933966636658, 0.010731718502938747, -0.043915413320064545, -0.023924143984913826, 0.0006336538936011493, 0.028343072161078453, 0.01513297576457262, -0.014313671737909317, 0.05932080000638962, 0.035297758877277374, -0.06290233880281448, -0.0682770162820816, -0.0020325861405581236, -0.014137500897049904, 0.0037589101120829582, -0.01723908632993698, 0.008232463151216507, 0.027085108682513237, -0.039545897394418716, -0.029940368607640266, 0.0014414944453164935, 0.013678804971277714, -0.008625970222055912, 0.018934303894639015, -0.013552656397223473, -0.028324132785201073, 0.03260744363069534, 0.047017768025398254, -0.030667588114738464, -0.012276963330805302, -0.009736643172800541, 0.034985389560461044, -0.028786126524209976, -0.002093801274895668, 0.061981912702322006, 0.020919017493724823, 0.008386779576539993, 0.010756674222648144, 0.016354113817214966, 0.049175798892974854, -0.03904768452048302, -0.02012297697365284, 0.022191720083355904, -0.011666852980852127, -0.02739008516073227, -0.001075245440006256, 0.03644957020878792, -0.015613406896591187, 0.014063416048884392, 0.0020566261373460293, 0.017732148990035057, 0.033992987126111984, 0.054555218666791916, 0.014703474007546902, -0.028994988650083542, 0.006244286894798279, -0.03558485582470894, 0.005733507685363293, -0.004557345993816853, -0.04667719826102257, 0.020908603444695473, 0.026947086676955223, -0.011746205389499664, -0.0001358972367597744, -0.01691032201051712, 0.03479652851819992, -0.03425748273730278, 0.0304684117436409, -0.040027596056461334, 0.011605566367506981, -0.0359165333211422, 0.006896190345287323, -0.002033740747720003, 7.099695358192548e-05, -0.027793342247605324, -0.018248453736305237, -0.01486743614077568, -0.01228346023708582, 0.013514427468180656, 0.01153833232820034, -0.03530316799879074, 0.009422238916158676, -0.043862294405698776, 0.007235810160636902, -0.0013028588145971298, -0.006666097324341536, -0.02447471208870411, 0.055895041674375534, 0.004063739906996489, -0.00758031290024519, -0.0054847863502800465, -0.017305167391896248, -0.019382087513804436, -0.03226705640554428, -0.01368334423750639, 0.03233730420470238, -0.02584625408053398, 0.005987707991153002, -0.01120171882212162, 0.004146992228925228, -0.030493561178445816, -0.019989756867289543, -0.00974713172763586, -0.004219724331051111, 0.03101895935833454, 0.0038379812613129616, 0.03883075714111328, 0.046296633780002594, 0.04475832358002663, -0.0007112631574273109, 0.020503804087638855, -0.0015086387284100056, 0.05456553399562836, 0.021972227841615677, 0.016566818580031395, -0.014808161184191704, -0.011373976245522499, -0.041548941284418106, 0.047068070620298386, 0.010952272452414036, 0.00022054270084481686, 0.035896752029657364, -0.013912922702729702, -0.008307503536343575, -0.03802543133497238, -0.014806066639721394, 0.032463762909173965, 0.024320784956216812, 0.046732380986213684, -0.03943188861012459, 0.02434667944908142, -0.002437197370454669, -0.01765497773885727, 0.03093879111111164, -0.020389782264828682, -0.04845656827092171, 0.011352436617016792, -0.043466612696647644, -0.010163623839616776, -0.027808915823698044, 0.013990148901939392, 0.023196538910269737, 0.020278288051486015, 0.008637791499495506, 0.015193132683634758, 0.019112704321742058, 0.008561684750020504, -0.022833202034235, -0.04279446601867676, -0.05470544472336769, -0.003682998474687338, 0.011696657165884972, -0.037605710327625275, -0.07038195431232452, 0.04226049408316612, 0.07365996390581131, -0.013453872874379158, -0.002089880174025893, -0.05266029015183449, -0.004617000464349985, -0.04434366896748543, 0.02057076431810856, -0.03848852589726448, 0.015368692576885223, -0.0443832129240036, -0.0045088897459208965, -0.032064564526081085, 0.003926815930753946, 0.015066679567098618, 0.021499870344996452, 0.01280946470797062, -0.0109845120459795, -0.02458861656486988, 0.015869678929448128, 0.015872156247496605, -0.028528401628136635, 0.02474929951131344, 0.0017809458076953888, 0.009971212595701218, 0.0030612109694629908, -0.020924663171172142, 0.05734231323003769, 0.0010082506341859698, 0.08395560085773468, 0.031464435160160065, -0.018367554992437363, 0.04099796339869499, 0.003819551318883896, -0.008382530882954597, 0.0022994624450802803, 0.025172539055347443, 0.0271739661693573, -0.0004948204150423408, 0.005679800175130367, -0.031539540737867355, -0.0017707593506202102, -0.01506426278501749, 0.018201006576418877, 0.025992458686232567, -0.010322852060198784, -0.0033538765273988247, -0.025653205811977386, -0.0009485542541369796, 0.037698011845350266, 0.02446926012635231, -0.05046674981713295, -0.03843583166599274, 0.009970123879611492, 0.04269453138113022, -0.01675288937985897, -0.008294750936329365, 0.008505902253091335, 0.06054244562983513, 0.01776229217648506, 0.014110835269093513, -0.0034652764443308115, -0.00566675653681159, -0.0016131106531247497, -0.015317533165216446, 0.010555698536336422, -0.027277788147330284, 0.0031823113095015287, 0.02541881613433361, -0.0004277011612430215, -0.020617859438061714, 0.030351435765624046, -0.011172899045050144, -0.01091720536351204, -0.005874134600162506, -0.026453737169504166, 0.01102942693978548, -0.01821068674325943, 0.03324945271015167, -0.0027250361163169146, 0.018853357061743736, 0.042102351784706116, -0.04609503224492073, -0.007904300466179848, 0.033765241503715515, 0.024333184584975243, -0.0064818402752280235, 0.0022152233868837357, 0.041817840188741684, 0.024314261972904205, 0.062313929200172424, 0.01056374330073595, -0.01192671712487936, 0.0003408991324249655, 0.011942772194743156, 0.023696502670645714, -0.006059631705284119, 0.0455719456076622, -0.017161307856440544, -0.009265046566724777, -0.023971766233444214, -0.04736711084842682, 0.023813830688595772, -0.002399178920313716, -0.00011069230822613463, 0.00836116448044777, -0.0026128808967769146, -0.022798720747232437, -0.046692002564668655, 0.025361303240060806, 0.045532017946243286, 0.022776367142796516, 0.038453277200460434, 0.016340920701622963, 0.020484549924731255, -0.08553098142147064, 0.0019799186848104, -0.02735160104930401, 0.017994452267885208, -0.0024389633908867836, -0.014829329214990139, 0.014708515256643295, -0.03727604076266289, -0.02229240909218788, -0.02600475773215294, -0.011952032335102558, 0.0009071913664229214, 0.01437058299779892, 0.00010343365283915773, 0.03538733348250389, 0.009608631022274494, -0.01907414384186268, -0.004359018988907337, 0.014307133853435516, 0.05181458219885826, -0.008355282247066498, 0.06408034265041351, 0.05058771371841431, -0.02924659475684166, -0.025400176644325256, 0.018114492297172546, -0.01375009585171938, -0.00025632919277995825, 0.022806119173765182, -0.048544373363256454, -0.016751063987612724, -0.014451109804213047, -0.05633687227964401, 0.016828035935759544, 0.08328721672296524, 0.02552063576877117, 0.008846115320920944, -0.02516590803861618, -0.01212665718048811, -0.0248718224465847, 0.007230396848171949, -0.05361049994826317, 0.02335387095808983, -0.012272750027477741, 0.009292465634644032, 0.04288087412714958, -0.026463082060217857, 0.27630603313446045, 0.07567160576581955, 0.018419519066810608, 0.023979585617780685, 0.017888493835926056, 0.0805756226181984, 0.004579870030283928, -0.022676384076476097, 0.02456800639629364, -0.054437875747680664, 0.0121424850076437, -0.012792385183274746, -0.004878973122686148, 0.04011401906609535, -0.03539130091667175, 0.019058339297771454, -0.046561092138290405, -0.03878222033381462, -0.043499741703271866, -0.03400816768407822, -0.046167194843292236, 0.0011734783183783293, 0.008669370785355568, 0.027760831639170647, 0.013429548591375351, 0.011897976510226727, 0.016695907339453697, -0.006703601684421301, 0.0212139580398798, -0.0525493249297142, -0.006812738254666328, -0.01589888706803322, 0.022233152762055397, -0.02357710711658001, -0.03197091445326805, -0.0015158592723309994, -0.0032094770576804876, -0.046527963131666183, -0.01130236592143774, 0.048155203461647034, 0.01717434450984001, 0.008826259523630142, 0.007095235865563154, -0.02191433124244213, -0.012018823996186256, 0.07124488800764084, -0.012167778797447681, 0.06321627646684647, 0.05515775457024574, -0.05796719714999199, 0.024668065831065178, -0.005784716457128525, 0.030423618853092194, -0.06709449738264084, -0.03782591596245766, 0.009215365163981915, 0.0038883190136402845, -0.05391767993569374, -0.03203606978058815, 0.028000427410006523, -0.050224028527736664, 0.02324938029050827, -0.009391147643327713, 0.039316575974226, -0.01328065525740385, 0.040243856608867645, 0.020717281848192215, 0.017894424498081207, -0.05748343840241432, -0.01095711998641491, -0.005401873495429754, -0.010600176639854908, -0.027041614055633545, -0.06585738062858582, 0.03831751272082329, -0.027437061071395874, -0.0065922122448682785, 0.010370692238211632, 0.028471508994698524, -0.034477170556783676, -0.012302388437092304, 0.0008021946414373815, -0.052753422409296036, -0.019213085994124413, 0.03759627789258957, 0.02138732187449932, -0.012289470992982388, -0.0029254076071083546, -0.028308816254138947, -0.0032073939219117165, -0.012049460783600807, 0.015502514317631721, -0.0266216229647398, -0.014742783270776272, -0.0012363450368866324], metadata={'page_label': '4', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\n3.1 N ATURAL LANGUAGE SIGNATURES CAN ABSTRACT PROMPTING & FINETUNING\\nInstead of free-form string prompts, DSPy programs use natural language signatures to assign work\\nto the LM. A DSPy signature isnatural-language typed declaration of a function: a short declarative\\nspec that tells DSPy what a text transformation needs to do (e.g., “consume questions and return\\nanswers”), rather than how a specific LM should be prompted to implement that behavior. More\\nformally, a DSPy signature is a tuple of input fields and output fields (and an optional instruction).\\nA field consists offield name and optional metadata.4 In typical usage, the roles of fields are inferred\\nby DSPy as a function of field names. For instance, the DSPy compiler will use in-context learning\\nto interpret questiondifferently from answer and will iteratively refine its usage of these fields.\\nSignatures offer two benefits over prompts: they can be compiled into self-improving and pipeline-\\nadaptive prompts or finetunes. This is primarily done by bootstrapping (Sec 4) useful demonstrating\\nexamples for each signature. Additionally, they handle structured formatting and parsing logic to\\nreduce (or, ideally, avoid) brittle string manipulation in user programs.\\nIn practice, DSPy signatures can be expressed with a shorthand notation likequestion -> answer,\\nso that line 1 in the following is a complete DSPy program for a basic question-answering system\\n(with line 2 illustrating usage and line 3 the response when GPT-3.5 is the LM):\\n1 qa = dspy.Predict(\"question -> answer\")\\n2 qa(question=\"Where is Guaran ´ı spoken?\")\\n3 # Out: Prediction(answer=’Guaran ´ı is spoken mainly in South America.’)\\nIn the shorthand notation, each field’s name indicates the semantic role that the input (or output)\\nfield plays in the transformation. DSPy will parse this notation and expand the field names into\\nmeaningful instructions for the LM, so that english document -> french translation would\\nprompt for English to French translation. When needed, DSPy offers more advanced programming\\ninterfaces for expressing more explicit constraints on signatures (Appendix A).\\n', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}'),\n",
       " Document(id_='2644f263-2548-479d-95dd-5451d542d5fa', embedding=[0.013846957124769688, 0.005032810848206282, -0.004789519589394331, -0.03214447572827339, -0.018146293237805367, 0.010334025137126446, -0.008398439735174179, -0.004041013307869434, -0.025616466999053955, 0.10865756869316101, 0.0015555184800177813, -0.018050964921712875, -0.015078449621796608, 0.009507114998996258, -0.020296236500144005, 0.02582663856446743, -0.007374743930995464, -0.03991559147834778, -0.06765419244766235, 0.005710609722882509, 0.020995602011680603, -0.025450682267546654, -0.06289836764335632, -0.024440022185444832, -0.04271019995212555, 0.02438158541917801, -0.0005448485026136041, 0.011542989872395992, 0.07141005992889404, 0.06757045537233353, 0.005311025306582451, 0.032459259033203125, -0.01762348972260952, -0.03912196680903435, -0.037893909960985184, -0.0692618191242218, 0.0024159972090274096, -0.02831260673701763, -0.00820955727249384, 0.013613205403089523, 0.0036228967364877462, 0.02531360648572445, 0.020120589062571526, -0.05170518532395363, -0.05711733177304268, -0.00847573485225439, 0.008187846280634403, -0.02370118722319603, -0.012904230505228043, -0.009529630653560162, 0.004452441819012165, 0.04553357511758804, -0.016209017485380173, -0.025804869830608368, -0.041077617555856705, -0.0039213476702570915, -0.006448002532124519, -0.01179369818419218, -9.984138887375593e-05, -0.0034410811495035887, -0.02145981229841709, 0.0005294604925438762, -0.03370104730129242, -0.03358502313494682, -0.02767646126449108, 0.01627981849014759, 0.001895842724479735, 0.026480425149202347, -0.0165251437574625, -0.02130039781332016, -0.03153868019580841, 0.011819136328995228, -0.029890088364481926, -0.04893425479531288, -0.01634739339351654, 0.020636068657040596, 0.04152921587228775, 0.022564897313714027, -0.022139715030789375, 0.0410250686109066, 0.03677420690655708, 0.03959609568119049, -0.03184179216623306, 0.006731416564434767, 0.012787163257598877, -0.010594917461276054, 0.04021136835217476, -0.06311239302158356, -0.003408294403925538, -0.03310246765613556, -0.02066020667552948, 0.041988324373960495, 0.009419148787856102, 0.01629096269607544, 0.04326457530260086, 0.014666539616882801, 0.00028794107493013144, 0.0652814581990242, 0.013308145105838776, -0.01976209320127964, 0.03836672008037567, 0.09746789932250977, -0.008676812052726746, 0.0042509897612035275, -0.028380170464515686, 0.03410937264561653, 0.03079652413725853, 0.015180652029812336, -0.03919046372175217, -0.023891864344477654, -0.004379275720566511, -0.0104270214214921, -0.04580925405025482, -0.004931792616844177, -0.05557475611567497, 0.04081539437174797, -0.01949544996023178, 0.03007669188082218, -0.036869555711746216, -0.00747679453343153, 0.022147785872220993, 0.0019936379976570606, 0.0034290472976863384, -0.01587030105292797, 0.0009148306562565267, -0.0026152832433581352, 0.00036047157482244074, 0.06708435714244843, -0.024575673043727875, 0.008247329853475094, -0.022410539910197258, 0.0127907395362854, -0.010434187948703766, 0.046117398887872696, -0.012470156885683537, 0.008134138770401478, -0.026494285091757774, -0.01769147627055645, 0.02129979617893696, -0.0038444073870778084, 0.0037895790301263332, -0.005305731203407049, -0.0010762105230242014, 0.07762626558542252, -0.014085434377193451, 0.009002318605780602, -0.033107027411460876, -0.001292931498028338, -0.06275294721126556, 0.008089110255241394, -0.009563807398080826, -0.03813766688108444, -4.795183485839516e-05, 0.008363377302885056, -4.456972237676382e-05, -0.005135614890605211, -0.019456975162029266, -0.014143768697977066, 0.005513004492968321, 0.016041714698076248, -0.03213917836546898, -0.013899946585297585, -0.01924761012196541, -0.001592369400896132, -0.021428443491458893, 0.0570085272192955, -0.053057312965393066, -0.023243263363838196, -0.0008981117862276733, -0.04031910002231598, 0.023127013817429543, -0.009700900875031948, -0.004044071771204472, 0.01727844960987568, 0.06306806951761246, 0.034775510430336, 0.06082562357187271, 0.0012041885638609529, 0.01621716469526291, -0.0022114324383437634, -0.026597848162055016, 0.008472888730466366, 0.013269225135445595, 0.008077407255768776, 0.032198842614889145, 0.057832881808280945, -0.008457541465759277, -0.002426121151074767, 0.008995584212243557, 0.012305933982133865, 0.0037552521098405123, 0.029332684352993965, -0.019292624667286873, 0.022497812286019325, -0.022913554683327675, 0.0005759805790148675, -0.029575353488326073, 0.02855413407087326, 0.010682377964258194, -0.0499180443584919, -0.034900013357400894, 0.07198779284954071, -0.0012158937752246857, -0.018649736419320107, -0.011595719493925571, 0.01835779845714569, 0.01036535669118166, 0.04539776220917702, -0.03143107891082764, 0.016336090862751007, 0.0413152351975441, -0.009832248091697693, -0.0630926713347435, 0.017259130254387856, -0.0004342371830716729, -0.020445842295885086, -0.0008397322962991893, -0.024303611367940903, 0.008572317659854889, 0.02721775323152542, -0.012996483594179153, -0.021258052438497543, -0.003535579890012741, 0.006367906928062439, -0.031380150467157364, -0.005034788977354765, -0.016072621569037437, 0.038669031113386154, 0.0038947134744375944, 0.00684203440323472, 0.015277695842087269, 0.024647220969200134, -0.014391710981726646, 0.07364609837532043, -0.006178179755806923, -0.010133160278201103, 0.06383658945560455, 0.025088733062148094, -0.022824231535196304, 0.019354894757270813, -0.010454250499606133, 0.0015317780198529363, 0.010720602236688137, 0.021553052589297295, 0.01233623642474413, -0.0004934833850711584, -0.00962600763887167, -0.014826975762844086, -0.023797141388058662, 0.041386861354112625, -0.05013255774974823, 0.06617849320173264, 0.021154489368200302, 0.008467620238661766, -0.005776823498308659, -0.023738685995340347, -0.006638571619987488, 0.019981227815151215, -0.025309013202786446, 0.009203770197927952, 0.04300489276647568, 0.014430347830057144, -0.004874853417277336, -0.007402216549962759, 0.007184895221143961, 0.04641912132501602, 0.054323650896549225, 0.0108809694647789, -0.013113190419971943, -0.02163727581501007, -0.001554140355437994, -0.038419440388679504, -0.059261031448841095, 0.0075258128345012665, -0.01830848678946495, -0.03213798627257347, -0.014172560535371304, -0.033364444971084595, 0.0006425907486118376, -0.04738130420446396, 0.0505024716258049, 0.018382197245955467, -0.0008192489040084183, 0.026589544489979744, 0.04531331732869148, 0.0043710339814424515, -0.09293260425329208, 0.03586699068546295, -0.04941146448254585, 0.04819757863879204, -0.006254397798329592, -0.004194275941699743, 0.0043526822701096535, 0.026088997721672058, 0.04799728840589523, 0.022073309868574142, 0.02706007845699787, -0.052254121750593185, -0.009610280394554138, 0.021882982924580574, -0.004738103598356247, 0.0077411397360265255, 0.029882168397307396, -0.02863997593522072, -0.02011859230697155, 0.04250868409872055, -0.011639142408967018, -0.029797492548823357, 0.033137720078229904, 0.029991518706083298, -0.030992424115538597, 0.04096192866563797, -0.018561573699116707, -0.02855406515300274, -0.027624428272247314, 0.007999204099178314, 0.014061813242733479, -0.0348631888628006, -0.016790064051747322, -0.07630819082260132, -0.012613040395081043, 0.02852415293455124, 0.011800162494182587, -0.009939032606780529, -0.014906838536262512, 0.06751268357038498, -0.045053835958242416, -0.031157778576016426, 0.0358198918402195, -0.03163062408566475, -0.015105453319847584, 0.011699388734996319, 0.0031597386114299297, 0.05268504098057747, 0.018529191613197327, 0.0596560500562191, -0.03519187867641449, -0.01963796094059944, -0.06364583969116211, -0.00432025408372283, -0.0007574682822450995, -0.02517002634704113, 0.02738662250339985, -0.007243338972330093, -0.004757004324346781, 0.03274303302168846, -0.008327771909534931, -0.02147696353495121, -0.062331102788448334, -0.034819550812244415, -0.009683508425951004, 0.00028307733009569347, -0.021787511184811592, -0.002308183116838336, 0.007652089465409517, 0.06283934414386749, -0.02047318033874035, -0.04419288411736488, 0.02909046970307827, 0.024457022547721863, 0.010095369070768356, 0.044964663684368134, -0.035386823117733, -0.004628053400665522, 0.0011559244012460113, -0.029275400564074516, -0.04688258469104767, 0.04466904699802399, -8.748310938244686e-05, -0.039561931043863297, 0.03662531450390816, -0.0065613072365522385, -0.04325868934392929, -0.01995820179581642, -0.019768625497817993, -0.04421558976173401, 0.01325692143291235, 0.03032388910651207, 0.05065371096134186, -0.026454351842403412, -0.045133545994758606, 0.005116135347634554, 0.0048213680274784565, 0.019935449585318565, 0.0256058182567358, -0.00015023746527731419, -0.02035437896847725, -0.0155261205509305, -0.009279417805373669, 0.007840834558010101, -0.0016364494804292917, 0.025083355605602264, -0.003910768311470747, -0.0340275876224041, -0.03508155047893524, -0.033270809799432755, 0.006552666425704956, 0.03876081109046936, 0.004358503036201, 0.02704322338104248, 0.011162634007632732, -0.026012588292360306, 0.008917774073779583, 1.49781317304587e-05, -0.019096454605460167, -0.016564343124628067, -0.051554273813962936, 0.01257635559886694, -0.036941856145858765, 0.02197079546749592, -0.0189167782664299, -0.002342438558116555, 0.01805691048502922, 0.031675875186920166, -0.01238163746893406, -0.00717830890789628, -0.023707697167992592, 0.004945075139403343, -0.021769970655441284, 0.02167634665966034, -0.006635401397943497, -0.034403473138809204, -0.006045099347829819, -0.009713624604046345, 0.03153451159596443, -0.04684370383620262, -0.00524040125310421, -0.017946185544133186, -0.025659611448645592, 0.017558839172124863, -0.027366289868950844, -0.017681505531072617, -0.0033781540114432573, -0.0007465300732292235, -0.02556602470576763, 0.0561450757086277, 0.028308667242527008, -0.04447187855839729, 0.013368106447160244, -0.048084504902362823, -0.007952101528644562, 0.0039827036671340466, -0.012800323776900768, -0.007967076264321804, 0.016836658120155334, -0.0022625885903835297, 0.041827958077192307, 0.014290033839643002, -0.02149789035320282, -0.04178953170776367, 0.06419285386800766, -0.05761604383587837, 0.05241483449935913, -0.05199093371629715, 0.03582353889942169, -0.018766768276691437, -0.015432392247021198, 0.003909386228770018, 0.022625243291258812, -0.01286003366112709, 0.01969970017671585, 0.02122228778898716, 0.013223441317677498, -0.05556446686387062, 0.004337317775934935, 0.05707355961203575, -0.007441468071192503, 0.01819128915667534, 0.06152590736746788, 0.00598551332950592, 0.0007729171775281429, 0.024447157979011536, 0.0010947572300210595, -0.03661349043250084, -0.009618082083761692, 0.01142764650285244, 0.007940510287880898, 0.010347793810069561, -0.009280656464397907, -0.003645641030743718, -0.06329859793186188, 0.0350477434694767, -0.015049319714307785, -0.053362973034381866, 0.019073687493801117, -0.06050637364387512, -0.02008923888206482, -0.005331037100404501, -0.018315384164452553, 0.00826253741979599, 0.010862760245800018, -0.022083332762122154, 0.014988324604928493, -0.033497605472803116, -0.044935259968042374, -0.04075279086828232, -0.021198756992816925, -0.010948621667921543, 0.005328864324837923, 0.07220438867807388, 0.0459962822496891, -0.011712580919265747, -0.023662826046347618, 0.0780867487192154, -0.006153748836368322, -0.028411509469151497, -0.029896914958953857, 0.024865826591849327, -0.03537103906273842, -0.0021411480847746134, -0.06201862171292305, 0.013401211239397526, 0.02939736843109131, -0.013735175132751465, 0.025305775925517082, 0.0056034293957054615, 0.020241079851984978, -0.009349675849080086, -0.044740717858076096, 0.041716400533914566, 0.029076503589749336, -0.06861215829849243, -0.029652420431375504, 0.005999732296913862, -0.013074319809675217, 0.01679336279630661, 0.03831613436341286, 0.022110532969236374, 0.009406914003193378, -0.04333078861236572, 0.04530267044901848, -0.02415921539068222, 0.023604199290275574, -0.03708510100841522, -0.004880998283624649, 0.02481869049370289, 0.009347295388579369, 0.036931272596120834, -0.04450847581028938, -0.05135254189372063, -0.01997867040336132, 0.03861963376402855, -0.07716955989599228, -0.014565529301762581, -0.03948861360549927, -0.03334655612707138, -0.029593853279948235, 0.044336091727018356, -0.031118163838982582, -0.026135409250855446, -0.019698521122336388, -0.005674996878951788, -0.0001708763011265546, 0.023529939353466034, -0.032769061625003815, -0.022277986630797386, -0.004614881705492735, 0.03963744640350342, 0.03178161382675171, 0.0039406996220350266, -0.0010103073436766863, 0.05305181443691254, -0.02644147165119648, 0.03674347698688507, -0.020377513021230698, -0.023639336228370667, -0.007947674952447414, 0.008594430983066559, 0.024029217660427094, -0.06379471719264984, -0.00886362325400114, -0.03311651945114136, 0.020948907360434532, -0.019394535571336746, 0.012828057631850243, -0.02836938202381134, 0.004343705251812935, -0.06108774244785309, -0.04274829104542732, 0.018547361716628075, -0.028135251253843307, 0.01604316011071205, -0.003140512155368924, 0.023402689024806023, 0.030101561918854713, -0.05004340037703514, -0.01456435862928629, 0.06356354802846909, 0.03156119957566261, -0.010560075752437115, -0.03732757270336151, 0.03954564407467842, -0.006328420713543892, 0.009176073595881462, 0.017818456515669823, 0.020641634240746498, -0.027251552790403366, -0.018622979521751404, 0.008639526553452015, -0.027353275567293167, -0.01683215983211994, 0.027279121801257133, 0.05141041800379753, -0.011561457067728043, 0.024340013042092323, -0.0017385277897119522, -0.0661437064409256, -0.032105952501297, 0.01601449027657509, 0.008775096386671066, 0.00837316457182169, 0.03556378558278084, 0.02102889120578766, -4.754660039907321e-05, -0.005098224151879549, -0.04535622522234917, -0.03222876787185669, -0.005846018902957439, 0.027525046840310097, -0.008417690172791481, 0.003056110581383109, 0.04090939834713936, 0.04603837803006172, -0.031172221526503563, -0.04895595461130142, 0.0031642031390219927, 0.007504599168896675, -0.002069881884381175, -0.020590495318174362, -0.02259514480829239, 0.034834206104278564, -0.03013308160007, -0.009679012931883335, 0.03850695118308067, 0.015948349609971046, -0.013070255517959595, -0.012707711197435856, 0.0022754818201065063, -0.05837821215391159, 0.031056182458996773, 0.04116770997643471, -0.02488812990486622, -0.01591741107404232, -0.027138322591781616, 0.03174688667058945, -0.033723071217536926, -0.025317968800663948, 0.07170671969652176, 0.022731654345989227, -0.00947720929980278, 0.016365796327590942, 0.008888404816389084, 0.070943683385849, -0.05851009488105774, -0.0009165164083242416, 0.02282031625509262, -0.020448189228773117, -0.03296618536114693, -0.005323177669197321, 0.028420012444257736, 0.0061891945078969, 0.022566629573702812, 0.021949348971247673, 0.022845791652798653, 0.0415567047894001, 0.050317633897066116, -0.005593212321400642, -0.04775456711649895, -0.0030551571398973465, -0.035100843757390976, 0.0008138263365253806, 0.00537357572466135, -0.00691399397328496, 0.03239218518137932, 0.019964370876550674, -0.012249051593244076, -0.013220821507275105, -0.03421434760093689, 0.011687583290040493, -0.037250857800245285, -0.018654905259609222, -0.03590133413672447, 0.025023339316248894, -0.04934278130531311, 0.011444484815001488, -0.029940469190478325, -0.012718395330011845, -0.006848596967756748, -0.02143016830086708, -0.010167554020881653, 0.001697316998615861, 0.008111719973385334, 0.015487737953662872, -0.029253652319312096, 0.004853100515902042, -0.0406126044690609, -0.016800465062260628, -0.008657267317175865, 0.015065804123878479, -0.016479482874274254, 0.05627741292119026, 0.01218336634337902, -0.018501030281186104, 0.016965433955192566, -0.020011359825730324, -0.006179950665682554, -0.018448717892169952, -0.005333945155143738, 0.026456311345100403, -0.015572323463857174, -0.018390990793704987, -0.002087016124278307, 0.026448415592312813, -0.03510737046599388, -0.017922477796673775, 0.0036850296892225742, -0.006178352981805801, 0.04956861585378647, 0.006372708827257156, 0.04230637475848198, 0.04491008073091507, 0.04412341117858887, 0.004135717172175646, 0.027112320065498352, 0.008516884408891201, 0.055737968534231186, 0.05014804005622864, 0.015366112813353539, -0.006215832196176052, -0.0090807368978858, -0.040316980332136154, 0.04843180626630783, 0.0017416931223124266, -0.012029385194182396, 0.043508872389793396, 0.003527454100549221, -0.0140765979886055, -0.04652586951851845, -0.00512723159044981, 0.032457057386636734, 0.00846134964376688, 0.025914039462804794, -0.03632289171218872, 0.006201503332704306, -0.02396203763782978, -0.009362388402223587, 0.011712143197655678, -0.046898018568754196, -0.024037295952439308, 0.027914637699723244, -0.03816389665007591, -0.026786260306835175, -0.02680155076086521, -0.0012747786240652204, 0.02143915928900242, 0.010080574080348015, 0.018363939598202705, 0.004571976605802774, 0.019665930420160294, -0.017776010558009148, -0.009901105426251888, -0.03776553273200989, -0.04368016496300697, 0.0066645643673837185, 0.022867774590849876, -0.04199635609984398, -0.07343165576457977, 0.04106749966740608, 0.0752200037240982, -0.014583212323486805, -0.009104283526539803, -0.03987883776426315, -0.021932771429419518, -0.02013668231666088, 0.026614924892783165, -0.06038844585418701, -0.0007640352705493569, -0.061102673411369324, 0.01880434714257717, -0.030507946386933327, 0.00452239066362381, 0.004354876931756735, 0.032453812658786774, 0.0017172672087326646, -0.00506045576184988, 0.005932449363172054, 0.02201043628156185, -0.0005530713242478669, -0.04136635363101959, 0.05733136832714081, 0.016951248049736023, 0.03276069834828377, -0.02285699173808098, -0.006589430384337902, 0.04472515359520912, 0.0005596188711933792, 0.060048140585422516, 0.02055525779724121, -0.022193701937794685, 0.05792820081114769, 0.034337837249040604, -0.02918659895658493, -0.017798786982893944, 0.028457757085561752, 0.014047076925635338, -0.006455185357481241, 0.003606154816225171, -0.012872503139078617, 0.022733613848686218, -0.003983248490840197, 0.01761830784380436, 0.03885584697127342, 0.009481821209192276, 0.03939995914697647, -0.03840324282646179, -0.007271602749824524, 0.013864153064787388, 0.030253464356064796, -0.028554629534482956, -0.02955254539847374, 0.008524060249328613, 0.07127507776021957, -0.01698732189834118, 0.004554604180157185, -0.013480824418365955, 0.06607445329427719, 0.02325425110757351, 0.014825517311692238, -0.012217352166771889, -0.02730678953230381, 0.011247295886278152, 0.006672234740108252, 0.02497250959277153, -0.030482690781354904, 0.029950110241770744, 0.033791735768318176, -0.023528555408120155, 0.0003608076076488942, 0.04085502773523331, 0.001508942455984652, -0.01606431044638157, -0.019007334485650063, -0.022455468773841858, 0.015454432927072048, -0.038780577480793, 0.034136973321437836, -0.0031423449981957674, 0.0025695764925330877, 0.020134305581450462, -0.0333695225417614, -0.007789802271872759, 0.03230592980980873, 0.028108861297369003, -0.011661672964692116, 0.0008254577405750751, 0.04996446520090103, 0.019459960982203484, 0.09165647625923157, 0.012750559486448765, 0.010999144986271858, 0.027587123215198517, 0.02076878398656845, -0.009003616869449615, -0.0068331388756632805, 0.04260101914405823, -0.006905837450176477, 0.011224824003875256, -0.05939159169793129, -0.031078720465302467, 0.03733036667108536, -0.013043257407844067, -0.01495817955583334, 0.015310455113649368, -0.012007040902972221, -0.027670085430145264, -0.025538189336657524, -0.0068631526082754135, 0.03580048680305481, 0.033637672662734985, 0.036792442202568054, -0.0001538265059934929, 0.006207823753356934, -0.06646142154932022, -0.0002551962388679385, -0.02396116778254509, 0.02288185991346836, -0.009506496600806713, -0.013459410518407822, 0.0015273181488737464, -0.02042234316468239, -0.009868948720395565, -0.008144577965140343, -0.016196193173527718, 0.0010440765181556344, 0.013129211962223053, -0.0011131125502288342, 0.019277717918157578, 0.007946571335196495, -0.01959378272294998, -0.010914141312241554, 0.0315035879611969, 0.03253551572561264, 0.016811883077025414, 0.07397331297397614, 0.07316268980503082, -0.029340315610170364, -0.02513750270009041, 0.02791423723101616, -0.011304543353617191, -0.006046752445399761, 0.029937727376818657, -0.019314561039209366, -0.0003454374091234058, -0.006976489443331957, -0.0428430438041687, 0.012651869095861912, 0.052562590688467026, 0.002230006270110607, 0.003849961794912815, -0.007981258444488049, -0.031393278390169144, -0.057287462055683136, 0.016292639076709747, -0.043034784495830536, 0.00035581373958848417, -0.014033765532076359, -0.008602007292211056, 0.004126250743865967, -0.021617762744426727, 0.28116583824157715, 0.07393355667591095, 0.02588716894388199, 0.014968141913414001, 0.04607629030942917, 0.06047365069389343, 0.003932247404009104, -0.03839564695954323, 0.02171928994357586, -0.059413038194179535, 0.010013152845203876, -0.031612593680620193, 0.0008119503618218005, 0.009404978714883327, -0.02729739062488079, 0.019714228808879852, -0.042895492166280746, -0.012216872535645962, -0.024273894727230072, -0.01251550205051899, -0.06922976672649384, 0.022447511553764343, 0.014818011783063412, 0.03137867897748947, -0.0018179771723225713, 0.023910384625196457, 0.006968597415834665, -0.044248443096876144, 0.06668892502784729, -0.06380657851696014, -0.046889569610357285, -0.012308277189731598, 0.01764780841767788, -0.042685579508543015, -0.01253463514149189, 0.03889862820506096, -0.026770122349262238, -0.0094723179936409, 0.012197650969028473, 0.02135184034705162, 0.018014326691627502, -0.018415899947285652, -0.008021671324968338, -0.00520953256636858, -0.015383491292595863, 0.05588247999548912, -0.007035623770207167, 0.0667082741856575, 0.0655224397778511, -0.07257135957479477, 0.03002263233065605, -0.03955785185098648, 0.03267994895577431, -0.03093428909778595, -0.03916018083691597, 0.0021403953433036804, 0.019305547699332237, -0.06305618584156036, -0.027531206607818604, -0.0017274148995056748, -0.018346982076764107, 0.01143929548561573, -0.03421246260404587, 0.04112953320145607, 0.04935784265398979, 0.007561436854302883, -0.0023387728724628687, 0.015180591493844986, -0.011111089028418064, 0.0036594271659851074, 0.0017268253723159432, 0.009486948139965534, -0.014101802371442318, -0.04184042662382126, 0.053635455667972565, -0.009864192456007004, -0.004424130544066429, -0.011001991108059883, 0.028795387595891953, -0.03965287283062935, -0.011344530619680882, 0.009381795302033424, -0.043819162994623184, -0.029949400573968887, 0.017585109919309616, 0.02751477248966694, -0.015542013570666313, -0.01841658726334572, -0.010973315685987473, 0.00627405010163784, 0.010259528644382954, 0.02075248770415783, -0.02606363222002983, -0.011550741270184517, -0.0028949787374585867], metadata={'page_label': '4', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=[], excluded_llm_metadata_keys=[], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='3.2 P ARAMETERIZED & TEMPLATED MODULES CAN ABSTRACT PROMPTING TECHNIQUES\\nAkin to type signatures in programming languages, DSPy signatures simply define an interface and\\nprovide type-like hints on the expected behavior. To use a signature, we must declare amodule with\\nthat signature, like we instantiated a Predict module above. A module declaration like this returns\\na function having that signature.\\nThe Predict Module The core module for working with signatures in DSPy isPredict(simplified\\npseudocode in Appendix D.1). Internally, Predict stores the supplied signature, an optional LM to\\nuse (initially None, but otherwise overrides the default LM for this module), and a list of demon-\\nstrations for prompting (initially empty). Like layers in PyTorch, the instantiated module behaves as\\na callable function: it takes in keyword arguments corresponding to the signature input fields (e.g.,\\nquestion), formats a prompt to implement the signature and includes the appropriate demonstra-\\ntions, calls the LM, and parses the output fields. When Predict detects it’s being used in compile\\nmode, it will also internally track input/output traces to assist the teleprompter at bootstrapping the\\ndemonstrations.\\nOther Built-in ModulesDSPy modules translate prompting techniques into modular functions that\\nsupport any signature, contrasting with the standard approach of prompting LMs with task-specific\\ndetails (e.g., hand-written few-shot examples). To this end, DSPy includes a number of more sophis-\\nticated modules like ChainOfThought, ProgramOfThought, MultiChainComparison, and ReAct.5\\nThese can all be used interchangeably to implement a DSPy signature. For instance, simply chang-\\n4String descriptions of the task and the fields are also optional and usually omitted. Fields can carry optional\\nfield prefix and description. By default, fields are assumed to hold free-form strings; we are actively exploring\\noptional data type as a way to specify constraints on valid values (e.g.,boolor int) and more gracefully handle\\nformatting and parsing logic, though this feature is not core to DSPy at the time of writing.\\n5These modules generalize prompting techniques from the literature, respectively, by Wei et al. ', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_chunks[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2f54557",
   "metadata": {},
   "source": [
    "## 5. Create Ddrant Collection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6682847",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import numpy as np\n",
    "# from qdrant_client.models import VectorParams, Distance\n",
    "# from qdrant_client.models import PointStruct\n",
    "\n",
    "\n",
    "# # Create the collection if it doesn't exist\n",
    "# client.recreate_collection(\n",
    "#     collection_name=collection_name,\n",
    "#     vectors_config=VectorParams(\n",
    "#         size=np.array(all_chunks[0].embedding).shape[0],  # dimension of your embedding\n",
    "#         distance=Distance.COSINE                # or Distance.DOT, Distance.EUCLID\n",
    "#     )\n",
    "# )\n",
    "\n",
    "# points = []\n",
    "# for i, chunk in enumerate(all_chunks):\n",
    "#     if chunk.embedding is not None:\n",
    "#         points.append(\n",
    "#             PointStruct(\n",
    "#                 id=i,\n",
    "#                 vector=chunk.embedding,\n",
    "#                 payload={\"text\": chunk.text}\n",
    "#             )\n",
    "#         )\n",
    "\n",
    "# client.upsert(\n",
    "#     collection_name=collection_name,\n",
    "#     points=points\n",
    "# )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6189b8fe",
   "metadata": {},
   "source": [
    "# 5. Load the embedding model and index data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398d3707",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.vector_stores.qdrant import QdrantVectorStore\n",
    "from llama_index.core import VectorStoreIndex, StorageContext\n",
    "\n",
    "def create_index(documents):\n",
    "\n",
    "    vector_store = QdrantVectorStore(client=client,\n",
    "                                     collection_name=collection_name)\n",
    "    \n",
    "    storage_context = StorageContext.from_defaults(vector_store=vector_store)\n",
    "    \n",
    "    index = VectorStoreIndex.from_documents(documents,\n",
    "                                            storage_context=storage_context)\n",
    "    \n",
    "    return index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4cbe8452",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import Settings\n",
    "\n",
    "index = create_index(all_chunks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "cd5373f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "llama_index.core.indices.vector_store.base.VectorStoreIndex"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(index)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c43420f",
   "metadata": {},
   "source": [
    "## 6. Load the LLM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0df5efb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.llms.ollama import Ollama\n",
    "from llama_index.core import Settings\n",
    "\n",
    "\n",
    "llm = Ollama(model=\"llama3.2:1b\", request_timeout=120.0)\n",
    "\n",
    "Settings.llm = llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7dd2a7ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(llama_index.core.settings._Settings,\n",
       " Ollama(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x12a615100>, system_prompt=None, messages_to_prompt=<function messages_to_prompt at 0x11be15160>, completion_to_prompt=<function default_completion_to_prompt at 0x11c188550>, output_parser=None, pydantic_program_mode=<PydanticProgramMode.DEFAULT: 'default'>, query_wrapper_prompt=None, base_url='http://localhost:11434', model='llama3.2:1b', temperature=None, context_window=-1, request_timeout=120.0, prompt_key='prompt', json_mode=False, additional_kwargs={}, is_function_calling_model=True, keep_alive=None, thinking=None),\n",
       " HuggingFaceEmbedding(model_name='BAAI/bge-large-en-v1.5', embed_batch_size=10, callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x12a615100>, num_workers=None, embeddings_cache=None, max_length=512, normalize=True, query_instruction=None, text_instruction=None, cache_folder=None, show_progress_bar=False))"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Settings), Settings.llm, Settings.embed_model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b2f8e3f",
   "metadata": {},
   "source": [
    "# 7. Define the prompt template"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "89ac4eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core import PromptTemplate\n",
    "\n",
    "template = \"\"\"Context information is below:\n",
    "              ---------------------\n",
    "              {context_str}\n",
    "              ---------------------\n",
    "              Given the context information above I want you to think\n",
    "              step by step to answer the query in a crisp manner,\n",
    "              incase you don't know the answer say 'I don't know!'\n",
    "            \n",
    "              Query: {query_str}\n",
    "        \n",
    "              Answer:\"\"\"\n",
    "\n",
    "qa_prompt_tmpl = PromptTemplate(template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1f4e4672",
   "metadata": {},
   "outputs": [],
   "source": [
    "## 8. Query Qdrant directly with your own embedding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "24aeb544",
   "metadata": {},
   "outputs": [],
   "source": [
    "# query = \"What exactly is DSPy?\"\n",
    "\n",
    "# # Use the same embedding model as for chunking\n",
    "# query_embedding = semantic_chunker.chunk([query])[0]\n",
    "\n",
    "# search_result = client.search(\n",
    "#     collection_name=collection_name,\n",
    "#     query_vector=query_embedding.tolist(),\n",
    "#     limit=5\n",
    "# )\n",
    "\n",
    "# # Gather the top results' texts\n",
    "# top_chunks = [hit.payload[\"text\"] for hit in search_result]\n",
    "\n",
    "# # Optionally, synthesize an answer using your LLM\n",
    "# context_str = \"\\n\\n\".join(top_chunks)\n",
    "# prompt = template.format(context_str=context_str, query_str=query)\n",
    "\n",
    "# response = llm.complete(prompt)\n",
    "# print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c6c1af9",
   "metadata": {},
   "source": [
    "# 8. Reranking"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eee93a22",
   "metadata": {},
   "source": [
    "Here, we use a cross-encoder to re-rank the document chunks. Also, we limit the output to the top 3 most relevant chunks based on the model’s scoring."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a04ba8a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from llama_index.core.postprocessor import SentenceTransformerRerank\n",
    "\n",
    "rerank = SentenceTransformerRerank(\n",
    "    model=\"cross-encoder/ms-marco-MiniLM-L-2-v2\", \n",
    "    top_n=3\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0739096d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "SentenceTransformerRerank(callback_manager=<llama_index.core.callbacks.base.CallbackManager object at 0x396fab0d0>, model='cross-encoder/ms-marco-MiniLM-L-2-v2', top_n=3, device='mps', keep_retrieval_score=False, trust_remote_code=False)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rerank"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb166d08",
   "metadata": {},
   "source": [
    "# 9. Query the document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "ad1dcfe2",
   "metadata": {},
   "outputs": [],
   "source": [
    "query_engine = index.as_query_engine(similarity_top_k=3,\n",
    "                                     node_postprocessors=[rerank])\n",
    "\n",
    "query_engine.update_prompts(\n",
    "    {\"response_synthesizer:text_qa_template\": qa_prompt_tmpl}\n",
    ")\n",
    "\n",
    "# response = query_engine.query(\"What exactly is DSPy?\")\n",
    "response = query_engine.query(\"How is DSPy pronounced?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2d1a01d1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "DSPy is pronounced \"dee-ess-pie\"."
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "\n",
    "display(Markdown(str(response)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8275c694",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'4127d83f-54ce-4b8b-9f09-8f34f8968228': {'page_label': '2',\n",
       "  'file_name': 'dspy.pdf',\n",
       "  'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 460814,\n",
       "  'creation_date': '2025-06-11',\n",
       "  'last_modified_date': '2024-11-02'},\n",
       " '4651e2cd-75f4-4f43-9dfb-80e2310b19fb': {'page_label': '4',\n",
       "  'file_name': 'dspy.pdf',\n",
       "  'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 460814,\n",
       "  'creation_date': '2025-06-11',\n",
       "  'last_modified_date': '2024-11-02'},\n",
       " 'a421a2a3-c3b6-42b4-920c-bd24222d6579': {'page_label': '11',\n",
       "  'file_name': 'dspy.pdf',\n",
       "  'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf',\n",
       "  'file_type': 'application/pdf',\n",
       "  'file_size': 460814,\n",
       "  'creation_date': '2025-06-11',\n",
       "  'last_modified_date': '2024-11-02'}}"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "deb85e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'DSPy is pronounced \"dee-ess-pie\".'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "response.response"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41bfbad3",
   "metadata": {},
   "source": [
    "## Debug"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "479a1b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Source Document (page_label: 2)\n",
       "\n",
       "Preprint\n",
       "calls in existing LM pipelines and in popular developer frameworks are generally implemented using\n",
       "hard-coded ‘prompt templates’, that is, long strings of instructions and demonstrations that are hand\n",
       "crafted through manual trial and error. We argue that this approach, while pervasive, can be brittle\n",
       "and unscalable—conceptually akin to hand-tuning the weights for a classifier. A given string prompt\n",
       "might not generalize to different pipelines or across different LMs, data domains, or even inputs.\n",
       "Toward a more systematic approach to designing AI pipelines, we introduce theDSPy programming\n",
       "model.1 DSPy pushes building new LM pipelines away from manipulating free-form strings and\n",
       "closer to programming (composing modular operators to build text transformation graphs) where a\n",
       "compiler automatically generates optimized LM invocation strategies and prompts from a program.\n",
       "We draw inspiration from the consensus that emerged around neural network abstractions (Bergstra\n",
       "et al., 2013), where (1) many general-purpose layers can be modularly composed in any complex\n",
       "architecture and (2) the model weights can be trained using optimizers instead of being hand-tuned.\n",
       "To this end, we propose the DSPy programming model(Sec 3). We first translate string-based\n",
       "prompting techniques, including complex and task-dependent ones like Chain of Thought (Wei et al.,\n",
       "2022) and ReAct (Yao et al., 2022), into declarative modules that carrynatural-language typed sig-\n",
       "natures. DSPy modules are task-adaptive components—akin to neural network layers—that abstract\n",
       "any particular text transformation, like answering a question or summarizing a paper. We then pa-\n",
       "rameterize each module so that it can learn its desired behavior by iteratively bootstrapping useful\n",
       "demonstrations within the pipeline. Inspired directly by PyTorch abstractions (Paszke et al., 2019),\n",
       "DSPy modules are used via expressive define-by-run computational graphs. Pipelines are expressed\n",
       "by (1) declaring the modules needed and (2) using these modules in any logical control flow (e.g.,\n",
       "ifstatements, for loops, exceptions, etc.) to logically connect the modules.\n",
       "We then develop theDSPy compiler(Sec 4), which optimizes any DSPy program to improve quality\n",
       "or cost. The compiler inputs are the program, a few training inputs with optional labels, and a valida-\n",
       "tion metric. The compiler simulates versions of the program on the inputs and bootstraps example\n",
       "traces of each module for self-improvement, using them to construct effective few-shot prompts\n",
       "or finetuning small LMs for steps of the pipeline. Optimization in DSPy is highly modular: it is\n",
       "conducted by teleprompters,2 which are general-purpose optimization strategies that determine how\n",
       "the modules should learn from data. In this way, the compiler automatically maps the declarative\n",
       "modules to high-quality compositions of prompting, finetuning, reasoning, and augmentation.\n",
       "Programming models like DSPy could be assessed along many dimensions, but we focus on the role\n",
       "of expert-crafted prompts in shaping system performance. We are seeking to reduce or even remove\n",
       "their role through DSPy modules (e.g., versions of popular techniques like Chain of Thought) and\n",
       "teleprompters. We report on two expansive case studies: math word problems (GMS8K; Cobbe et al.\n",
       "2021) and multi-hop question answering (HotPotQA; Yang et al. 2018) with explorations of chain\n",
       "of thought, multi-chain reflection, multi-hop retrieval, retrieval-augmented question answering, and\n",
       "agent loops. Our evaluations use a number of different compiling strategies effectively and show\n",
       "that straightforward DSPy programs outperform systems using hand-crafted prompts, while also\n",
       "allowing our programs to use much smaller and hence more efficient LMs effectively.\n",
       "Overall, this work proposes the first programming model that translates prompting techniques into\n",
       "parameterized declarative modules and introduces an effective compiler with general optimiza-\n",
       "tion strategies (teleprompters) to optimize arbitrary pipelines of these modules. Our main contri-\n",
       "butions are empirical and algorithmic: with DSPy, we have found that we can implement very\n",
       "short programs that can bootstrap self-improving multi-stage NLP systems using LMs as small as\n",
       "llama2-13b-chat and T5-Large (770M parameters). Without hand-crafted prompts and within\n",
       "minutes to tens of minutes of compiling, compositions of DSPy modules can raise the quality of\n",
       "simple programs from 33% to 82% (Sec 6) and from 32% to 46% (Sec 7) for GPT-3.5 and, simi-\n",
       "larly, from 9% to 47% (Sec 6) and from 22% to 41% (Sec 7) for llama2-13b-chat.\n",
       "1DSPy is pronounced <mark style='background-color:#ffff00;'>dee-ess-pie</mark>. It’s the second iteration of our earlier Demonstrate–Search–Predict\n",
       "framework (DSP; Khattab et al. 2022). This paper introduces the key concepts in DSPy. For more extensive and\n",
       "up-to-date documentation of the framework, we refer readers to https://github.com/stanfordnlp/dspy.\n",
       "2We derive the name tele-prompters from the notion of abstracting and automating the task of prompting,\n",
       "in particular, such that it happens at a distance, without manual intervention.\n",
       "2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Source Document (page_label: 4)\n",
       "\n",
       "Preprint\n",
       "3.1 N ATURAL LANGUAGE SIGNATURES CAN ABSTRACT PROMPTING & FINETUNING\n",
       "Instead of free-form string prompts, DSPy programs use natural language signatures to assign work\n",
       "to the LM. A DSPy signature isnatural-language typed declaration of a function: a short declarative\n",
       "spec that tells DSPy what a text transformation needs to do (e.g., “consume questions and return\n",
       "answers”), rather than how a specific LM should be prompted to implement that behavior. More\n",
       "formally, a DSPy signature is a tuple of input fields and output fields (and an optional instruction).\n",
       "A field consists offield name and optional metadata.4 In typical usage, the roles of fields are inferred\n",
       "by DSPy as a function of field names. For instance, the DSPy compiler will use in-context learning\n",
       "to interpret questiondifferently from answer and will iteratively refine its usage of these fields.\n",
       "Signatures offer two benefits over prompts: they can be compiled into self-improving and pipeline-\n",
       "adaptive prompts or finetunes. This is primarily done by bootstrapping (Sec 4) useful demonstrating\n",
       "examples for each signature. Additionally, they handle structured formatting and parsing logic to\n",
       "reduce (or, ideally, avoid) brittle string manipulation in user programs.\n",
       "In practice, DSPy signatures can be expressed with a shorthand notation likequestion -> answer,\n",
       "so that line 1 in the following is a complete DSPy program for a basic question-answering system\n",
       "(with line 2 illustrating usage and line 3 the response when GPT-3.5 is the LM):\n",
       "1 qa = dspy.Predict(\"question -> answer\")\n",
       "2 qa(question=\"Where is Guaran ´ı spoken?\")\n",
       "3 # Out: Prediction(answer=’Guaran ´ı is spoken mainly in South America.’)\n",
       "In the shorthand notation, each field’s name indicates the semantic role that the input (or output)\n",
       "field plays in the transformation. DSPy will parse this notation and expand the field names into\n",
       "meaningful instructions for the LM, so that english document -> french translation would\n",
       "prompt for English to French translation. When needed, DSPy offers more advanced programming\n",
       "interfaces for expressing more explicit constraints on signatures (Appendix A).\n",
       "3.2 P ARAMETERIZED & TEMPLATED MODULES CAN ABSTRACT PROMPTING TECHNIQUES\n",
       "Akin to type signatures in programming languages, DSPy signatures simply define an interface and\n",
       "provide type-like hints on the expected behavior. To use a signature, we must declare amodule with\n",
       "that signature, like we instantiated a Predict module above. A module declaration like this returns\n",
       "a function having that signature.\n",
       "The Predict Module The core module for working with signatures in DSPy isPredict(simplified\n",
       "pseudocode in Appendix D.1). Internally, Predict stores the supplied signature, an optional LM to\n",
       "use (initially None, but otherwise overrides the default LM for this module), and a list of demon-\n",
       "strations for prompting (initially empty). Like layers in PyTorch, the instantiated module behaves as\n",
       "a callable function: it takes in keyword arguments corresponding to the signature input fields (e.g.,\n",
       "question), formats a prompt to implement the signature and includes the appropriate demonstra-\n",
       "tions, calls the LM, and parses the output fields. When Predict detects it’s being used in compile\n",
       "mode, it will also internally track input/output traces to assist the teleprompter at bootstrapping the\n",
       "demonstrations.\n",
       "Other Built-in ModulesDSPy modules translate prompting techniques into modular functions that\n",
       "support any signature, contrasting with the standard approach of prompting LMs with task-specific\n",
       "details (e.g., hand-written few-shot examples). To this end, DSPy includes a number of more sophis-\n",
       "ticated modules like ChainOfThought, ProgramOfThought, MultiChainComparison, and ReAct.5\n",
       "These can all be used interchangeably to implement a DSPy signature. For instance, simply chang-\n",
       "4String descriptions of the task and the fields are also optional and usually omitted. Fields can carry optional\n",
       "field prefix and description. By default, fields are assumed to hold free-form strings; we are actively exploring\n",
       "optional data type as a way to specify constraints on valid values (e.g.,boolor int) and more gracefully handle\n",
       "formatting and parsing logic, though this feature is not core to DSPy at the time of writing.\n",
       "5These modules generalize prompting techniques from the literature, respectively, by Wei et al. (2022),\n",
       "Chen et al. (2022), Yoran et al. (2023), and Yao et al. (2022) and, in doing so, generalize the ideas on zero-shot\n",
       "prompting and rationale self-generation from Kojima et al. (2022), Zelikman et al. (2022), Zhang et al. (2022),\n",
       "and Huang et al. (2022) to parameterized modules that can bootstrap arbitrary multi-stage pipelines.\n",
       "4"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/markdown": [
       "### Source Document (page_label: 11)\n",
       "\n",
       "Preprint\n",
       "Table 2: Results with in-context learning on HotPotQA multi-hop retrieval question answering. We\n",
       "report answer exact match (Ans) and pair-retrieval accuracy (Psg). Each row represents a separate\n",
       "pipeline: the module in the Program column is compiled against the examples in the Training set.\n",
       "The programs, compilers, and (small) training sets are defined in the main text. For HotPotQA, we\n",
       "use the training set (and not dev) directly for cross-validation. ∗The marked result is evaluated on\n",
       "50% of our test set due to cost.\n",
       "GPT-3.5 Llama2-13b-chat\n",
       "Program Compiler Dev Test Dev Test\n",
       "Ans Psg Ans Psg Ans Psg Ans Psg\n",
       "vanilla fewshot 34.3 n/a 31.5 n/a 27.5 n/a 21.8 n/a\n",
       "CoTRAG fewshot 36.4 36.0 29.8 34.4 34.5 36.0 28.0 34.4\n",
       "bootstrap 42.3 36.0 – – 38.3 36.0 32.9 34.4\n",
       "react\n",
       "none 20.3 – – – 20.0 – – –\n",
       "+humanr 33.0 – – – 28.3 – – –\n",
       "bootstrap 31.0 – – – 24.7 – – –\n",
       "bootstrap×2 39.0 – – – 40.0 – – –\n",
       "multihop\n",
       "fewshot 36.9 38.3 31.2 40.8 34.7 32.0 31.3 30.8\n",
       "bootstrap 48.7 47.0 39.6 43.8 42.0 48.3 36.4 43.5\n",
       "ensemble 54.7 – 45.6∗ – 50.0 – 41.0 –\n",
       "questions. For compiling, we use a teacher program consisting of an ensemble (union) of two\n",
       "multihop with llama2-13b-chat. Considering its extremely small size and local availability, this\n",
       "compiled program with T5-Largewould impose orders of magnitude lower costs for inference than\n",
       "a proprietary LM like GPT-3.5.\n",
       "Our results may be pegged against the evaluation on HotPotQA in a number of recent papers, though\n",
       "there is significant variation in evaluation methodology and test set samples across studies in this\n",
       "space. Using CoT prompting, Si et al. (2022) achieve 25.2% EM. With a “recite-and-answer” tech-\n",
       "nique that uses PaLM-62B (Chowdhery et al., 2022) to recite evidence passages, Sun et al. (2022)\n",
       "achieve 26.5% EM. Wang et al. (2022a) achieve 33.8% EM and 44.6% F1 when applying self-\n",
       "consistency for PaLM-540B. Yao et al. (2022) achieve 27.4% EM using ReAct with PaLM-540B\n",
       "and 30.8 with text-davinci-002, with a tool giving it the ability for search using a Wikipedia\n",
       "API. They push their PaLM results to 35.1% EM by applying an additional CoT step with self-\n",
       "consistency, which may resemble our ensemble approach in the sense of aggregating multiple an-\n",
       "swers. Trivedi et al. (2022) reports 49% using a pipeline with code-davinci-002 LM on a sample\n",
       "of 500 HotPotQA questions.\n",
       "8 C ONCLUSION\n",
       "This paper introduced DSPy, a new programming model for designing AI systems using pipelines\n",
       "of pretrained LMs and other tools. We presented three new concepts introduced in this abstraction\n",
       "(DSPy signatures, modules, and teleprompters), and showed in two very different case studies that\n",
       "it supports rapid development of highly effective systems that use relatively small LMs. We have\n",
       "maintained open-source versions of this framework for close to a year. In this period, we have seen\n",
       "and created a large number of programs that were compiled to high-quality systems by DSPy, span-\n",
       "ning tasks from information extraction to low-resource synthetic data generation. In the interest of\n",
       "space and to maintain reasonable scope in this paper, we leave reporting on such tasks under con-\n",
       "trolled experimental conditions to future work. While in-context learning has proved transformative\n",
       "over the past 2–3 years of LM research, we argue that the true expressive power in this emerging\n",
       "paradigm is in building sophisticated text transformation graphs in which composable modules and\n",
       "optimizers (teleprompters) come together to leverage LMs in more systematic and reliable ways.\n",
       "ACKNOWLEDGMENTS\n",
       "We thank Josh Purtell for suggesting the apt name “text transformation graph” for the computational\n",
       "graph abstraction of DSPy. We thank Rick Battle, Igor Kotenkov, Lisa Li, David Hall, Ashwin\n",
       "Paranjape, Chris Manning, Percy Liang, and many researchers, developers, and users for valuable\n",
       "11"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Markdown, display\n",
    "import re\n",
    "\n",
    "def highlight(text, query, color):\n",
    "        # Case-insensitive highlight\n",
    "        pattern = re.compile(re.escape(query), re.IGNORECASE)\n",
    "        return pattern.sub(f\"<mark style='background-color:{color};'>{query}</mark>\", text)\n",
    "\n",
    "def display_sources_with_highlight(response, docs, query, highlight_color=\"#ffff00\"):\n",
    "    \"\"\"\n",
    "    Display source documents for the response, highlighting the query in the text.\n",
    "    \"\"\"\n",
    "    \n",
    "    for source in response.metadata.values():\n",
    "        source_page = source.get(\"page_label\")\n",
    "        if source_page:\n",
    "            d = next((doc for doc in docs if doc.metadata.get(\"page_label\") == source_page), None)\n",
    "            if d:\n",
    "                highlighted = highlight(d.text, query, highlight_color)\n",
    "                display(Markdown(f\"### Source Document (page_label: {source_page})\\n\\n{highlighted}\"))\n",
    "\n",
    "# Example usage:\n",
    "word = \"dee-ess-pie\"\n",
    "display_sources_with_highlight(response, docs, word)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11d1f031",
   "metadata": {},
   "source": [
    "Let's try retrieving the docs containing the query instead"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "ac2e58dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Write an inline function to find the first document containing a specific text\n",
    "def find_document_with_text(text):\n",
    "    for i, doc in enumerate(docs):\n",
    "        if text in doc.text:\n",
    "            return i, doc\n",
    "    return None, None\n",
    "\n",
    "i, doc = find_document_with_text(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "404a282b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Document(id_='8084eedf-d1f1-4f0b-bf47-c3612d196444', embedding=None, metadata={'page_label': '2', 'file_name': 'dspy.pdf', 'file_path': '/Users/fc/experiments/rag-project/docs/dspy.pdf', 'file_type': 'application/pdf', 'file_size': 460814, 'creation_date': '2025-06-11', 'last_modified_date': '2024-11-02'}, excluded_embed_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], excluded_llm_metadata_keys=['file_name', 'file_type', 'file_size', 'creation_date', 'last_modified_date', 'last_accessed_date'], relationships={}, metadata_template='{key}: {value}', metadata_separator='\\n', text_resource=MediaResource(embeddings=None, data=None, text='Preprint\\ncalls in existing LM pipelines and in popular developer frameworks are generally implemented using\\nhard-coded ‘prompt templates’, that is, long strings of instructions and demonstrations that are hand\\ncrafted through manual trial and error. We argue that this approach, while pervasive, can be brittle\\nand unscalable—conceptually akin to hand-tuning the weights for a classifier. A given string prompt\\nmight not generalize to different pipelines or across different LMs, data domains, or even inputs.\\nToward a more systematic approach to designing AI pipelines, we introduce theDSPy programming\\nmodel.1 DSPy pushes building new LM pipelines away from manipulating free-form strings and\\ncloser to programming (composing modular operators to build text transformation graphs) where a\\ncompiler automatically generates optimized LM invocation strategies and prompts from a program.\\nWe draw inspiration from the consensus that emerged around neural network abstractions (Bergstra\\net al., 2013), where (1) many general-purpose layers can be modularly composed in any complex\\narchitecture and (2) the model weights can be trained using optimizers instead of being hand-tuned.\\nTo this end, we propose the DSPy programming model(Sec 3). We first translate string-based\\nprompting techniques, including complex and task-dependent ones like Chain of Thought (Wei et al.,\\n2022) and ReAct (Yao et al., 2022), into declarative modules that carrynatural-language typed sig-\\nnatures. DSPy modules are task-adaptive components—akin to neural network layers—that abstract\\nany particular text transformation, like answering a question or summarizing a paper. We then pa-\\nrameterize each module so that it can learn its desired behavior by iteratively bootstrapping useful\\ndemonstrations within the pipeline. Inspired directly by PyTorch abstractions (Paszke et al., 2019),\\nDSPy modules are used via expressive define-by-run computational graphs. Pipelines are expressed\\nby (1) declaring the modules needed and (2) using these modules in any logical control flow (e.g.,\\nifstatements, for loops, exceptions, etc.) to logically connect the modules.\\nWe then develop theDSPy compiler(Sec 4), which optimizes any DSPy program to improve quality\\nor cost. The compiler inputs are the program, a few training inputs with optional labels, and a valida-\\ntion metric. The compiler simulates versions of the program on the inputs and bootstraps example\\ntraces of each module for self-improvement, using them to construct effective few-shot prompts\\nor finetuning small LMs for steps of the pipeline. Optimization in DSPy is highly modular: it is\\nconducted by teleprompters,2 which are general-purpose optimization strategies that determine how\\nthe modules should learn from data. In this way, the compiler automatically maps the declarative\\nmodules to high-quality compositions of prompting, finetuning, reasoning, and augmentation.\\nProgramming models like DSPy could be assessed along many dimensions, but we focus on the role\\nof expert-crafted prompts in shaping system performance. We are seeking to reduce or even remove\\ntheir role through DSPy modules (e.g., versions of popular techniques like Chain of Thought) and\\nteleprompters. We report on two expansive case studies: math word problems (GMS8K; Cobbe et al.\\n2021) and multi-hop question answering (HotPotQA; Yang et al. 2018) with explorations of chain\\nof thought, multi-chain reflection, multi-hop retrieval, retrieval-augmented question answering, and\\nagent loops. Our evaluations use a number of different compiling strategies effectively and show\\nthat straightforward DSPy programs outperform systems using hand-crafted prompts, while also\\nallowing our programs to use much smaller and hence more efficient LMs effectively.\\nOverall, this work proposes the first programming model that translates prompting techniques into\\nparameterized declarative modules and introduces an effective compiler with general optimiza-\\ntion strategies (teleprompters) to optimize arbitrary pipelines of these modules. Our main contri-\\nbutions are empirical and algorithmic: with DSPy, we have found that we can implement very\\nshort programs that can bootstrap self-improving multi-stage NLP systems using LMs as small as\\nllama2-13b-chat and T5-Large (770M parameters). Without hand-crafted prompts and within\\nminutes to tens of minutes of compiling, compositions of DSPy modules can raise the quality of\\nsimple programs from 33% to 82% (Sec 6) and from 32% to 46% (Sec 7) for GPT-3.5 and, simi-\\nlarly, from 9% to 47% (Sec 6) and from 22% to 41% (Sec 7) for llama2-13b-chat.\\n1DSPy is pronounced dee-ess-pie. It’s the second iteration of our earlier Demonstrate–Search–Predict\\nframework (DSP; Khattab et al. 2022). This paper introduces the key concepts in DSPy. For more extensive and\\nup-to-date documentation of the framework, we refer readers to https://github.com/stanfordnlp/dspy.\\n2We derive the name tele-prompters from the notion of abstracting and automating the task of prompting,\\nin particular, such that it happens at a distance, without manual intervention.\\n2', path=None, url=None, mimetype=None), image_resource=None, audio_resource=None, video_resource=None, text_template='{metadata_str}\\n\\n{content}')"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "8ad8817b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "Preprint\n",
       "calls in existing LM pipelines and in popular developer frameworks are generally implemented using\n",
       "hard-coded ‘prompt templates’, that is, long strings of instructions and demonstrations that are hand\n",
       "crafted through manual trial and error. We argue that this approach, while pervasive, can be brittle\n",
       "and unscalable—conceptually akin to hand-tuning the weights for a classifier. A given string prompt\n",
       "might not generalize to different pipelines or across different LMs, data domains, or even inputs.\n",
       "Toward a more systematic approach to designing AI pipelines, we introduce theDSPy programming\n",
       "model.1 DSPy pushes building new LM pipelines away from manipulating free-form strings and\n",
       "closer to programming (composing modular operators to build text transformation graphs) where a\n",
       "compiler automatically generates optimized LM invocation strategies and prompts from a program.\n",
       "We draw inspiration from the consensus that emerged around neural network abstractions (Bergstra\n",
       "et al., 2013), where (1) many general-purpose layers can be modularly composed in any complex\n",
       "architecture and (2) the model weights can be trained using optimizers instead of being hand-tuned.\n",
       "To this end, we propose the DSPy programming model(Sec 3). We first translate string-based\n",
       "prompting techniques, including complex and task-dependent ones like Chain of Thought (Wei et al.,\n",
       "2022) and ReAct (Yao et al., 2022), into declarative modules that carrynatural-language typed sig-\n",
       "natures. DSPy modules are task-adaptive components—akin to neural network layers—that abstract\n",
       "any particular text transformation, like answering a question or summarizing a paper. We then pa-\n",
       "rameterize each module so that it can learn its desired behavior by iteratively bootstrapping useful\n",
       "demonstrations within the pipeline. Inspired directly by PyTorch abstractions (Paszke et al., 2019),\n",
       "DSPy modules are used via expressive define-by-run computational graphs. Pipelines are expressed\n",
       "by (1) declaring the modules needed and (2) using these modules in any logical control flow (e.g.,\n",
       "ifstatements, for loops, exceptions, etc.) to logically connect the modules.\n",
       "We then develop theDSPy compiler(Sec 4), which optimizes any DSPy program to improve quality\n",
       "or cost. The compiler inputs are the program, a few training inputs with optional labels, and a valida-\n",
       "tion metric. The compiler simulates versions of the program on the inputs and bootstraps example\n",
       "traces of each module for self-improvement, using them to construct effective few-shot prompts\n",
       "or finetuning small LMs for steps of the pipeline. Optimization in DSPy is highly modular: it is\n",
       "conducted by teleprompters,2 which are general-purpose optimization strategies that determine how\n",
       "the modules should learn from data. In this way, the compiler automatically maps the declarative\n",
       "modules to high-quality compositions of prompting, finetuning, reasoning, and augmentation.\n",
       "Programming models like DSPy could be assessed along many dimensions, but we focus on the role\n",
       "of expert-crafted prompts in shaping system performance. We are seeking to reduce or even remove\n",
       "their role through DSPy modules (e.g., versions of popular techniques like Chain of Thought) and\n",
       "teleprompters. We report on two expansive case studies: math word problems (GMS8K; Cobbe et al.\n",
       "2021) and multi-hop question answering (HotPotQA; Yang et al. 2018) with explorations of chain\n",
       "of thought, multi-chain reflection, multi-hop retrieval, retrieval-augmented question answering, and\n",
       "agent loops. Our evaluations use a number of different compiling strategies effectively and show\n",
       "that straightforward DSPy programs outperform systems using hand-crafted prompts, while also\n",
       "allowing our programs to use much smaller and hence more efficient LMs effectively.\n",
       "Overall, this work proposes the first programming model that translates prompting techniques into\n",
       "parameterized declarative modules and introduces an effective compiler with general optimiza-\n",
       "tion strategies (teleprompters) to optimize arbitrary pipelines of these modules. Our main contri-\n",
       "butions are empirical and algorithmic: with DSPy, we have found that we can implement very\n",
       "short programs that can bootstrap self-improving multi-stage NLP systems using LMs as small as\n",
       "llama2-13b-chat and T5-Large (770M parameters). Without hand-crafted prompts and within\n",
       "minutes to tens of minutes of compiling, compositions of DSPy modules can raise the quality of\n",
       "simple programs from 33% to 82% (Sec 6) and from 32% to 46% (Sec 7) for GPT-3.5 and, simi-\n",
       "larly, from 9% to 47% (Sec 6) and from 22% to 41% (Sec 7) for llama2-13b-chat.\n",
       "1DSPy is pronounced <mark style='background-color:#ffff00;'>dee-ess-pie</mark>. It’s the second iteration of our earlier Demonstrate–Search–Predict\n",
       "framework (DSP; Khattab et al. 2022). This paper introduces the key concepts in DSPy. For more extensive and\n",
       "up-to-date documentation of the framework, we refer readers to https://github.com/stanfordnlp/dspy.\n",
       "2We derive the name tele-prompters from the notion of abstracting and automating the task of prompting,\n",
       "in particular, such that it happens at a distance, without manual intervention.\n",
       "2"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Markdown(highlight(docs[1].text, word, \"#ffff00\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "69c48fa4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
